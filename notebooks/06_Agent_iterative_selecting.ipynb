{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804528d3",
   "metadata": {},
   "source": [
    "# Iterative Agent-Based Feature Selection for Financial Time Series\n",
    "\n",
    "This notebook implements an iterative process that:\n",
    "1. Runs a baseline model without enhanced features\n",
    "2. Uses an AI agent to generate feature engineering code\n",
    "3. Tests the enhanced features and measures performance\n",
    "4. Iteratively improves the features based on performance feedback\n",
    "5. Continues until performance plateaus\n",
    "\n",
    "The system combines the robust feature selection from `05_Agent_selecting.ipynb` with the iterative improvement process from `test.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b32849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pickle\n",
    "import anthropic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded successfully!\n",
      "Training data shape: (142, 4, 62)\n",
      "Test data shape: (36, 4, 62)\n",
      "Features per timestep: 62\n",
      "Lookback window: 4\n"
     ]
    }
   ],
   "source": [
    "# Load data and configuration\n",
    "stock = 'PFE'\n",
    "ANTHROPIC_API_KEY = ''  # Replace with your actual API key\n",
    "\n",
    "# Load raw data\n",
    "raw_data = pickle.load(open(f'cache/{stock}_raw_data_with_ohlc.pkl', 'rb'))\n",
    "X_train_raw = raw_data['X_train_raw']\n",
    "X_test_raw = raw_data['X_test_raw']\n",
    "y_train = raw_data['y_train']\n",
    "y_test = raw_data['y_test']\n",
    "prev_log_train = raw_data['prev_log_train']\n",
    "prev_log_test = raw_data['prev_log_test']\n",
    "si_dates = raw_data['si_dates']\n",
    "SI_series = raw_data['SI_series']\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"Training data shape: {X_train_raw.shape}\")\n",
    "print(f\"Test data shape: {X_test_raw.shape}\")\n",
    "print(f\"Features per timestep: {X_train_raw.shape[2]}\")\n",
    "print(f\"Lookback window: {X_train_raw.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a5eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LSTM model class defined!\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model class\n",
    "class EnhancedLSTMTimeSeries(nn.Module):\n",
    "    def __init__(self, input_size=62, hidden_size=64, num_layers=3, output_size=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Take the last time step output\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Feed through fully connected layers\n",
    "        out = self.dropout(last_output)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"‚úÖ LSTM model class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d11466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model training and evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate p-values for feature importance\n",
    "def calculate_feature_pvalues(X_train, y_train, feature_names=None):\n",
    "    \"\"\"\n",
    "    Calculate p-values for each feature using linear regression\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Flatten the 3D data to 2D for statistical analysis\n",
    "    X_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    y_flat = y_train.ravel()\n",
    "    \n",
    "    # Fit linear regression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_flat, y_flat)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    y_pred = lr.predict(X_flat)\n",
    "    residuals = y_flat - y_pred\n",
    "    mse = np.mean(residuals**2)\n",
    "    \n",
    "    # Calculate standard errors and t-statistics\n",
    "    X_with_intercept = np.column_stack([np.ones(X_flat.shape[0]), X_flat])\n",
    "    try:\n",
    "        # Calculate covariance matrix\n",
    "        cov_matrix = mse * np.linalg.inv(X_with_intercept.T @ X_with_intercept)\n",
    "        standard_errors = np.sqrt(np.diag(cov_matrix))[1:]  # Exclude intercept\n",
    "        t_statistics = lr.coef_ / standard_errors\n",
    "        \n",
    "        # Calculate p-values (two-tailed test)\n",
    "        degrees_of_freedom = X_flat.shape[0] - X_flat.shape[1] - 1\n",
    "        p_values = 2 * (1 - stats.t.cdf(np.abs(t_statistics), degrees_of_freedom))\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        # If matrix is singular, use a simpler approach\n",
    "        print(\"‚ö†Ô∏è Singular matrix detected, using simplified p-value calculation\")\n",
    "        p_values = np.ones(X_flat.shape[1]) * 0.5  # Default to non-significant\n",
    "    \n",
    "    # Create feature names if not provided\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"Feature_{i}\" for i in range(X_flat.shape[1])]\n",
    "    \n",
    "    # Create results dictionary\n",
    "    feature_stats = {}\n",
    "    for i, (name, pval, coef) in enumerate(zip(feature_names, p_values, lr.coef_)):\n",
    "        feature_stats[name] = {\n",
    "            'p_value': pval,\n",
    "            'coefficient': coef,\n",
    "            'significant': pval < 0.05,\n",
    "            'highly_significant': pval < 0.01\n",
    "        }\n",
    "    \n",
    "    return feature_stats, lr.coef_, p_values\n",
    "\n",
    "# Enhanced function to train and evaluate a model with p-value analysis\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, prev_log_test, model_name=\"Model\", epochs=50):\n",
    "    \"\"\"\n",
    "    Train and evaluate an LSTM model, returning performance metrics and feature statistics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Scale inputs\n",
    "    scaler = StandardScaler()\n",
    "    X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "    scaler.fit(X_train_reshaped)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "    X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "    X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "    \n",
    "    # Create data loaders\n",
    "    batch_size = 8\n",
    "    train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=batch_size)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = EnhancedLSTMTimeSeries(input_size=X_train.shape[-1], hidden_size=32, num_layers=2, output_size=1)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    \n",
    "    # Training loop\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        # Early stopping\n",
    "        if train_loss < best_loss:\n",
    "            best_loss = train_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    pred_logret = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in test_loader:\n",
    "            pred_logret.append(model(xb).numpy())\n",
    "    pred_logret = np.concatenate(pred_logret, axis=0).ravel()\n",
    "    \n",
    "    # Reconstruct levels\n",
    "    y_pred_levels = np.exp(prev_log_test + pred_logret)\n",
    "    y_true_levels = np.exp(prev_log_test + y_test.ravel())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(y_pred_levels - y_true_levels))\n",
    "    rmse = np.sqrt(np.mean((y_pred_levels - y_true_levels)**2))\n",
    "    mape = np.mean(np.abs((y_true_levels - y_pred_levels) / y_true_levels)) * 100\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    # Calculate feature p-values\n",
    "    print(f\"\\nüìä Calculating feature p-values...\")\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[-1])]\n",
    "    feature_stats, coefficients, p_values = calculate_feature_pvalues(X_train_scaled, y_train, feature_names)\n",
    "    \n",
    "    # Print feature significance summary\n",
    "    significant_features = [name for name, stats in feature_stats.items() if stats['significant']]\n",
    "    highly_significant = [name for name, stats in feature_stats.items() if stats['highly_significant']]\n",
    "    \n",
    "    print(f\"üìà Feature Significance Analysis:\")\n",
    "    print(f\"   ‚Ä¢ Total features: {len(feature_stats)}\")\n",
    "    print(f\"   ‚Ä¢ Significant features (p < 0.05): {len(significant_features)}\")\n",
    "    print(f\"   ‚Ä¢ Highly significant features (p < 0.01): {len(highly_significant)}\")\n",
    "    \n",
    "    if significant_features:\n",
    "        print(f\"   ‚Ä¢ Significant features: {significant_features[:5]}{'...' if len(significant_features) > 5 else ''}\")\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'predictions': y_pred_levels,\n",
    "        'true_values': y_true_levels,\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'feature_stats': feature_stats,\n",
    "        'coefficients': coefficients,\n",
    "        'p_values': p_values,\n",
    "        'significant_features': significant_features,\n",
    "        'highly_significant_features': highly_significant\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Model training and evaluation function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3901d62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Iterative Agent-Based Feature Selection Process\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "Training Baseline (All 62 Features)\n",
      "==================================================\n",
      "Epoch 1/50, Train Loss: 0.026222\n",
      "Epoch 11/50, Train Loss: 0.014758\n",
      "Epoch 21/50, Train Loss: 0.013826\n",
      "Epoch 31/50, Train Loss: 0.012481\n",
      "Epoch 41/50, Train Loss: 0.011918\n",
      "\n",
      "Baseline (All 62 Features) Performance:\n",
      "MAE: 7301369.5718\n",
      "RMSE: 9576693.4427\n",
      "MAPE: 9.37%\n",
      "\n",
      "üìä Baseline Performance: MAPE = 9.37%\n",
      "‚úÖ Baseline model completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Run baseline model with all original features\n",
    "print(\"üöÄ Starting Iterative Agent-Based Feature Selection Process\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Baseline model with all 62 features\n",
    "baseline_results = train_and_evaluate_model(\n",
    "    X_train_raw, X_test_raw, y_train, y_test, prev_log_test, \n",
    "    model_name=\"Baseline (All 62 Features)\", epochs=50\n",
    ")\n",
    "\n",
    "baseline_mape = baseline_results['mape']\n",
    "print(f\"\\nüìä Baseline Performance: MAPE = {baseline_mape:.2f}%\")\n",
    "\n",
    "# Store results for comparison\n",
    "iteration_results = []\n",
    "iteration_results.append({\n",
    "    'iteration': 0,\n",
    "    'model_name': 'Baseline',\n",
    "    'features_used': 'All 62 original features',\n",
    "    'feature_count': X_train_raw.shape[2],\n",
    "    'mape': baseline_mape,\n",
    "    'mae': baseline_results['mae'],\n",
    "    'rmse': baseline_results['rmse'],\n",
    "    'improvement': 0.0,\n",
    "    'predictions': baseline_results['predictions']\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Baseline model completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12e715c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Iterative LLM Feature Selector class defined!\n"
     ]
    }
   ],
   "source": [
    "# Define the LLM Feature Selector class (adapted from test.py)\n",
    "class IterativeLLMFeatureSelector:\n",
    "    \"\"\"\n",
    "    An iterative LLM-based feature selector that learns from previous iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, anthropic_api_key: str):\n",
    "        self.client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "        self.iteration_history = []\n",
    "        print(\"‚úÖ Claude API client initialized successfully!\")\n",
    "    \n",
    "    def create_iterative_prompt(self, iteration_num: int, previous_results: list, feature_description: str) -> str:\n",
    "        \"\"\"\n",
    "        Create a prompt that includes performance history and asks for improvements\n",
    "        \"\"\"\n",
    "        # Build performance history\n",
    "        history_text = \"\"\n",
    "        if previous_results:\n",
    "            history_text = \"\\n\\nPERFORMANCE HISTORY:\\n\"\n",
    "            for i, result in enumerate(previous_results):\n",
    "                history_text += f\"Iteration {i}: {result['model_name']} - MAPE: {result['mape']:.2f}%\"\n",
    "                if i > 0:\n",
    "                    improvement = result['improvement']\n",
    "                    history_text += f\" (Improvement: {improvement:+.1f}%)\"\n",
    "                history_text += f\"\\n  Features: {result['features_used']}\\n\"\n",
    "        \n",
    "        # Get the best performance so far\n",
    "        best_mape = min([r['mape'] for r in previous_results]) if previous_results else 100.0\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are a financial data scientist expert in feature engineering for Short Interest prediction models. \n",
    "\n",
    "I have financial time series data with the following structure:\n",
    "- Shape: (samples, lookback_window=4, features=62)\n",
    "- Features at each timestamp T include:\n",
    "  1. Short interest at time T reproted every 15 days (1 feature)\n",
    "  2. Average daily volume quantity of past 15 days (1 feature) \n",
    "  3. OHLC (Open, High, Low, Close) prices for past 15 days (4 √ó 15 = 60 features)\n",
    "\n",
    "Total: 1 + 1 + 60 = 62 features per timestamp.\n",
    "\n",
    "{history_text}\n",
    "\n",
    "CURRENT TASK (Iteration {iteration_num}):\n",
    "Your goal is to create an improved feature engineering function that will achieve better performance than the current best MAPE of {best_mape:.2f}%.\n",
    "\n",
    "Based on the performance history above, analyze what worked and what didn't, then create a new feature engineering approach that:\n",
    "1. Learns from previous iterations' successes and failures\n",
    "2. Focuses on the most predictive features\n",
    "3. Considers financial domain knowledge (momentum, volatility, volume patterns, etc.)\n",
    "4. Maintains LSTM-compatible time series structure\n",
    "\n",
    "Requirements:\n",
    "1. Write a function called `construct_features` that takes a numpy array of shape (lookback_window, 62) and returns a numpy array of shape (lookback_window, constructed_features)\n",
    "2. The function should process each timestamp independently but maintain the temporal structure\n",
    "3. Focus on the most predictive features for each time step\n",
    "4. Consider financial domain knowledge (e.g., price momentum, volatility, volume patterns, etc.)\n",
    "5. The output should be a 2D numpy array with shape (lookback_window, constructed_features)\n",
    "6. Include comments explaining your feature engineering choices and how they address previous performance issues\n",
    "7. Make sure the code is production-ready and handles edge cases\n",
    "8. DO NOT include any import statements - only use numpy (available as 'np') and built-in Python functions\n",
    "9. The function must return a 2D array where each row represents features for one time step\n",
    "10. Use numpy nan_to_num to handle NaN values\n",
    "\n",
    "Please provide ONLY the Python function code, no explanations outside the code comments.\n",
    "\n",
    "Feature description: {feature_description}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def call_claude_for_iterative_improvement(self, iteration_num: int, previous_results: list, feature_description: str = \"Stock prediction with short interest, volume, and OHLC data\") -> str:\n",
    "        \"\"\"\n",
    "        Call Claude API with iterative improvement context\n",
    "        \"\"\"\n",
    "        prompt = self.create_iterative_prompt(iteration_num, previous_results, feature_description)\n",
    "        \n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=2000,\n",
    "                temperature=0.1,  # Slightly higher temperature for creativity in later iterations\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            return response.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Claude API: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_function_from_response(self, response_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the construct_features function from Claude's response\n",
    "        \"\"\"\n",
    "        lines = response_text.split('\\n')\n",
    "        function_lines = []\n",
    "        in_function = False\n",
    "        indent_level = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'def construct_features' in line:\n",
    "                in_function = True\n",
    "                function_lines.append(line)\n",
    "                indent_level = len(line) - len(line.lstrip())\n",
    "            elif in_function:\n",
    "                if line.strip() == '':\n",
    "                    function_lines.append(line)\n",
    "                elif len(line) - len(line.lstrip()) > indent_level or line.strip() == '':\n",
    "                    function_lines.append(line)\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        return '\\n'.join(function_lines)\n",
    "    \n",
    "    def execute_feature_construction_code(self, code: str) -> callable:\n",
    "        \"\"\"\n",
    "        Execute the generated feature construction code and return the function\n",
    "        \"\"\"\n",
    "        try:\n",
    "            exec_globals = {\n",
    "                'np': np,\n",
    "                'pd': pd,\n",
    "                '__builtins__': {\n",
    "                    'len': len, 'range': range, 'enumerate': enumerate, 'zip': zip,\n",
    "                    'sum': sum, 'max': max, 'min': min, 'abs': abs, 'round': round,\n",
    "                    'int': int, 'float': float, 'str': str, 'list': list, 'dict': dict,\n",
    "                    'tuple': tuple, 'set': set, 'print': print, 'any': any, 'all': all,\n",
    "                    'sorted': sorted, 'reversed': reversed, 'isinstance': isinstance,\n",
    "                    'type': type, 'hasattr': hasattr, 'getattr': getattr, 'setattr': setattr,\n",
    "                    'callable': callable, 'issubclass': issubclass, 'super': super,\n",
    "                    'open': open, 'iter': iter, 'next': next, 'map': map, 'filter': filter,\n",
    "                    'pow': pow, 'divmod': divmod, 'bin': bin, 'hex': hex, 'oct': oct,\n",
    "                    'ord': ord, 'chr': chr, 'bool': bool, 'complex': complex,\n",
    "                    'bytes': bytes, 'bytearray': bytearray, 'memoryview': memoryview,\n",
    "                    'slice': slice, 'property': property, 'staticmethod': staticmethod,\n",
    "                    'classmethod': classmethod,\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            exec(code, exec_globals)\n",
    "            \n",
    "            if 'construct_features' in exec_globals:\n",
    "                return exec_globals['construct_features']\n",
    "            else:\n",
    "                raise ValueError(\"construct_features function not found in generated code\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error executing generated code: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def fallback_construct_features(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fallback feature construction function\n",
    "        \"\"\"\n",
    "        if data.shape[1] != 62:\n",
    "            raise ValueError(f\"Expected 62 features, got {data.shape[1]}\")\n",
    "        \n",
    "        lookback_window = data.shape[0]\n",
    "        features_per_timestep = 15\n",
    "        \n",
    "        output = np.zeros((lookback_window, features_per_timestep))\n",
    "        \n",
    "        for t in range(lookback_window):\n",
    "            short_interest = data[t, 0]\n",
    "            volume = data[t, 1]\n",
    "            ohlc = data[t, 2:].reshape(15, 4)\n",
    "            \n",
    "            # Basic features\n",
    "            output[t, 0] = short_interest\n",
    "            output[t, 1] = volume\n",
    "            output[t, 2:6] = ohlc[-1]  # Latest OHLC\n",
    "            \n",
    "            # Momentum features\n",
    "            close_prices = ohlc[:, 3]\n",
    "            for i, horizon in enumerate([1, 3, 5, 10]):\n",
    "                if len(close_prices) > horizon:\n",
    "                    momentum = (close_prices[-1] - close_prices[-horizon-1]) / close_prices[-horizon-1]\n",
    "                    output[t, 6 + i] = momentum\n",
    "                else:\n",
    "                    output[t, 6 + i] = 0\n",
    "            \n",
    "            # Volatility and range\n",
    "            if len(close_prices) > 1:\n",
    "                returns = np.diff(close_prices) / close_prices[:-1]\n",
    "                output[t, 10] = np.std(returns)\n",
    "                output[t, 11] = (np.max(close_prices) - np.min(close_prices)) / np.mean(close_prices)\n",
    "            \n",
    "            # Technical indicators\n",
    "            if len(close_prices) > 1:\n",
    "                sma_5 = np.mean(close_prices[-5:]) if len(close_prices) >= 5 else np.mean(close_prices)\n",
    "                output[t, 12] = close_prices[-1] / sma_5\n",
    "                \n",
    "                high_low_ratio = ohlc[:, 1] / ohlc[:, 2]\n",
    "                output[t, 13] = np.mean(high_low_ratio)\n",
    "                \n",
    "                output[t, 14] = volume * close_prices[-1] / np.mean(close_prices)\n",
    "        \n",
    "        return output.astype(np.float32)\n",
    "    \n",
    "    def apply_feature_selection_to_data(self, X_data: np.ndarray, construct_func: callable, max_retries: int = 5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply feature selection to the entire dataset with retry mechanism\n",
    "        \"\"\"\n",
    "        processed_samples = []\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                processed_samples = []\n",
    "                success = True\n",
    "                \n",
    "                for i in range(X_data.shape[0]):\n",
    "                    sample_features = X_data[i]\n",
    "                    \n",
    "                    try:\n",
    "                        reduced_features = construct_func(sample_features)\n",
    "                        \n",
    "                        if reduced_features.ndim == 1:\n",
    "                            # Reshape 1D to 2D\n",
    "                            features_per_step = len(reduced_features) // sample_features.shape[0]\n",
    "                            if features_per_step > 0:\n",
    "                                reduced_features = reduced_features[:features_per_step * sample_features.shape[0]]\n",
    "                                reduced_features = reduced_features.reshape(sample_features.shape[0], features_per_step)\n",
    "                            else:\n",
    "                                reduced_features = np.zeros((sample_features.shape[0], 1))\n",
    "                                reduced_features[0, 0] = reduced_features.mean() if len(reduced_features) > 0 else 0\n",
    "                        \n",
    "                        processed_samples.append(reduced_features)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing sample {i} in attempt {retry_count + 1}: {e}\")\n",
    "                        fallback_features = sample_features[:, :10] if sample_features.shape[1] >= 10 else sample_features\n",
    "                        processed_samples.append(fallback_features)\n",
    "                \n",
    "                # If we get here, the function executed successfully\n",
    "                print(f\"‚úÖ Feature selection applied successfully on attempt {retry_count + 1}\")\n",
    "                return np.array(processed_samples)\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                print(f\"‚ùå Attempt {retry_count} failed with error: {e}\")\n",
    "                if retry_count < max_retries:\n",
    "                    print(f\"üîÑ Retrying... ({retry_count}/{max_retries})\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è All {max_retries} attempts failed, using fallback function\")\n",
    "                    # Use fallback function as last resort\n",
    "                    return self._apply_fallback_feature_selection(X_data)\n",
    "        \n",
    "        return np.array(processed_samples)\n",
    "    \n",
    "    def _apply_fallback_feature_selection(self, X_data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fallback feature selection when all retries fail\n",
    "        \"\"\"\n",
    "        print(\"üÜò Using fallback feature selection...\")\n",
    "        processed_samples = []\n",
    "        \n",
    "        for i in range(X_data.shape[0]):\n",
    "            sample_features = X_data[i]\n",
    "            # Simple fallback: take first 15 features from each timestep\n",
    "            fallback_features = sample_features[:, :15] if sample_features.shape[1] >= 15 else sample_features\n",
    "            processed_samples.append(fallback_features)\n",
    "        \n",
    "        return np.array(processed_samples)\n",
    "\n",
    "print(\"‚úÖ Iterative LLM Feature Selector class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afbe7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced IterativeLLMFeatureSelector with p-value analysis defined!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced IterativeLLMFeatureSelector with p-value analysis\n",
    "class EnhancedIterativeLLMFeatureSelector(IterativeLLMFeatureSelector):\n",
    "    \"\"\"\n",
    "    Enhanced version with p-value analysis and improved prompts\n",
    "    \"\"\"\n",
    "    \n",
    "    def create_iterative_prompt(self, iteration_num: int, previous_results: list, feature_description: str) -> str:\n",
    "        \"\"\"\n",
    "        Create a prompt that includes performance history, p-value analysis, and asks for improvements\n",
    "        \"\"\"\n",
    "        # Build performance history with p-value information\n",
    "        history_text = \"\"\n",
    "        if previous_results:\n",
    "            history_text = \"\\n\\nPERFORMANCE HISTORY:\\n\"\n",
    "            for i, result in enumerate(previous_results):\n",
    "                history_text += f\"Iteration {i}: {result['model_name']} - MAPE: {result['mape']:.2f}%\"\n",
    "                if i > 0:\n",
    "                    improvement = result['improvement']\n",
    "                    history_text += f\" (Improvement: {improvement:+.1f}%)\"\n",
    "                history_text += f\"\\n  Features: {result['features_used']}\\n\"\n",
    "                \n",
    "                # Add p-value analysis if available\n",
    "                if 'feature_stats' in result and result['feature_stats']:\n",
    "                    significant_count = len(result.get('significant_features', []))\n",
    "                    highly_significant_count = len(result.get('highly_significant_features', []))\n",
    "                    total_features = len(result['feature_stats'])\n",
    "                    \n",
    "                    history_text += f\"  Statistical Analysis:\\n\"\n",
    "                    history_text += f\"    ‚Ä¢ Total features: {total_features}\\n\"\n",
    "                    history_text += f\"    ‚Ä¢ Significant features (p < 0.05): {significant_count}\\n\"\n",
    "                    history_text += f\"    ‚Ä¢ Highly significant features (p < 0.01): {highly_significant_count}\\n\"\n",
    "                    \n",
    "                    # Add top significant features\n",
    "                    if result.get('significant_features'):\n",
    "                        top_significant = result['significant_features'][:3]\n",
    "                        history_text += f\"    ‚Ä¢ Top significant features: {', '.join(top_significant)}\\n\"\n",
    "                    \n",
    "                    # Add feature with lowest p-value\n",
    "                    if result['feature_stats']:\n",
    "                        min_pval_feature = min(result['feature_stats'].items(), key=lambda x: x[1]['p_value'])\n",
    "                        history_text += f\"    ‚Ä¢ Most significant feature: {min_pval_feature[0]} (p={min_pval_feature[1]['p_value']:.4f})\\n\"\n",
    "                \n",
    "                history_text += \"\\n\"\n",
    "        \n",
    "        # Get the best performance so far\n",
    "        best_mape = min([r['mape'] for r in previous_results]) if previous_results else 100.0\n",
    "        \n",
    "        # Get statistical insights from the best performing model\n",
    "        best_result = min(previous_results, key=lambda x: x['mape']) if previous_results else None\n",
    "        statistical_insights = \"\"\n",
    "        \n",
    "        if best_result and 'feature_stats' in best_result:\n",
    "            statistical_insights = f\"\"\"\n",
    "STATISTICAL INSIGHTS FROM BEST MODEL (MAPE: {best_result['mape']:.2f}%):\n",
    "- Most predictive features (lowest p-values): {', '.join([f\"{name} (p={stats['p_value']:.4f})\" for name, stats in sorted(best_result['feature_stats'].items(), key=lambda x: x[1]['p_value'])[:5]])}\n",
    "- Least predictive features (highest p-values): {', '.join([f\"{name} (p={stats['p_value']:.4f})\" for name, stats in sorted(best_result['feature_stats'].items(), key=lambda x: x[1]['p_value'], reverse=True)[:3]])}\n",
    "- Feature significance ratio: {len(best_result.get('significant_features', []))}/{len(best_result['feature_stats'])} features are statistically significant\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are a financial data scientist expert in feature engineering for stock prediction models. \n",
    "\n",
    "I have financial time series data with the following structure:\n",
    "- Shape: (samples, lookback_window=4, features=62)\n",
    "- Features at each timestamp T include:\n",
    "  1. Short interest at time T (1 feature)\n",
    "  2. Average daily volume quantity of past 15 days (1 feature) \n",
    "  3. OHLC (Open, High, Low, Close) prices for past 15 days (4 √ó 15 = 60 features)\n",
    "\n",
    "Total: 1 + 1 + 60 = 62 features per timestamp.\n",
    "\n",
    "{history_text}\n",
    "\n",
    "{statistical_insights}\n",
    "\n",
    "CURRENT TASK (Iteration {iteration_num}):\n",
    "Your goal is to create an improved feature engineering function that will achieve better performance than the current best MAPE of {best_mape:.2f}%.\n",
    "\n",
    "Based on the performance history and statistical analysis above, analyze what worked and what didn't, then create a new feature engineering approach that:\n",
    "1. Learns from previous iterations' successes and failures\n",
    "2. Focuses on the most statistically significant and predictive features\n",
    "3. Considers financial domain knowledge (momentum, volatility, volume patterns, etc.)\n",
    "4. Maintains LSTM-compatible time series structure\n",
    "5. Uses p-value insights to prioritize feature construction\n",
    "\n",
    "Requirements:\n",
    "1. Write a function called `construct_features` that takes a numpy array of shape (lookback_window, 62) and returns a numpy array of shape (lookback_window, constructed_features)\n",
    "2. The function should process each timestamp independently but maintain the temporal structure\n",
    "3. Focus on the most predictive features for each time step, using statistical significance as guidance\n",
    "4. Consider financial domain knowledge (e.g., price momentum, volatility, volume patterns, etc.)\n",
    "5. The output should be a 2D numpy array with shape (lookback_window, constructed_features)\n",
    "6. Include comments explaining your feature engineering choices and how they address previous performance issues and statistical insights\n",
    "7. Make sure the code is production-ready and handles edge cases\n",
    "8. DO NOT include any import statements - only use numpy (available as 'np') and built-in Python functions\n",
    "9. The function must return a 2D array where each row represents features for one time step\n",
    "10. Use numpy nan_to_num to handle NaN values\n",
    "\n",
    "Please provide ONLY the Python function code, no explanations outside the code comments.\n",
    "\n",
    "Feature description: {feature_description}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "print(\"‚úÖ Enhanced IterativeLLMFeatureSelector with p-value analysis defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99b4dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Iterative LLM Feature Selector class defined!\n"
     ]
    }
   ],
   "source": [
    "# Define the LLM Feature Selector class (adapted from test.py)\n",
    "class IterativeLLMFeatureSelector:\n",
    "    \"\"\"\n",
    "    An iterative LLM-based feature selector that learns from previous iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, anthropic_api_key: str):\n",
    "        self.client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "        self.iteration_history = []\n",
    "        print(\"‚úÖ Claude API client initialized successfully!\")\n",
    "    \n",
    "    def create_iterative_prompt(self, iteration_num: int, previous_results: list, feature_description: str) -> str:\n",
    "        \"\"\"\n",
    "        Create a prompt that includes performance history and asks for improvements\n",
    "        \"\"\"\n",
    "        # Build performance history\n",
    "        history_text = \"\"\n",
    "        if previous_results:\n",
    "            history_text = \"\\n\\nPERFORMANCE HISTORY:\\n\"\n",
    "            for i, result in enumerate(previous_results):\n",
    "                history_text += f\"Iteration {i}: {result['model_name']} - MAPE: {result['mape']:.2f}%\"\n",
    "                if i > 0:\n",
    "                    improvement = result['improvement']\n",
    "                    history_text += f\" (Improvement: {improvement:+.1f}%)\"\n",
    "                history_text += f\"\\n  Features: {result['features_used']}\\n\"\n",
    "        \n",
    "        # Get the best performance so far\n",
    "        best_mape = min([r['mape'] for r in previous_results]) if previous_results else 100.0\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are a financial data scientist expert in feature engineering for Short Interest prediction models. \n",
    "\n",
    "I have financial time series data with the following structure:\n",
    "- Shape: (samples, lookback_window=4, features=62)\n",
    "- Features at each timestamp T include:\n",
    "  1. Short interest at time T reproted every 15 days (1 feature)\n",
    "  2. Average daily volume quantity of past 15 days (1 feature) \n",
    "  3. OHLC (Open, High, Low, Close) prices for past 15 days (4 √ó 15 = 60 features)\n",
    "\n",
    "Total: 1 + 1 + 60 = 62 features per timestamp.\n",
    "\n",
    "{history_text}\n",
    "\n",
    "CURRENT TASK (Iteration {iteration_num}):\n",
    "Your goal is to create an improved feature engineering function that will achieve better performance than the current best MAPE of {best_mape:.2f}%.\n",
    "\n",
    "Based on the performance history above, analyze what worked and what didn't, then create a new feature engineering approach that:\n",
    "1. Learns from previous iterations' successes and failures\n",
    "2. Focuses on the most predictive features\n",
    "3. Considers financial domain knowledge (momentum, volatility, volume patterns, etc.)\n",
    "4. Maintains LSTM-compatible time series structure\n",
    "\n",
    "Requirements:\n",
    "1. Write a function called `construct_features` that takes a numpy array of shape (lookback_window, 62) and returns a numpy array of shape (lookback_window, constructed_features)\n",
    "2. The function should process each timestamp independently but maintain the temporal structure\n",
    "3. Focus on the most predictive features for each time step\n",
    "4. Consider financial domain knowledge (e.g., price momentum, volatility, volume patterns, etc.)\n",
    "5. The output should be a 2D numpy array with shape (lookback_window, constructed_features)\n",
    "6. Include comments explaining your feature engineering choices and how they address previous performance issues\n",
    "7. Make sure the code is production-ready and handles edge cases\n",
    "8. DO NOT include any import statements - only use numpy (available as 'np') and built-in Python functions\n",
    "9. The function must return a 2D array where each row represents features for one time step\n",
    "10. Use numpy nan_to_num to handle NaN values\n",
    "\n",
    "Please provide ONLY the Python function code, no explanations outside the code comments.\n",
    "\n",
    "Feature description: {feature_description}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def call_claude_for_iterative_improvement(self, iteration_num: int, previous_results: list, feature_description: str = \"Stock prediction with short interest, volume, and OHLC data\") -> str:\n",
    "        \"\"\"\n",
    "        Call Claude API with iterative improvement context\n",
    "        \"\"\"\n",
    "        prompt = self.create_iterative_prompt(iteration_num, previous_results, feature_description)\n",
    "        \n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=2000,\n",
    "                temperature=0.1,  # Slightly higher temperature for creativity in later iterations\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            return response.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Claude API: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_function_from_response(self, response_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the construct_features function from Claude's response\n",
    "        \"\"\"\n",
    "        lines = response_text.split('\\n')\n",
    "        function_lines = []\n",
    "        in_function = False\n",
    "        indent_level = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'def construct_features' in line:\n",
    "                in_function = True\n",
    "                function_lines.append(line)\n",
    "                indent_level = len(line) - len(line.lstrip())\n",
    "            elif in_function:\n",
    "                if line.strip() == '':\n",
    "                    function_lines.append(line)\n",
    "                elif len(line) - len(line.lstrip()) > indent_level or line.strip() == '':\n",
    "                    function_lines.append(line)\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        return '\\n'.join(function_lines)\n",
    "    \n",
    "    def execute_feature_construction_code(self, code: str) -> callable:\n",
    "        \"\"\"\n",
    "        Execute the generated feature construction code and return the function\n",
    "        \"\"\"\n",
    "        try:\n",
    "            exec_globals = {\n",
    "                'np': np,\n",
    "                'pd': pd,\n",
    "                '__builtins__': {\n",
    "                    'len': len, 'range': range, 'enumerate': enumerate, 'zip': zip,\n",
    "                    'sum': sum, 'max': max, 'min': min, 'abs': abs, 'round': round,\n",
    "                    'int': int, 'float': float, 'str': str, 'list': list, 'dict': dict,\n",
    "                    'tuple': tuple, 'set': set, 'print': print, 'any': any, 'all': all,\n",
    "                    'sorted': sorted, 'reversed': reversed, 'isinstance': isinstance,\n",
    "                    'type': type, 'hasattr': hasattr, 'getattr': getattr, 'setattr': setattr,\n",
    "                    'callable': callable, 'issubclass': issubclass, 'super': super,\n",
    "                    'open': open, 'iter': iter, 'next': next, 'map': map, 'filter': filter,\n",
    "                    'pow': pow, 'divmod': divmod, 'bin': bin, 'hex': hex, 'oct': oct,\n",
    "                    'ord': ord, 'chr': chr, 'bool': bool, 'complex': complex,\n",
    "                    'bytes': bytes, 'bytearray': bytearray, 'memoryview': memoryview,\n",
    "                    'slice': slice, 'property': property, 'staticmethod': staticmethod,\n",
    "                    'classmethod': classmethod,\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            exec(code, exec_globals)\n",
    "            \n",
    "            if 'construct_features' in exec_globals:\n",
    "                return exec_globals['construct_features']\n",
    "            else:\n",
    "                raise ValueError(\"construct_features function not found in generated code\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error executing generated code: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def fallback_construct_features(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fallback feature construction function\n",
    "        \"\"\"\n",
    "        if data.shape[1] != 62:\n",
    "            raise ValueError(f\"Expected 62 features, got {data.shape[1]}\")\n",
    "        \n",
    "        lookback_window = data.shape[0]\n",
    "        features_per_timestep = 15\n",
    "        \n",
    "        output = np.zeros((lookback_window, features_per_timestep))\n",
    "        \n",
    "        for t in range(lookback_window):\n",
    "            short_interest = data[t, 0]\n",
    "            volume = data[t, 1]\n",
    "            ohlc = data[t, 2:].reshape(15, 4)\n",
    "            \n",
    "            # Basic features\n",
    "            output[t, 0] = short_interest\n",
    "            output[t, 1] = volume\n",
    "            output[t, 2:6] = ohlc[-1]  # Latest OHLC\n",
    "            \n",
    "            # Momentum features\n",
    "            close_prices = ohlc[:, 3]\n",
    "            for i, horizon in enumerate([1, 3, 5, 10]):\n",
    "                if len(close_prices) > horizon:\n",
    "                    momentum = (close_prices[-1] - close_prices[-horizon-1]) / close_prices[-horizon-1]\n",
    "                    output[t, 6 + i] = momentum\n",
    "                else:\n",
    "                    output[t, 6 + i] = 0\n",
    "            \n",
    "            # Volatility and range\n",
    "            if len(close_prices) > 1:\n",
    "                returns = np.diff(close_prices) / close_prices[:-1]\n",
    "                output[t, 10] = np.std(returns)\n",
    "                output[t, 11] = (np.max(close_prices) - np.min(close_prices)) / np.mean(close_prices)\n",
    "            \n",
    "            # Technical indicators\n",
    "            if len(close_prices) > 1:\n",
    "                sma_5 = np.mean(close_prices[-5:]) if len(close_prices) >= 5 else np.mean(close_prices)\n",
    "                output[t, 12] = close_prices[-1] / sma_5\n",
    "                \n",
    "                high_low_ratio = ohlc[:, 1] / ohlc[:, 2]\n",
    "                output[t, 13] = np.mean(high_low_ratio)\n",
    "                \n",
    "                output[t, 14] = volume * close_prices[-1] / np.mean(close_prices)\n",
    "        \n",
    "        return output.astype(np.float32)\n",
    "    \n",
    "    def apply_feature_selection_to_data(self, X_data: np.ndarray, construct_func: callable, max_retries: int = 5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply feature selection to the entire dataset with retry mechanism\n",
    "        \"\"\"\n",
    "        processed_samples = []\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                processed_samples = []\n",
    "                success = True\n",
    "                \n",
    "                for i in range(X_data.shape[0]):\n",
    "                    sample_features = X_data[i]\n",
    "                    \n",
    "                    try:\n",
    "                        reduced_features = construct_func(sample_features)\n",
    "                        \n",
    "                        if reduced_features.ndim == 1:\n",
    "                            # Reshape 1D to 2D\n",
    "                            features_per_step = len(reduced_features) // sample_features.shape[0]\n",
    "                            if features_per_step > 0:\n",
    "                                reduced_features = reduced_features[:features_per_step * sample_features.shape[0]]\n",
    "                                reduced_features = reduced_features.reshape(sample_features.shape[0], features_per_step)\n",
    "                            else:\n",
    "                                reduced_features = np.zeros((sample_features.shape[0], 1))\n",
    "                                reduced_features[0, 0] = reduced_features.mean() if len(reduced_features) > 0 else 0\n",
    "                        \n",
    "                        processed_samples.append(reduced_features)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing sample {i} in attempt {retry_count + 1}: {e}\")\n",
    "                        fallback_features = sample_features[:, :10] if sample_features.shape[1] >= 10 else sample_features\n",
    "                        processed_samples.append(fallback_features)\n",
    "                \n",
    "                # If we get here, the function executed successfully\n",
    "                print(f\"‚úÖ Feature selection applied successfully on attempt {retry_count + 1}\")\n",
    "                return np.array(processed_samples)\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                print(f\"‚ùå Attempt {retry_count} failed with error: {e}\")\n",
    "                if retry_count < max_retries:\n",
    "                    print(f\"üîÑ Retrying... ({retry_count}/{max_retries})\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è All {max_retries} attempts failed, using fallback function\")\n",
    "                    # Use fallback function as last resort\n",
    "                    return self._apply_fallback_feature_selection(X_data)\n",
    "        \n",
    "        return np.array(processed_samples)\n",
    "    \n",
    "    def _apply_fallback_feature_selection(self, X_data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fallback feature selection when all retries fail\n",
    "        \"\"\"\n",
    "        print(\"üÜò Using fallback feature selection...\")\n",
    "        processed_samples = []\n",
    "        \n",
    "        for i in range(X_data.shape[0]):\n",
    "            sample_features = X_data[i]\n",
    "            # Simple fallback: take first 15 features from each timestep\n",
    "            fallback_features = sample_features[:, :15] if sample_features.shape[1] >= 15 else sample_features\n",
    "            processed_samples.append(fallback_features)\n",
    "        \n",
    "        return np.array(processed_samples)\n",
    "\n",
    "print(\"‚úÖ Iterative LLM Feature Selector class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb9308f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Starting enhanced iterative improvement process...\n",
      "Max iterations: 10\n",
      "Min improvement threshold: 0.1%\n",
      "Patience: 3 iterations without improvement\n",
      "\n",
      "======================================================================\n",
      "ITERATION 1\n",
      "======================================================================\n",
      "ü§ñ Calling Claude for iteration 1 with statistical insights...\n",
      "‚úÖ Claude response received!\n",
      "\n",
      "üìù Claude's Response:\n",
      "--------------------------------------------------\n",
      "```python\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) where 62 = [short_interest, volume, OHLC*15]\n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    features = np.zeros((lookback, 25))  # Output features\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        # Extract core data for current timestamp\n",
      "        short_interest = data[t,0]\n",
      "        volume = data[t,1] \n",
      "        \n",
      "        # Reshape OHLC data (60 values) into (15,4) matrix\n",
      "        ohlc = data[t,2:].reshape(15,4)\n",
      "        opens = ohlc[:,0]\n",
      "        highs = ohlc[:,1]\n",
      "        lows = ohlc[:,2]\n",
      "        closes = ohlc[:,3]\n",
      "        \n",
      "        # 1. Price momentum features\n",
      "        returns = np.diff(closes) / closes[:-1]  # Daily returns\n",
      "        features[t,0] = np.mean(returns)  # Average return\n",
      "        features[t,1] = np.sum(returns > 0) / len(returns)  # Up day ratio\n",
      "        \n",
      "        # 2. Volatility features \n",
      "        true_range = np.maximum(highs - lows, \n",
      "                              np.abs(highs - np.roll(closes, 1)),\n",
      "                              np.abs(lows - np.roll(closes, 1)))\n",
      "        features[t,2] = np.mean(true_range) / np.mean(closes)  # ATR\n",
      "        features[t,3] = np.std(returns)  # Return volatility\n",
      "        \n",
      "        # 3. Price levels & ranges\n",
      "        features[t,4] = (closes[-1] - np.min(lows)) / np.min(lows)  # Price above min\n",
      "        features[t,5] = (np.max(highs) - closes[-1]) / closes[-1]  # Room to high\n",
      "        features[t,6] = (highs - lows).mean() / closes.mean()  # Avg daily range\n",
      "        \n",
      "        # 4. Volume analysis\n",
      "        vol_ma = np.mean(volume)\n",
      "        features[t,7] = volume / vol_ma - 1  # Volume vs average\n",
      "        features[t,8] = np.corrcoef(volume, np.abs(returns))[0,1]  # Vol-return corr\n",
      "        \n",
      "        # 5. Short interest dynamics\n",
      "        features[t,9] = short_interest / volume  # Days to cover\n",
      "        features[t,10] = short_interest / np.mean(volume)  # Relative short interest\n",
      "        \n",
      "        # 6. Technical indicators\n",
      "        sma5 = np.mean(closes[-5:])\n",
      "        sma15 = np.mean(closes)\n",
      "        features[t,11] = closes[-1] / sma5 - 1  # Price vs SMA5\n",
      "        features[t,12] = closes[-1] / sma15 - 1  # Price vs SMA15\n",
      "        features[t,13] = sma5 / sma15 - 1  # SMA crossover\n",
      "        \n",
      "        # 7. Gap analysis\n",
      "        gaps = opens - np.roll(closes, 1)\n",
      "        features[t,14] = np.sum(np.abs(gaps)) / np.mean(closes)  # Gap activity\n",
      "        features[t,15] = np.sum(gaps > 0) / len(gaps)  # Up gap ratio\n",
      "        \n",
      "        # 8. Momentum indicators\n",
      "        roc = (closes[-1] / closes[0] - 1) * 100  # Rate of change\n",
      "        features[t,16] = roc\n",
      "        features[t,17] = np.sum(closes > sma5) / len(closes)  # Above SMA5 ratio\n",
      "        \n",
      "        # 9. Volatility patterns\n",
      "        features[t,18] = np.mean((highs-closes)/(highs-lows))  # Upper shadow ratio\n",
      "        features[t,19] = np.mean((closes-lows)/(highs-lows))  # Lower shadow ratio\n",
      "        \n",
      "        # 10. Price patterns\n",
      "        features[t,20] = np.polyfit(range(len(closes)), closes, 1)[0]  # Price trend\n",
      "        features[t,21] = np.std(highs) / np.mean(highs)  # High volatility\n",
      "        features[t,22] = np.std(lows) / np.mean(lows)  # Low volatility\n",
      "        \n",
      "        # 11. Combined metrics\n",
      "        features[t,23] = features[t,3] * features[t,7]  # Vol-adjusted volatility\n",
      "        features[t,24] = features[t,9] * features[t,4]  # Short-adjusted price level\n",
      "\n",
      "    # Handle any NaN values\n",
      "    features = np.nan_to_num(features, nan=0.0)\n",
      "    \n",
      "    return features\n",
      "```\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß Extracted Function Code:\n",
      "--------------------------------------------------\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) where 62 = [short_interest, volume, OHLC*15]\n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    features = np.zeros((lookback, 25))  # Output features\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        # Extract core data for current timestamp\n",
      "        short_interest = data[t,0]\n",
      "        volume = data[t,1] \n",
      "        \n",
      "        # Reshape OHLC data (60 values) into (15,4) matrix\n",
      "        ohlc = data[t,2:].reshape(15,4)\n",
      "        opens = ohlc[:,0]\n",
      "        highs = ohlc[:,1]\n",
      "        lows = ohlc[:,2]\n",
      "        closes = ohlc[:,3]\n",
      "        \n",
      "        # 1. Price momentum features\n",
      "        returns = np.diff(closes) / closes[:-1]  # Daily returns\n",
      "        features[t,0] = np.mean(returns)  # Average return\n",
      "        features[t,1] = np.sum(returns > 0) / len(returns)  # Up day ratio\n",
      "        \n",
      "        # 2. Volatility features \n",
      "        true_range = np.maximum(highs - lows, \n",
      "                              np.abs(highs - np.roll(closes, 1)),\n",
      "                              np.abs(lows - np.roll(closes, 1)))\n",
      "        features[t,2] = np.mean(true_range) / np.mean(closes)  # ATR\n",
      "        features[t,3] = np.std(returns)  # Return volatility\n",
      "        \n",
      "        # 3. Price levels & ranges\n",
      "        features[t,4] = (closes[-1] - np.min(lows)) / np.min(lows)  # Price above min\n",
      "        features[t,5] = (np.max(highs) - closes[-1]) / closes[-1]  # Room to high\n",
      "        features[t,6] = (highs - lows).mean() / closes.mean()  # Avg daily range\n",
      "        \n",
      "        # 4. Volume analysis\n",
      "        vol_ma = np.mean(volume)\n",
      "        features[t,7] = volume / vol_ma - 1  # Volume vs average\n",
      "        features[t,8] = np.corrcoef(volume, np.abs(returns))[0,1]  # Vol-return corr\n",
      "        \n",
      "        # 5. Short interest dynamics\n",
      "        features[t,9] = short_interest / volume  # Days to cover\n",
      "        features[t,10] = short_interest / np.mean(volume)  # Relative short interest\n",
      "        \n",
      "        # 6. Technical indicators\n",
      "        sma5 = np.mean(closes[-5:])\n",
      "        sma15 = np.mean(closes)\n",
      "        features[t,11] = closes[-1] / sma5 - 1  # Price vs SMA5\n",
      "        features[t,12] = closes[-1] / sma15 - 1  # Price vs SMA15\n",
      "        features[t,13] = sma5 / sma15 - 1  # SMA crossover\n",
      "        \n",
      "        # 7. Gap analysis\n",
      "        gaps = opens - np.roll(closes, 1)\n",
      "        features[t,14] = np.sum(np.abs(gaps)) / np.mean(closes)  # Gap activity\n",
      "        features[t,15] = np.sum(gaps > 0) / len(gaps)  # Up gap ratio\n",
      "        \n",
      "        # 8. Momentum indicators\n",
      "        roc = (closes[-1] / closes[0] - 1) * 100  # Rate of change\n",
      "        features[t,16] = roc\n",
      "        features[t,17] = np.sum(closes > sma5) / len(closes)  # Above SMA5 ratio\n",
      "        \n",
      "        # 9. Volatility patterns\n",
      "        features[t,18] = np.mean((highs-closes)/(highs-lows))  # Upper shadow ratio\n",
      "        features[t,19] = np.mean((closes-lows)/(highs-lows))  # Lower shadow ratio\n",
      "        \n",
      "        # 10. Price patterns\n",
      "        features[t,20] = np.polyfit(range(len(closes)), closes, 1)[0]  # Price trend\n",
      "        features[t,21] = np.std(highs) / np.mean(highs)  # High volatility\n",
      "        features[t,22] = np.std(lows) / np.mean(lows)  # Low volatility\n",
      "        \n",
      "        # 11. Combined metrics\n",
      "        features[t,23] = features[t,3] * features[t,7]  # Vol-adjusted volatility\n",
      "        features[t,24] = features[t,9] * features[t,4]  # Short-adjusted price level\n",
      "\n",
      "    # Handle any NaN values\n",
      "    features = np.nan_to_num(features, nan=0.0)\n",
      "    \n",
      "    return features\n",
      "--------------------------------------------------\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üîß Applying feature selection using claude function with retry mechanism...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "apply_feature_selection_to_data() got an unexpected keyword argument 'max_retries'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Apply feature selection to data with retry mechanism\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîß Applying feature selection using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m function with retry mechanism...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m X_train_processed \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_feature_selection_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstruct_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m X_test_processed \u001b[38;5;241m=\u001b[39m feature_selector\u001b[38;5;241m.\u001b[39mapply_feature_selection_to_data(X_test_raw, construct_func, max_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_raw\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_processed\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: apply_feature_selection_to_data() got an unexpected keyword argument 'max_retries'"
     ]
    }
   ],
   "source": [
    "# Updated iterative improvement loop with enhanced features\n",
    "print(f\"\\nüîÑ Starting enhanced iterative improvement process...\")\n",
    "print(f\"Max iterations: {max_iterations}\")\n",
    "print(f\"Min improvement threshold: {min_improvement_threshold}%\")\n",
    "print(f\"Patience: {patience} iterations without improvement\")\n",
    "\n",
    "best_mape = baseline_mape\n",
    "iterations_without_improvement = 0\n",
    "\n",
    "for iteration in range(1, max_iterations + 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ITERATION {iteration}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Get feature engineering code from Claude with p-value insights\n",
    "    print(f\"ü§ñ Calling Claude for iteration {iteration} with statistical insights...\")\n",
    "    claude_response = feature_selector.call_claude_for_iterative_improvement(\n",
    "        iteration, iteration_results, \n",
    "        \"Stock prediction with short interest, volume, and OHLC data for iterative improvement\"\n",
    "    )\n",
    "    \n",
    "    if not claude_response:\n",
    "        print(\"‚ùå No response from Claude, using fallback\")\n",
    "        construct_func = feature_selector.fallback_construct_features\n",
    "        function_source = \"fallback\"\n",
    "        claude_code = None\n",
    "    else:\n",
    "        print(\"‚úÖ Claude response received!\")\n",
    "        print(f\"\\nüìù Claude's Response:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(claude_response)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Extract and execute the function\n",
    "        function_code = feature_selector.extract_function_from_response(claude_response)\n",
    "        print(f\"\\nüîß Extracted Function Code:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(function_code)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        construct_func = feature_selector.execute_feature_construction_code(function_code)\n",
    "        \n",
    "        if construct_func:\n",
    "            print(\"‚úÖ Function executed successfully!\")\n",
    "            function_source = \"claude\"\n",
    "            claude_code = function_code\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Function execution failed, using fallback\")\n",
    "            construct_func = feature_selector.fallback_construct_features\n",
    "            function_source = \"fallback\"\n",
    "            claude_code = None\n",
    "    \n",
    "    # Apply feature selection to data with retry mechanism\n",
    "    print(f\"\\nüîß Applying feature selection using {function_source} function with retry mechanism...\")\n",
    "    X_train_processed = feature_selector.apply_feature_selection_to_data(X_train_raw, construct_func, max_retries=5)\n",
    "    X_test_processed = feature_selector.apply_feature_selection_to_data(X_test_raw, construct_func, max_retries=5)\n",
    "    \n",
    "    print(f\"Training data shape: {X_train_raw.shape} -> {X_train_processed.shape}\")\n",
    "    print(f\"Test data shape: {X_test_raw.shape} -> {X_test_processed.shape}\")\n",
    "    \n",
    "    # Train and evaluate the model with p-value analysis\n",
    "    iteration_results_model = train_and_evaluate_model(\n",
    "        X_train_processed, X_test_processed, y_train, y_test, prev_log_test,\n",
    "        model_name=f\"Iteration {iteration} ({function_source})\", epochs=50\n",
    "    )\n",
    "    \n",
    "    # Calculate improvement\n",
    "    improvement = best_mape - iteration_results_model['mape']\n",
    "    \n",
    "    # Store results with p-value information\n",
    "    iteration_results.append({\n",
    "        'iteration': iteration,\n",
    "        'model_name': f'Iteration {iteration}',\n",
    "        'features_used': f'{function_source} feature engineering',\n",
    "        'feature_count': X_train_processed.shape[2],\n",
    "        'mape': iteration_results_model['mape'],\n",
    "        'mae': iteration_results_model['mae'],\n",
    "        'rmse': iteration_results_model['rmse'],\n",
    "        'improvement': improvement,\n",
    "        'predictions': iteration_results_model['predictions'],\n",
    "        'claude_code': claude_code,\n",
    "        'function_source': function_source,\n",
    "        'feature_stats': iteration_results_model.get('feature_stats', {}),\n",
    "        'significant_features': iteration_results_model.get('significant_features', []),\n",
    "        'highly_significant_features': iteration_results_model.get('highly_significant_features', []),\n",
    "        'p_values': iteration_results_model.get('p_values', []),\n",
    "        'coefficients': iteration_results_model.get('coefficients', [])\n",
    "    })\n",
    "    \n",
    "    # Check for improvement\n",
    "    if improvement > min_improvement_threshold:\n",
    "        print(f\"üéâ IMPROVEMENT! MAPE improved by {improvement:.2f}%\")\n",
    "        best_mape = iteration_results_model['mape']\n",
    "        iterations_without_improvement = 0\n",
    "    else:\n",
    "        print(f\"üìä No significant improvement. Change: {improvement:+.2f}%\")\n",
    "        iterations_without_improvement += 1\n",
    "    \n",
    "    # Check stopping criteria\n",
    "    if iterations_without_improvement >= patience:\n",
    "        print(f\"\\nüõë Stopping: No improvement for {patience} consecutive iterations\")\n",
    "        break\n",
    "    \n",
    "    print(f\"\\nüìà Current best MAPE: {best_mape:.2f}%\")\n",
    "    print(f\"üîÑ Iterations without improvement: {iterations_without_improvement}/{patience}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Enhanced iterative process completed!\")\n",
    "print(f\"üèÜ Final best MAPE: {best_mape:.2f}%\")\n",
    "print(f\"üìä Total iterations: {len(iteration_results) - 1}\")  # -1 for baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Performance Analysis and Summary with P-value Information\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENHANCED PERFORMANCE ANALYSIS AND SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create enhanced performance summary DataFrame\n",
    "performance_data = []\n",
    "for result in iteration_results:\n",
    "    significant_count = len(result.get('significant_features', []))\n",
    "    highly_significant_count = len(result.get('highly_significant_features', []))\n",
    "    \n",
    "    performance_data.append({\n",
    "        'Iteration': result['iteration'],\n",
    "        'Model': result['model_name'],\n",
    "        'Features': result['feature_count'],\n",
    "        'MAPE (%)': result['mape'],\n",
    "        'MAE': result['mae'],\n",
    "        'RMSE': result['rmse'],\n",
    "        'Improvement (%)': result['improvement'],\n",
    "        'Source': result.get('function_source', 'baseline'),\n",
    "        'Significant Features': significant_count,\n",
    "        'Highly Significant': highly_significant_count\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "print(\"\\nüìä ENHANCED PERFORMANCE SUMMARY TABLE:\")\n",
    "print(\"=\"*70)\n",
    "print(performance_df.round(4).to_string(index=False))\n",
    "\n",
    "# Find best performing model\n",
    "best_result = min(iteration_results, key=lambda x: x['mape'])\n",
    "print(f\"\\nüèÜ BEST PERFORMING MODEL:\")\n",
    "print(f\"   Model: {best_result['model_name']}\")\n",
    "print(f\"   MAPE: {best_result['mape']:.2f}%\")\n",
    "print(f\"   MAE: {best_result['mae']:.4f}\")\n",
    "print(f\"   RMSE: {best_result['rmse']:.4f}\")\n",
    "print(f\"   Features: {best_result['feature_count']}\")\n",
    "print(f\"   Source: {best_result.get('function_source', 'baseline')}\")\n",
    "\n",
    "# Statistical significance analysis\n",
    "if 'feature_stats' in best_result and best_result['feature_stats']:\n",
    "    print(f\"\\nüìà STATISTICAL SIGNIFICANCE ANALYSIS:\")\n",
    "    print(f\"   ‚Ä¢ Total features: {len(best_result['feature_stats'])}\")\n",
    "    print(f\"   ‚Ä¢ Significant features (p < 0.05): {len(best_result.get('significant_features', []))}\")\n",
    "    print(f\"   ‚Ä¢ Highly significant features (p < 0.01): {len(best_result.get('highly_significant_features', []))}\")\n",
    "    \n",
    "    # Show top 5 most significant features\n",
    "    if best_result['feature_stats']:\n",
    "        sorted_features = sorted(best_result['feature_stats'].items(), key=lambda x: x[1]['p_value'])\n",
    "        print(f\"\\nüîç TOP 5 MOST SIGNIFICANT FEATURES:\")\n",
    "        for i, (name, stats) in enumerate(sorted_features[:5]):\n",
    "            significance = \"***\" if stats['p_value'] < 0.001 else \"**\" if stats['p_value'] < 0.01 else \"*\" if stats['p_value'] < 0.05 else \"\"\n",
    "            print(f\"   {i+1}. {name}: p={stats['p_value']:.4f} {significance}\")\n",
    "\n",
    "# Calculate total improvement\n",
    "total_improvement = baseline_mape - best_result['mape']\n",
    "improvement_percentage = (total_improvement / baseline_mape) * 100\n",
    "\n",
    "print(f\"\\nüìà OVERALL IMPROVEMENT:\")\n",
    "print(f\"   Baseline MAPE: {baseline_mape:.2f}%\")\n",
    "print(f\"   Best MAPE: {best_result['mape']:.2f}%\")\n",
    "print(f\"   Total Improvement: {total_improvement:.2f}% ({improvement_percentage:.1f}% relative)\")\n",
    "\n",
    "# Feature reduction analysis\n",
    "baseline_features = iteration_results[0]['feature_count']\n",
    "best_features = best_result['feature_count']\n",
    "feature_reduction = ((baseline_features - best_features) / baseline_features) * 100\n",
    "\n",
    "print(f\"\\nüîß FEATURE REDUCTION:\")\n",
    "print(f\"   Baseline features: {baseline_features}\")\n",
    "print(f\"   Best model features: {best_features}\")\n",
    "print(f\"   Feature reduction: {feature_reduction:.1f}%\")\n",
    "\n",
    "# Iteration efficiency\n",
    "successful_iterations = len([r for r in iteration_results[1:] if r['improvement'] > 0])\n",
    "total_iterations = len(iteration_results) - 1\n",
    "efficiency = (successful_iterations / total_iterations) * 100 if total_iterations > 0 else 0\n",
    "\n",
    "print(f\"\\n‚ö° ITERATION EFFICIENCY:\")\n",
    "print(f\"   Total iterations: {total_iterations}\")\n",
    "print(f\"   Successful improvements: {successful_iterations}\")\n",
    "print(f\"   Success rate: {efficiency:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e3c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Claude API client initialized successfully!\n",
      "\n",
      "üîÑ Starting iterative improvement process...\n",
      "Max iterations: 10\n",
      "Min improvement threshold: 0.1%\n",
      "Patience: 3 iterations without improvement\n",
      "\n",
      "======================================================================\n",
      "ITERATION 1\n",
      "======================================================================\n",
      "ü§ñ Calling Claude for iteration 1...\n",
      "‚úÖ Claude response received!\n",
      "\n",
      "üìù Claude's Response:\n",
      "--------------------------------------------------\n",
      "```python\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs engineered features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]\n",
      "    volume = data[:, 1] \n",
      "    \n",
      "    # Reshape OHLC data: (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    # Initialize output array\n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        t_features = []\n",
      "        \n",
      "        # 1. Core features\n",
      "        t_features.append(short_interest[t])\n",
      "        t_features.append(volume[t])\n",
      "        \n",
      "        # 2. Price action features\n",
      "        daily_returns = (ohlc[t, :, 3] - ohlc[t, :, 0]) / ohlc[t, :, 0]  # (Close - Open)/Open\n",
      "        t_features.append(np.mean(daily_returns))\n",
      "        t_features.append(np.std(daily_returns))\n",
      "        \n",
      "        # 3. Volatility features\n",
      "        true_range = np.maximum(\n",
      "            ohlc[t, :, 1] - ohlc[t, :, 2],  # High - Low\n",
      "            np.abs(ohlc[t, :, 1] - ohlc[t, :, 3]),  # |High - Close|\n",
      "            np.abs(ohlc[t, :, 2] - ohlc[t, :, 3])   # |Low - Close|\n",
      "        )\n",
      "        atr = np.mean(true_range)\n",
      "        t_features.append(atr)\n",
      "        \n",
      "        # 4. Price momentum \n",
      "        close_prices = ohlc[t, :, 3]\n",
      "        momentum_5 = (close_prices[-1] - close_prices[-5])/close_prices[-5]\n",
      "        momentum_15 = (close_prices[-1] - close_prices[0])/close_prices[0]\n",
      "        t_features.extend([momentum_5, momentum_15])\n",
      "        \n",
      "        # 5. Volume profile\n",
      "        vol_ma5 = np.mean(volume[max(0, t-5):t+1])\n",
      "        vol_ma15 = np.mean(volume[max(0, t-15):t+1]) \n",
      "        t_features.extend([vol_ma5/vol_ma15])\n",
      "        \n",
      "        # 6. Price levels\n",
      "        support = np.percentile(close_prices, 25)\n",
      "        resistance = np.percentile(close_prices, 75)\n",
      "        curr_price = close_prices[-1]\n",
      "        price_position = (curr_price - support)/(resistance - support)\n",
      "        t_features.append(price_position)\n",
      "        \n",
      "        # 7. Candlestick patterns\n",
      "        body_sizes = np.abs(ohlc[t, :, 3] - ohlc[t, :, 0])/ohlc[t, :, 0]  # |Close - Open|/Open\n",
      "        upper_shadows = (ohlc[t, :, 1] - np.maximum(ohlc[t, :, 0], ohlc[t, :, 3]))/ohlc[t, :, 0]\n",
      "        lower_shadows = (np.minimum(ohlc[t, :, 0], ohlc[t, :, 3]) - ohlc[t, :, 2])/ohlc[t, :, 0]\n",
      "        \n",
      "        t_features.extend([\n",
      "            np.mean(body_sizes),\n",
      "            np.mean(upper_shadows),\n",
      "            np.mean(lower_shadows)\n",
      "        ])\n",
      "        \n",
      "        features.append(t_features)\n",
      "    \n",
      "    features = np.array(features)\n",
      "    \n",
      "    # Handle NaN/inf values\n",
      "    features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
      "    \n",
      "    return features\n",
      "```\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß Extracted Function Code:\n",
      "--------------------------------------------------\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs engineered features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]\n",
      "    volume = data[:, 1] \n",
      "    \n",
      "    # Reshape OHLC data: (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    # Initialize output array\n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        t_features = []\n",
      "        \n",
      "        # 1. Core features\n",
      "        t_features.append(short_interest[t])\n",
      "        t_features.append(volume[t])\n",
      "        \n",
      "        # 2. Price action features\n",
      "        daily_returns = (ohlc[t, :, 3] - ohlc[t, :, 0]) / ohlc[t, :, 0]  # (Close - Open)/Open\n",
      "        t_features.append(np.mean(daily_returns))\n",
      "        t_features.append(np.std(daily_returns))\n",
      "        \n",
      "        # 3. Volatility features\n",
      "        true_range = np.maximum(\n",
      "            ohlc[t, :, 1] - ohlc[t, :, 2],  # High - Low\n",
      "            np.abs(ohlc[t, :, 1] - ohlc[t, :, 3]),  # |High - Close|\n",
      "            np.abs(ohlc[t, :, 2] - ohlc[t, :, 3])   # |Low - Close|\n",
      "        )\n",
      "        atr = np.mean(true_range)\n",
      "        t_features.append(atr)\n",
      "        \n",
      "        # 4. Price momentum \n",
      "        close_prices = ohlc[t, :, 3]\n",
      "        momentum_5 = (close_prices[-1] - close_prices[-5])/close_prices[-5]\n",
      "        momentum_15 = (close_prices[-1] - close_prices[0])/close_prices[0]\n",
      "        t_features.extend([momentum_5, momentum_15])\n",
      "        \n",
      "        # 5. Volume profile\n",
      "        vol_ma5 = np.mean(volume[max(0, t-5):t+1])\n",
      "        vol_ma15 = np.mean(volume[max(0, t-15):t+1]) \n",
      "        t_features.extend([vol_ma5/vol_ma15])\n",
      "        \n",
      "        # 6. Price levels\n",
      "        support = np.percentile(close_prices, 25)\n",
      "        resistance = np.percentile(close_prices, 75)\n",
      "        curr_price = close_prices[-1]\n",
      "        price_position = (curr_price - support)/(resistance - support)\n",
      "        t_features.append(price_position)\n",
      "        \n",
      "        # 7. Candlestick patterns\n",
      "        body_sizes = np.abs(ohlc[t, :, 3] - ohlc[t, :, 0])/ohlc[t, :, 0]  # |Close - Open|/Open\n",
      "        upper_shadows = (ohlc[t, :, 1] - np.maximum(ohlc[t, :, 0], ohlc[t, :, 3]))/ohlc[t, :, 0]\n",
      "        lower_shadows = (np.minimum(ohlc[t, :, 0], ohlc[t, :, 3]) - ohlc[t, :, 2])/ohlc[t, :, 0]\n",
      "        \n",
      "        t_features.extend([\n",
      "            np.mean(body_sizes),\n",
      "            np.mean(upper_shadows),\n",
      "            np.mean(lower_shadows)\n",
      "        ])\n",
      "        \n",
      "        features.append(t_features)\n",
      "    \n",
      "    features = np.array(features)\n",
      "    \n",
      "    # Handle NaN/inf values\n",
      "    features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
      "    \n",
      "    return features\n",
      "--------------------------------------------------\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üîß Applying feature selection using claude function...\n",
      "Training data shape: (142, 4, 62) -> (142, 4, 12)\n",
      "Test data shape: (36, 4, 62) -> (36, 4, 12)\n",
      "\n",
      "==================================================\n",
      "Training Iteration 1 (claude)\n",
      "==================================================\n",
      "Epoch 1/50, Train Loss: 0.021551\n",
      "Epoch 11/50, Train Loss: 0.014016\n",
      "Epoch 21/50, Train Loss: 0.011734\n",
      "Epoch 31/50, Train Loss: 0.009888\n",
      "Epoch 41/50, Train Loss: 0.009151\n",
      "\n",
      "Iteration 1 (claude) Performance:\n",
      "MAE: 9154671.5988\n",
      "RMSE: 11890581.6519\n",
      "MAPE: 10.63%\n",
      "üìä No significant improvement. Change: -1.26%\n",
      "\n",
      "üìà Current best MAPE: 9.37%\n",
      "üîÑ Iterations without improvement: 1/3\n",
      "\n",
      "======================================================================\n",
      "ITERATION 2\n",
      "======================================================================\n",
      "ü§ñ Calling Claude for iteration 2...\n",
      "‚úÖ Claude response received!\n",
      "\n",
      "üìù Claude's Response:\n",
      "--------------------------------------------------\n",
      "```python\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]\n",
      "    volume = data[:, 1] \n",
      "    \n",
      "    # Reshape OHLC data: (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        # Current time features\n",
      "        curr_features = []\n",
      "        \n",
      "        # 1. Short Interest Features\n",
      "        curr_features.append(short_interest[t])\n",
      "        if t > 0:\n",
      "            si_change = (short_interest[t] - short_interest[t-1])/short_interest[t-1]\n",
      "            curr_features.append(si_change)\n",
      "        else:\n",
      "            curr_features.append(0)\n",
      "            \n",
      "        # 2. Volume Features\n",
      "        curr_features.append(volume[t])\n",
      "        vol_ma5 = np.mean(volume[max(0,t-5):t+1])\n",
      "        vol_ma15 = np.mean(volume[max(0,t-15):t+1])\n",
      "        curr_features.extend([vol_ma5, vol_ma15])\n",
      "        \n",
      "        # 3. Price Features\n",
      "        curr_ohlc = ohlc[t]\n",
      "        \n",
      "        # Basic price levels\n",
      "        close = curr_ohlc[:, 3]\n",
      "        high = curr_ohlc[:, 1] \n",
      "        low = curr_ohlc[:, 2]\n",
      "        \n",
      "        # Price momentum\n",
      "        returns = np.diff(close)/close[:-1]\n",
      "        momentum_1d = returns[-1] if len(returns) > 0 else 0\n",
      "        momentum_5d = np.mean(returns[-5:]) if len(returns) >= 5 else np.mean(returns)\n",
      "        momentum_15d = np.mean(returns) \n",
      "        curr_features.extend([momentum_1d, momentum_5d, momentum_15d])\n",
      "        \n",
      "        # Volatility \n",
      "        true_range = np.maximum(high - low,\n",
      "                              np.abs(high - np.roll(close, 1)),\n",
      "                              np.abs(low - np.roll(close, 1)))\n",
      "        atr = np.mean(true_range)\n",
      "        vol = np.std(returns)\n",
      "        curr_features.extend([atr, vol])\n",
      "        \n",
      "        # Price levels\n",
      "        typical_price = (high + low + close)/3\n",
      "        tp_ma5 = np.mean(typical_price[-5:])\n",
      "        tp_ma15 = np.mean(typical_price)\n",
      "        curr_features.extend([tp_ma5, tp_ma15])\n",
      "        \n",
      "        # 4. Technical Indicators\n",
      "        # RSI\n",
      "        gains = np.where(returns > 0, returns, 0)\n",
      "        losses = np.where(returns < 0, -returns, 0)\n",
      "        avg_gain = np.mean(gains)\n",
      "        avg_loss = np.mean(losses)\n",
      "        rs = avg_gain/(avg_loss + 1e-9)\n",
      "        rsi = 100 - (100/(1 + rs))\n",
      "        curr_features.append(rsi)\n",
      "        \n",
      "        # Bollinger Bands\n",
      "        ma20 = np.mean(close)\n",
      "        std20 = np.std(close)\n",
      "        bb_upper = ma20 + 2*std20\n",
      "        bb_lower = ma20 - 2*std20\n",
      "        bb_width = (bb_upper - bb_lower)/ma20\n",
      "        curr_features.extend([bb_width])\n",
      "        \n",
      "        # Add features for current timestamp\n",
      "        features.append(np.nan_to_num(curr_features))\n",
      "        \n",
      "    return np.array(features)\n",
      "```\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß Extracted Function Code:\n",
      "--------------------------------------------------\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]\n",
      "    volume = data[:, 1] \n",
      "    \n",
      "    # Reshape OHLC data: (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        # Current time features\n",
      "        curr_features = []\n",
      "        \n",
      "        # 1. Short Interest Features\n",
      "        curr_features.append(short_interest[t])\n",
      "        if t > 0:\n",
      "            si_change = (short_interest[t] - short_interest[t-1])/short_interest[t-1]\n",
      "            curr_features.append(si_change)\n",
      "        else:\n",
      "            curr_features.append(0)\n",
      "            \n",
      "        # 2. Volume Features\n",
      "        curr_features.append(volume[t])\n",
      "        vol_ma5 = np.mean(volume[max(0,t-5):t+1])\n",
      "        vol_ma15 = np.mean(volume[max(0,t-15):t+1])\n",
      "        curr_features.extend([vol_ma5, vol_ma15])\n",
      "        \n",
      "        # 3. Price Features\n",
      "        curr_ohlc = ohlc[t]\n",
      "        \n",
      "        # Basic price levels\n",
      "        close = curr_ohlc[:, 3]\n",
      "        high = curr_ohlc[:, 1] \n",
      "        low = curr_ohlc[:, 2]\n",
      "        \n",
      "        # Price momentum\n",
      "        returns = np.diff(close)/close[:-1]\n",
      "        momentum_1d = returns[-1] if len(returns) > 0 else 0\n",
      "        momentum_5d = np.mean(returns[-5:]) if len(returns) >= 5 else np.mean(returns)\n",
      "        momentum_15d = np.mean(returns) \n",
      "        curr_features.extend([momentum_1d, momentum_5d, momentum_15d])\n",
      "        \n",
      "        # Volatility \n",
      "        true_range = np.maximum(high - low,\n",
      "                              np.abs(high - np.roll(close, 1)),\n",
      "                              np.abs(low - np.roll(close, 1)))\n",
      "        atr = np.mean(true_range)\n",
      "        vol = np.std(returns)\n",
      "        curr_features.extend([atr, vol])\n",
      "        \n",
      "        # Price levels\n",
      "        typical_price = (high + low + close)/3\n",
      "        tp_ma5 = np.mean(typical_price[-5:])\n",
      "        tp_ma15 = np.mean(typical_price)\n",
      "        curr_features.extend([tp_ma5, tp_ma15])\n",
      "        \n",
      "        # 4. Technical Indicators\n",
      "        # RSI\n",
      "        gains = np.where(returns > 0, returns, 0)\n",
      "        losses = np.where(returns < 0, -returns, 0)\n",
      "        avg_gain = np.mean(gains)\n",
      "        avg_loss = np.mean(losses)\n",
      "        rs = avg_gain/(avg_loss + 1e-9)\n",
      "        rsi = 100 - (100/(1 + rs))\n",
      "        curr_features.append(rsi)\n",
      "        \n",
      "        # Bollinger Bands\n",
      "        ma20 = np.mean(close)\n",
      "        std20 = np.std(close)\n",
      "        bb_upper = ma20 + 2*std20\n",
      "        bb_lower = ma20 - 2*std20\n",
      "        bb_width = (bb_upper - bb_lower)/ma20\n",
      "        curr_features.extend([bb_width])\n",
      "        \n",
      "        # Add features for current timestamp\n",
      "        features.append(np.nan_to_num(curr_features))\n",
      "        \n",
      "    return np.array(features)\n",
      "--------------------------------------------------\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üîß Applying feature selection using claude function...\n",
      "Training data shape: (142, 4, 62) -> (142, 4, 14)\n",
      "Test data shape: (36, 4, 62) -> (36, 4, 14)\n",
      "\n",
      "==================================================\n",
      "Training Iteration 2 (claude)\n",
      "==================================================\n",
      "Epoch 1/50, Train Loss: 0.016611\n",
      "Epoch 11/50, Train Loss: 0.012763\n",
      "Epoch 21/50, Train Loss: 0.011412\n",
      "Epoch 31/50, Train Loss: 0.008679\n",
      "Epoch 41/50, Train Loss: 0.004313\n",
      "\n",
      "Iteration 2 (claude) Performance:\n",
      "MAE: 7631902.2234\n",
      "RMSE: 9856147.3296\n",
      "MAPE: 9.21%\n",
      "üéâ IMPROVEMENT! MAPE improved by 0.17%\n",
      "\n",
      "üìà Current best MAPE: 9.21%\n",
      "üîÑ Iterations without improvement: 0/3\n",
      "\n",
      "======================================================================\n",
      "ITERATION 3\n",
      "======================================================================\n",
      "ü§ñ Calling Claude for iteration 3...\n",
      "‚úÖ Claude response received!\n",
      "\n",
      "üìù Claude's Response:\n",
      "--------------------------------------------------\n",
      "```python\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) where 62 = [short_interest, volume, OHLC*15]\n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    features = []\n",
      "\n",
      "    for t in range(lookback):\n",
      "        # Extract core data for current timestamp\n",
      "        short_interest = data[t,0]\n",
      "        volume = data[t,1] \n",
      "        ohlc = data[t,2:].reshape(15,4) # Reshape to (15,4) for 15 days of OHLC\n",
      "        \n",
      "        timestamp_features = []\n",
      "        \n",
      "        # 1. Core metrics\n",
      "        timestamp_features.append(short_interest)\n",
      "        timestamp_features.append(volume)\n",
      "        \n",
      "        # 2. Price action features\n",
      "        typical_price = np.mean(ohlc[:,[1,2,3]], axis=1) # (H+L+C)/3\n",
      "        \n",
      "        # Moving averages (5,10,15 day)\n",
      "        ma5 = np.mean(typical_price[-5:])\n",
      "        ma10 = np.mean(typical_price[-10:])\n",
      "        ma15 = np.mean(typical_price)\n",
      "        timestamp_features.extend([ma5, ma10, ma15])\n",
      "        \n",
      "        # 3. Volatility metrics\n",
      "        daily_returns = np.diff(typical_price)/typical_price[:-1]\n",
      "        volatility = np.std(daily_returns)\n",
      "        high_low_ratio = np.mean(ohlc[:,1]/ohlc[:,2]) # Average H/L ratio\n",
      "        timestamp_features.extend([volatility, high_low_ratio])\n",
      "        \n",
      "        # 4. Volume analysis \n",
      "        vol_ma5 = np.mean(volume[-5:])\n",
      "        vol_ma15 = np.mean(volume)\n",
      "        vol_ratio = volume/vol_ma15 # Volume vs 15d average\n",
      "        timestamp_features.extend([vol_ma5, vol_ma15, vol_ratio])\n",
      "        \n",
      "        # 5. Price momentum\n",
      "        mom5 = (typical_price[-1] - typical_price[-5])/typical_price[-5]\n",
      "        mom10 = (typical_price[-1] - typical_price[-10])/typical_price[-10]\n",
      "        mom15 = (typical_price[-1] - typical_price[0])/typical_price[0]\n",
      "        timestamp_features.extend([mom5, mom10, mom15])\n",
      "        \n",
      "        # 6. Technical indicators\n",
      "        # RSI-14\n",
      "        gains = np.maximum(daily_returns, 0)\n",
      "        losses = np.abs(np.minimum(daily_returns, 0))\n",
      "        avg_gain = np.mean(gains)\n",
      "        avg_loss = np.mean(losses)\n",
      "        rs = avg_gain/(avg_loss + 1e-7)\n",
      "        rsi = 100 - (100/(1 + rs))\n",
      "        timestamp_features.append(rsi)\n",
      "        \n",
      "        # 7. Gap analysis\n",
      "        overnight_gaps = ohlc[1:,0] - ohlc[:-1,3] # Open - Previous Close\n",
      "        avg_gap = np.mean(np.abs(overnight_gaps))\n",
      "        timestamp_features.append(avg_gap)\n",
      "\n",
      "        features.append(timestamp_features)\n",
      "\n",
      "    features = np.array(features)\n",
      "    # Handle any NaN values\n",
      "    features = np.nan_to_num(features, nan=0.0)\n",
      "    \n",
      "    return features\n",
      "```\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß Extracted Function Code:\n",
      "--------------------------------------------------\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) where 62 = [short_interest, volume, OHLC*15]\n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    features = []\n",
      "\n",
      "    for t in range(lookback):\n",
      "        # Extract core data for current timestamp\n",
      "        short_interest = data[t,0]\n",
      "        volume = data[t,1] \n",
      "        ohlc = data[t,2:].reshape(15,4) # Reshape to (15,4) for 15 days of OHLC\n",
      "        \n",
      "        timestamp_features = []\n",
      "        \n",
      "        # 1. Core metrics\n",
      "        timestamp_features.append(short_interest)\n",
      "        timestamp_features.append(volume)\n",
      "        \n",
      "        # 2. Price action features\n",
      "        typical_price = np.mean(ohlc[:,[1,2,3]], axis=1) # (H+L+C)/3\n",
      "        \n",
      "        # Moving averages (5,10,15 day)\n",
      "        ma5 = np.mean(typical_price[-5:])\n",
      "        ma10 = np.mean(typical_price[-10:])\n",
      "        ma15 = np.mean(typical_price)\n",
      "        timestamp_features.extend([ma5, ma10, ma15])\n",
      "        \n",
      "        # 3. Volatility metrics\n",
      "        daily_returns = np.diff(typical_price)/typical_price[:-1]\n",
      "        volatility = np.std(daily_returns)\n",
      "        high_low_ratio = np.mean(ohlc[:,1]/ohlc[:,2]) # Average H/L ratio\n",
      "        timestamp_features.extend([volatility, high_low_ratio])\n",
      "        \n",
      "        # 4. Volume analysis \n",
      "        vol_ma5 = np.mean(volume[-5:])\n",
      "        vol_ma15 = np.mean(volume)\n",
      "        vol_ratio = volume/vol_ma15 # Volume vs 15d average\n",
      "        timestamp_features.extend([vol_ma5, vol_ma15, vol_ratio])\n",
      "        \n",
      "        # 5. Price momentum\n",
      "        mom5 = (typical_price[-1] - typical_price[-5])/typical_price[-5]\n",
      "        mom10 = (typical_price[-1] - typical_price[-10])/typical_price[-10]\n",
      "        mom15 = (typical_price[-1] - typical_price[0])/typical_price[0]\n",
      "        timestamp_features.extend([mom5, mom10, mom15])\n",
      "        \n",
      "        # 6. Technical indicators\n",
      "        # RSI-14\n",
      "        gains = np.maximum(daily_returns, 0)\n",
      "        losses = np.abs(np.minimum(daily_returns, 0))\n",
      "        avg_gain = np.mean(gains)\n",
      "        avg_loss = np.mean(losses)\n",
      "        rs = avg_gain/(avg_loss + 1e-7)\n",
      "        rsi = 100 - (100/(1 + rs))\n",
      "        timestamp_features.append(rsi)\n",
      "        \n",
      "        # 7. Gap analysis\n",
      "        overnight_gaps = ohlc[1:,0] - ohlc[:-1,3] # Open - Previous Close\n",
      "        avg_gap = np.mean(np.abs(overnight_gaps))\n",
      "        timestamp_features.append(avg_gap)\n",
      "\n",
      "        features.append(timestamp_features)\n",
      "\n",
      "    features = np.array(features)\n",
      "    # Handle any NaN values\n",
      "    features = np.nan_to_num(features, nan=0.0)\n",
      "    \n",
      "    return features\n",
      "--------------------------------------------------\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üîß Applying feature selection using claude function...\n",
      "Error processing sample 0: invalid index to scalar variable.\n",
      "Error processing sample 1: invalid index to scalar variable.\n",
      "Error processing sample 2: invalid index to scalar variable.\n",
      "Error processing sample 3: invalid index to scalar variable.\n",
      "Error processing sample 4: invalid index to scalar variable.\n",
      "Error processing sample 5: invalid index to scalar variable.\n",
      "Error processing sample 6: invalid index to scalar variable.\n",
      "Error processing sample 7: invalid index to scalar variable.\n",
      "Error processing sample 8: invalid index to scalar variable.\n",
      "Error processing sample 9: invalid index to scalar variable.\n",
      "Error processing sample 10: invalid index to scalar variable.\n",
      "Error processing sample 11: invalid index to scalar variable.\n",
      "Error processing sample 12: invalid index to scalar variable.\n",
      "Error processing sample 13: invalid index to scalar variable.\n",
      "Error processing sample 14: invalid index to scalar variable.\n",
      "Error processing sample 15: invalid index to scalar variable.\n",
      "Error processing sample 16: invalid index to scalar variable.\n",
      "Error processing sample 17: invalid index to scalar variable.\n",
      "Error processing sample 18: invalid index to scalar variable.\n",
      "Error processing sample 19: invalid index to scalar variable.\n",
      "Error processing sample 20: invalid index to scalar variable.\n",
      "Error processing sample 21: invalid index to scalar variable.\n",
      "Error processing sample 22: invalid index to scalar variable.\n",
      "Error processing sample 23: invalid index to scalar variable.\n",
      "Error processing sample 24: invalid index to scalar variable.\n",
      "Error processing sample 25: invalid index to scalar variable.\n",
      "Error processing sample 26: invalid index to scalar variable.\n",
      "Error processing sample 27: invalid index to scalar variable.\n",
      "Error processing sample 28: invalid index to scalar variable.\n",
      "Error processing sample 29: invalid index to scalar variable.\n",
      "Error processing sample 30: invalid index to scalar variable.\n",
      "Error processing sample 31: invalid index to scalar variable.\n",
      "Error processing sample 32: invalid index to scalar variable.\n",
      "Error processing sample 33: invalid index to scalar variable.\n",
      "Error processing sample 34: invalid index to scalar variable.\n",
      "Error processing sample 35: invalid index to scalar variable.\n",
      "Error processing sample 36: invalid index to scalar variable.\n",
      "Error processing sample 37: invalid index to scalar variable.\n",
      "Error processing sample 38: invalid index to scalar variable.\n",
      "Error processing sample 39: invalid index to scalar variable.\n",
      "Error processing sample 40: invalid index to scalar variable.\n",
      "Error processing sample 41: invalid index to scalar variable.\n",
      "Error processing sample 42: invalid index to scalar variable.\n",
      "Error processing sample 43: invalid index to scalar variable.\n",
      "Error processing sample 44: invalid index to scalar variable.\n",
      "Error processing sample 45: invalid index to scalar variable.\n",
      "Error processing sample 46: invalid index to scalar variable.\n",
      "Error processing sample 47: invalid index to scalar variable.\n",
      "Error processing sample 48: invalid index to scalar variable.\n",
      "Error processing sample 49: invalid index to scalar variable.\n",
      "Error processing sample 50: invalid index to scalar variable.\n",
      "Error processing sample 51: invalid index to scalar variable.\n",
      "Error processing sample 52: invalid index to scalar variable.\n",
      "Error processing sample 53: invalid index to scalar variable.\n",
      "Error processing sample 54: invalid index to scalar variable.\n",
      "Error processing sample 55: invalid index to scalar variable.\n",
      "Error processing sample 56: invalid index to scalar variable.\n",
      "Error processing sample 57: invalid index to scalar variable.\n",
      "Error processing sample 58: invalid index to scalar variable.\n",
      "Error processing sample 59: invalid index to scalar variable.\n",
      "Error processing sample 60: invalid index to scalar variable.\n",
      "Error processing sample 61: invalid index to scalar variable.\n",
      "Error processing sample 62: invalid index to scalar variable.\n",
      "Error processing sample 63: invalid index to scalar variable.\n",
      "Error processing sample 64: invalid index to scalar variable.\n",
      "Error processing sample 65: invalid index to scalar variable.\n",
      "Error processing sample 66: invalid index to scalar variable.\n",
      "Error processing sample 67: invalid index to scalar variable.\n",
      "Error processing sample 68: invalid index to scalar variable.\n",
      "Error processing sample 69: invalid index to scalar variable.\n",
      "Error processing sample 70: invalid index to scalar variable.\n",
      "Error processing sample 71: invalid index to scalar variable.\n",
      "Error processing sample 72: invalid index to scalar variable.\n",
      "Error processing sample 73: invalid index to scalar variable.\n",
      "Error processing sample 74: invalid index to scalar variable.\n",
      "Error processing sample 75: invalid index to scalar variable.\n",
      "Error processing sample 76: invalid index to scalar variable.\n",
      "Error processing sample 77: invalid index to scalar variable.\n",
      "Error processing sample 78: invalid index to scalar variable.\n",
      "Error processing sample 79: invalid index to scalar variable.\n",
      "Error processing sample 80: invalid index to scalar variable.\n",
      "Error processing sample 81: invalid index to scalar variable.\n",
      "Error processing sample 82: invalid index to scalar variable.\n",
      "Error processing sample 83: invalid index to scalar variable.\n",
      "Error processing sample 84: invalid index to scalar variable.\n",
      "Error processing sample 85: invalid index to scalar variable.\n",
      "Error processing sample 86: invalid index to scalar variable.\n",
      "Error processing sample 87: invalid index to scalar variable.\n",
      "Error processing sample 88: invalid index to scalar variable.\n",
      "Error processing sample 89: invalid index to scalar variable.\n",
      "Error processing sample 90: invalid index to scalar variable.\n",
      "Error processing sample 91: invalid index to scalar variable.\n",
      "Error processing sample 92: invalid index to scalar variable.\n",
      "Error processing sample 93: invalid index to scalar variable.\n",
      "Error processing sample 94: invalid index to scalar variable.\n",
      "Error processing sample 95: invalid index to scalar variable.\n",
      "Error processing sample 96: invalid index to scalar variable.\n",
      "Error processing sample 97: invalid index to scalar variable.\n",
      "Error processing sample 98: invalid index to scalar variable.\n",
      "Error processing sample 99: invalid index to scalar variable.\n",
      "Error processing sample 100: invalid index to scalar variable.\n",
      "Error processing sample 101: invalid index to scalar variable.\n",
      "Error processing sample 102: invalid index to scalar variable.\n",
      "Error processing sample 103: invalid index to scalar variable.\n",
      "Error processing sample 104: invalid index to scalar variable.\n",
      "Error processing sample 105: invalid index to scalar variable.\n",
      "Error processing sample 106: invalid index to scalar variable.\n",
      "Error processing sample 107: invalid index to scalar variable.\n",
      "Error processing sample 108: invalid index to scalar variable.\n",
      "Error processing sample 109: invalid index to scalar variable.\n",
      "Error processing sample 110: invalid index to scalar variable.\n",
      "Error processing sample 111: invalid index to scalar variable.\n",
      "Error processing sample 112: invalid index to scalar variable.\n",
      "Error processing sample 113: invalid index to scalar variable.\n",
      "Error processing sample 114: invalid index to scalar variable.\n",
      "Error processing sample 115: invalid index to scalar variable.\n",
      "Error processing sample 116: invalid index to scalar variable.\n",
      "Error processing sample 117: invalid index to scalar variable.\n",
      "Error processing sample 118: invalid index to scalar variable.\n",
      "Error processing sample 119: invalid index to scalar variable.\n",
      "Error processing sample 120: invalid index to scalar variable.\n",
      "Error processing sample 121: invalid index to scalar variable.\n",
      "Error processing sample 122: invalid index to scalar variable.\n",
      "Error processing sample 123: invalid index to scalar variable.\n",
      "Error processing sample 124: invalid index to scalar variable.\n",
      "Error processing sample 125: invalid index to scalar variable.\n",
      "Error processing sample 126: invalid index to scalar variable.\n",
      "Error processing sample 127: invalid index to scalar variable.\n",
      "Error processing sample 128: invalid index to scalar variable.\n",
      "Error processing sample 129: invalid index to scalar variable.\n",
      "Error processing sample 130: invalid index to scalar variable.\n",
      "Error processing sample 131: invalid index to scalar variable.\n",
      "Error processing sample 132: invalid index to scalar variable.\n",
      "Error processing sample 133: invalid index to scalar variable.\n",
      "Error processing sample 134: invalid index to scalar variable.\n",
      "Error processing sample 135: invalid index to scalar variable.\n",
      "Error processing sample 136: invalid index to scalar variable.\n",
      "Error processing sample 137: invalid index to scalar variable.\n",
      "Error processing sample 138: invalid index to scalar variable.\n",
      "Error processing sample 139: invalid index to scalar variable.\n",
      "Error processing sample 140: invalid index to scalar variable.\n",
      "Error processing sample 141: invalid index to scalar variable.\n",
      "Error processing sample 0: invalid index to scalar variable.\n",
      "Error processing sample 1: invalid index to scalar variable.\n",
      "Error processing sample 2: invalid index to scalar variable.\n",
      "Error processing sample 3: invalid index to scalar variable.\n",
      "Error processing sample 4: invalid index to scalar variable.\n",
      "Error processing sample 5: invalid index to scalar variable.\n",
      "Error processing sample 6: invalid index to scalar variable.\n",
      "Error processing sample 7: invalid index to scalar variable.\n",
      "Error processing sample 8: invalid index to scalar variable.\n",
      "Error processing sample 9: invalid index to scalar variable.\n",
      "Error processing sample 10: invalid index to scalar variable.\n",
      "Error processing sample 11: invalid index to scalar variable.\n",
      "Error processing sample 12: invalid index to scalar variable.\n",
      "Error processing sample 13: invalid index to scalar variable.\n",
      "Error processing sample 14: invalid index to scalar variable.\n",
      "Error processing sample 15: invalid index to scalar variable.\n",
      "Error processing sample 16: invalid index to scalar variable.\n",
      "Error processing sample 17: invalid index to scalar variable.\n",
      "Error processing sample 18: invalid index to scalar variable.\n",
      "Error processing sample 19: invalid index to scalar variable.\n",
      "Error processing sample 20: invalid index to scalar variable.\n",
      "Error processing sample 21: invalid index to scalar variable.\n",
      "Error processing sample 22: invalid index to scalar variable.\n",
      "Error processing sample 23: invalid index to scalar variable.\n",
      "Error processing sample 24: invalid index to scalar variable.\n",
      "Error processing sample 25: invalid index to scalar variable.\n",
      "Error processing sample 26: invalid index to scalar variable.\n",
      "Error processing sample 27: invalid index to scalar variable.\n",
      "Error processing sample 28: invalid index to scalar variable.\n",
      "Error processing sample 29: invalid index to scalar variable.\n",
      "Error processing sample 30: invalid index to scalar variable.\n",
      "Error processing sample 31: invalid index to scalar variable.\n",
      "Error processing sample 32: invalid index to scalar variable.\n",
      "Error processing sample 33: invalid index to scalar variable.\n",
      "Error processing sample 34: invalid index to scalar variable.\n",
      "Error processing sample 35: invalid index to scalar variable.\n",
      "Training data shape: (142, 4, 62) -> (142, 4, 10)\n",
      "Test data shape: (36, 4, 62) -> (36, 4, 10)\n",
      "\n",
      "==================================================\n",
      "Training Iteration 3 (claude)\n",
      "==================================================\n",
      "Epoch 1/50, Train Loss: 0.030268\n",
      "Epoch 11/50, Train Loss: 0.014674\n",
      "Epoch 21/50, Train Loss: 0.014127\n",
      "Epoch 31/50, Train Loss: 0.013111\n",
      "Early stopping at epoch 32\n",
      "\n",
      "Iteration 3 (claude) Performance:\n",
      "MAE: 9436836.5775\n",
      "RMSE: 11981621.1236\n",
      "MAPE: 11.00%\n",
      "üìä No significant improvement. Change: -1.79%\n",
      "\n",
      "üìà Current best MAPE: 9.21%\n",
      "üîÑ Iterations without improvement: 1/3\n",
      "\n",
      "======================================================================\n",
      "ITERATION 4\n",
      "======================================================================\n",
      "ü§ñ Calling Claude for iteration 4...\n",
      "‚úÖ Claude response received!\n",
      "\n",
      "üìù Claude's Response:\n",
      "--------------------------------------------------\n",
      "```python\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    # Handle edge cases and NaN values\n",
      "    data = np.nan_to_num(data)\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]  # Short interest\n",
      "    volume = data[:, 1]  # Volume\n",
      "    \n",
      "    # Reshape OHLC data (last 60 columns) into (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    # Price features\n",
      "    typical_price = np.mean(ohlc[:,:,[0,1,2,3]], axis=2)  # (lookback, 15)\n",
      "    \n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        t_features = []\n",
      "        \n",
      "        # Short interest features\n",
      "        t_features.append(short_interest[t])\n",
      "        if t > 0:\n",
      "            t_features.append(short_interest[t] - short_interest[t-1])  # Change\n",
      "            t_features.append((short_interest[t] - short_interest[t-1])/short_interest[t-1])  # % Change\n",
      "        else:\n",
      "            t_features.extend([0, 0])\n",
      "            \n",
      "        # Volume features\n",
      "        vol = volume[t]\n",
      "        t_features.append(vol)\n",
      "        if t > 0:\n",
      "            t_features.append(vol/volume[t-1] - 1)  # Volume momentum\n",
      "        else:\n",
      "            t_features.append(0)\n",
      "            \n",
      "        # Price action features\n",
      "        tp = typical_price[t]\n",
      "        \n",
      "        # Volatility (std of typical price)\n",
      "        t_features.append(np.std(tp))\n",
      "        \n",
      "        # Price momentum features\n",
      "        price_momentum_1 = (tp[-1] - tp[0])/tp[0]  # 15-day momentum\n",
      "        price_momentum_2 = (tp[-1] - tp[-6])/tp[-6]  # 5-day momentum\n",
      "        t_features.extend([price_momentum_1, price_momentum_2])\n",
      "        \n",
      "        # High-low range features\n",
      "        hl_range = np.mean((ohlc[t,:,1] - ohlc[t,:,2])/ohlc[t,:,3])  # Avg daily range\n",
      "        t_features.append(hl_range)\n",
      "        \n",
      "        # Gap features\n",
      "        gaps = ohlc[t,1:,0] - ohlc[t,:-1,3]  # Open - Previous Close\n",
      "        t_features.append(np.mean(np.abs(gaps)))  # Average gap size\n",
      "        t_features.append(np.sum(gaps > 0)/len(gaps))  # Gap up ratio\n",
      "        \n",
      "        # Candlestick features\n",
      "        body = ohlc[t,:,3] - ohlc[t,:,0]  # Close - Open\n",
      "        upper_shadow = ohlc[t,:,1] - np.maximum(ohlc[t,:,0], ohlc[t,:,3])\n",
      "        lower_shadow = np.minimum(ohlc[t,:,0], ohlc[t,:,3]) - ohlc[t,:,2]\n",
      "        \n",
      "        t_features.extend([\n",
      "            np.mean(body),  # Average body size\n",
      "            np.mean(upper_shadow),  # Average upper shadow\n",
      "            np.mean(lower_shadow),  # Average lower shadow\n",
      "            np.sum(body > 0)/len(body)  # Bullish candle ratio\n",
      "        ])\n",
      "        \n",
      "        # Support/Resistance features\n",
      "        t_features.extend([\n",
      "            np.min(ohlc[t,:,2]),  # Support level\n",
      "            np.max(ohlc[t,:,1]),  # Resistance level\n",
      "            np.percentile(tp, 25),  # 25th percentile price\n",
      "            np.percentile(tp, 75)   # 75th percentile price\n",
      "        ])\n",
      "        \n",
      "        features.append(t_features)\n",
      "    \n",
      "    return np.array(features)\n",
      "```\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß Extracted Function Code:\n",
      "--------------------------------------------------\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    # Handle edge cases and NaN values\n",
      "    data = np.nan_to_num(data)\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]  # Short interest\n",
      "    volume = data[:, 1]  # Volume\n",
      "    \n",
      "    # Reshape OHLC data (last 60 columns) into (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    # Price features\n",
      "    typical_price = np.mean(ohlc[:,:,[0,1,2,3]], axis=2)  # (lookback, 15)\n",
      "    \n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        t_features = []\n",
      "        \n",
      "        # Short interest features\n",
      "        t_features.append(short_interest[t])\n",
      "        if t > 0:\n",
      "            t_features.append(short_interest[t] - short_interest[t-1])  # Change\n",
      "            t_features.append((short_interest[t] - short_interest[t-1])/short_interest[t-1])  # % Change\n",
      "        else:\n",
      "            t_features.extend([0, 0])\n",
      "            \n",
      "        # Volume features\n",
      "        vol = volume[t]\n",
      "        t_features.append(vol)\n",
      "        if t > 0:\n",
      "            t_features.append(vol/volume[t-1] - 1)  # Volume momentum\n",
      "        else:\n",
      "            t_features.append(0)\n",
      "            \n",
      "        # Price action features\n",
      "        tp = typical_price[t]\n",
      "        \n",
      "        # Volatility (std of typical price)\n",
      "        t_features.append(np.std(tp))\n",
      "        \n",
      "        # Price momentum features\n",
      "        price_momentum_1 = (tp[-1] - tp[0])/tp[0]  # 15-day momentum\n",
      "        price_momentum_2 = (tp[-1] - tp[-6])/tp[-6]  # 5-day momentum\n",
      "        t_features.extend([price_momentum_1, price_momentum_2])\n",
      "        \n",
      "        # High-low range features\n",
      "        hl_range = np.mean((ohlc[t,:,1] - ohlc[t,:,2])/ohlc[t,:,3])  # Avg daily range\n",
      "        t_features.append(hl_range)\n",
      "        \n",
      "        # Gap features\n",
      "        gaps = ohlc[t,1:,0] - ohlc[t,:-1,3]  # Open - Previous Close\n",
      "        t_features.append(np.mean(np.abs(gaps)))  # Average gap size\n",
      "        t_features.append(np.sum(gaps > 0)/len(gaps))  # Gap up ratio\n",
      "        \n",
      "        # Candlestick features\n",
      "        body = ohlc[t,:,3] - ohlc[t,:,0]  # Close - Open\n",
      "        upper_shadow = ohlc[t,:,1] - np.maximum(ohlc[t,:,0], ohlc[t,:,3])\n",
      "        lower_shadow = np.minimum(ohlc[t,:,0], ohlc[t,:,3]) - ohlc[t,:,2]\n",
      "        \n",
      "        t_features.extend([\n",
      "            np.mean(body),  # Average body size\n",
      "            np.mean(upper_shadow),  # Average upper shadow\n",
      "            np.mean(lower_shadow),  # Average lower shadow\n",
      "            np.sum(body > 0)/len(body)  # Bullish candle ratio\n",
      "        ])\n",
      "        \n",
      "        # Support/Resistance features\n",
      "        t_features.extend([\n",
      "            np.min(ohlc[t,:,2]),  # Support level\n",
      "            np.max(ohlc[t,:,1]),  # Resistance level\n",
      "            np.percentile(tp, 25),  # 25th percentile price\n",
      "            np.percentile(tp, 75)   # 75th percentile price\n",
      "        ])\n",
      "        \n",
      "        features.append(t_features)\n",
      "    \n",
      "    return np.array(features)\n",
      "--------------------------------------------------\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üîß Applying feature selection using claude function...\n",
      "Training data shape: (142, 4, 62) -> (142, 4, 19)\n",
      "Test data shape: (36, 4, 62) -> (36, 4, 19)\n",
      "\n",
      "==================================================\n",
      "Training Iteration 4 (claude)\n",
      "==================================================\n",
      "Epoch 1/50, Train Loss: 0.040486\n",
      "Epoch 11/50, Train Loss: 0.015013\n",
      "Epoch 21/50, Train Loss: 0.011885\n",
      "Epoch 31/50, Train Loss: 0.008189\n",
      "Epoch 41/50, Train Loss: 0.004086\n",
      "\n",
      "Iteration 4 (claude) Performance:\n",
      "MAE: 8909981.1264\n",
      "RMSE: 11327050.1194\n",
      "MAPE: 10.36%\n",
      "üìä No significant improvement. Change: -1.16%\n",
      "\n",
      "üìà Current best MAPE: 9.21%\n",
      "üîÑ Iterations without improvement: 2/3\n",
      "\n",
      "======================================================================\n",
      "ITERATION 5\n",
      "======================================================================\n",
      "ü§ñ Calling Claude for iteration 5...\n",
      "‚úÖ Claude response received!\n",
      "\n",
      "üìù Claude's Response:\n",
      "--------------------------------------------------\n",
      "```python\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]\n",
      "    volume = data[:, 1] \n",
      "    \n",
      "    # Reshape OHLC data from flattened to (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        # Current time features\n",
      "        curr_ohlc = ohlc[t]\n",
      "        curr_si = short_interest[t]\n",
      "        curr_vol = volume[t]\n",
      "        \n",
      "        # Price features\n",
      "        typical_price = np.mean(curr_ohlc[:, [0,1,2,3]], axis=1) # (O+H+L+C)/4\n",
      "        log_returns = np.diff(np.log(typical_price))\n",
      "        \n",
      "        # Volatility features (focus on recent volatility)\n",
      "        volatility_3d = np.std(log_returns[-3:])\n",
      "        volatility_7d = np.std(log_returns[-7:])\n",
      "        volatility_15d = np.std(log_returns)\n",
      "        \n",
      "        # Price momentum \n",
      "        momentum_3d = (typical_price[-1] / typical_price[-3]) - 1\n",
      "        momentum_7d = (typical_price[-1] / typical_price[-7]) - 1\n",
      "        momentum_15d = (typical_price[-1] / typical_price[0]) - 1\n",
      "        \n",
      "        # Volume momentum\n",
      "        vol_momentum = curr_vol / np.mean(volume[:t+1]) if t > 0 else 1.0\n",
      "        \n",
      "        # Price gaps and ranges\n",
      "        daily_gaps = curr_ohlc[1:,0] - curr_ohlc[:-1,3]  # Open - prev Close\n",
      "        gap_std = np.std(daily_gaps)\n",
      "        daily_ranges = curr_ohlc[:,1] - curr_ohlc[:,2]  # High - Low\n",
      "        range_mean = np.mean(daily_ranges)\n",
      "        \n",
      "        # Short interest momentum\n",
      "        si_momentum = curr_si / np.mean(short_interest[:t+1]) if t > 0 else 1.0\n",
      "        \n",
      "        # Combine features\n",
      "        time_features = np.array([\n",
      "            curr_si,                    # Current short interest\n",
      "            si_momentum,                # Short interest momentum\n",
      "            curr_vol,                   # Current volume\n",
      "            vol_momentum,               # Volume momentum\n",
      "            volatility_3d,              # Recent volatility\n",
      "            volatility_7d,              # Medium-term volatility  \n",
      "            volatility_15d,             # Long-term volatility\n",
      "            momentum_3d,                # Short-term price momentum\n",
      "            momentum_7d,                # Medium-term price momentum\n",
      "            momentum_15d,               # Long-term price momentum\n",
      "            gap_std,                    # Gap volatility\n",
      "            range_mean,                 # Average daily range\n",
      "            typical_price[-1],          # Current price level\n",
      "            np.mean(daily_ranges[-3:]), # Recent range\n",
      "            np.mean(daily_gaps[-3:])    # Recent gaps\n",
      "        ])\n",
      "        \n",
      "        features.append(time_features)\n",
      "    \n",
      "    features = np.array(features)\n",
      "    \n",
      "    # Handle any NaN values\n",
      "    features = np.nan_to_num(features, nan=0.0)\n",
      "    \n",
      "    return features\n",
      "```\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß Extracted Function Code:\n",
      "--------------------------------------------------\n",
      "def construct_features(data):\n",
      "    \"\"\"\n",
      "    Constructs predictive features from raw financial data\n",
      "    Input shape: (lookback_window, 62) \n",
      "    Output shape: (lookback_window, constructed_features)\n",
      "    \"\"\"\n",
      "    lookback = data.shape[0]\n",
      "    \n",
      "    # Extract core features\n",
      "    short_interest = data[:, 0]\n",
      "    volume = data[:, 1] \n",
      "    \n",
      "    # Reshape OHLC data from flattened to (lookback, 15, 4)\n",
      "    ohlc = data[:, 2:].reshape(lookback, 15, 4)\n",
      "    \n",
      "    features = []\n",
      "    \n",
      "    for t in range(lookback):\n",
      "        # Current time features\n",
      "        curr_ohlc = ohlc[t]\n",
      "        curr_si = short_interest[t]\n",
      "        curr_vol = volume[t]\n",
      "        \n",
      "        # Price features\n",
      "        typical_price = np.mean(curr_ohlc[:, [0,1,2,3]], axis=1) # (O+H+L+C)/4\n",
      "        log_returns = np.diff(np.log(typical_price))\n",
      "        \n",
      "        # Volatility features (focus on recent volatility)\n",
      "        volatility_3d = np.std(log_returns[-3:])\n",
      "        volatility_7d = np.std(log_returns[-7:])\n",
      "        volatility_15d = np.std(log_returns)\n",
      "        \n",
      "        # Price momentum \n",
      "        momentum_3d = (typical_price[-1] / typical_price[-3]) - 1\n",
      "        momentum_7d = (typical_price[-1] / typical_price[-7]) - 1\n",
      "        momentum_15d = (typical_price[-1] / typical_price[0]) - 1\n",
      "        \n",
      "        # Volume momentum\n",
      "        vol_momentum = curr_vol / np.mean(volume[:t+1]) if t > 0 else 1.0\n",
      "        \n",
      "        # Price gaps and ranges\n",
      "        daily_gaps = curr_ohlc[1:,0] - curr_ohlc[:-1,3]  # Open - prev Close\n",
      "        gap_std = np.std(daily_gaps)\n",
      "        daily_ranges = curr_ohlc[:,1] - curr_ohlc[:,2]  # High - Low\n",
      "        range_mean = np.mean(daily_ranges)\n",
      "        \n",
      "        # Short interest momentum\n",
      "        si_momentum = curr_si / np.mean(short_interest[:t+1]) if t > 0 else 1.0\n",
      "        \n",
      "        # Combine features\n",
      "        time_features = np.array([\n",
      "            curr_si,                    # Current short interest\n",
      "            si_momentum,                # Short interest momentum\n",
      "            curr_vol,                   # Current volume\n",
      "            vol_momentum,               # Volume momentum\n",
      "            volatility_3d,              # Recent volatility\n",
      "            volatility_7d,              # Medium-term volatility  \n",
      "            volatility_15d,             # Long-term volatility\n",
      "            momentum_3d,                # Short-term price momentum\n",
      "            momentum_7d,                # Medium-term price momentum\n",
      "            momentum_15d,               # Long-term price momentum\n",
      "            gap_std,                    # Gap volatility\n",
      "            range_mean,                 # Average daily range\n",
      "            typical_price[-1],          # Current price level\n",
      "            np.mean(daily_ranges[-3:]), # Recent range\n",
      "            np.mean(daily_gaps[-3:])    # Recent gaps\n",
      "        ])\n",
      "        \n",
      "        features.append(time_features)\n",
      "    \n",
      "    features = np.array(features)\n",
      "    \n",
      "    # Handle any NaN values\n",
      "    features = np.nan_to_num(features, nan=0.0)\n",
      "    \n",
      "    return features\n",
      "--------------------------------------------------\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üîß Applying feature selection using claude function...\n",
      "Training data shape: (142, 4, 62) -> (142, 4, 15)\n",
      "Test data shape: (36, 4, 62) -> (36, 4, 15)\n",
      "\n",
      "==================================================\n",
      "Training Iteration 5 (claude)\n",
      "==================================================\n",
      "Epoch 1/50, Train Loss: 0.018865\n",
      "Epoch 11/50, Train Loss: 0.012964\n",
      "Epoch 21/50, Train Loss: 0.011694\n",
      "Epoch 31/50, Train Loss: 0.006952\n",
      "Epoch 41/50, Train Loss: 0.004018\n",
      "\n",
      "Iteration 5 (claude) Performance:\n",
      "MAE: 11282259.6027\n",
      "RMSE: 15995889.3282\n",
      "MAPE: 12.77%\n",
      "üìä No significant improvement. Change: -3.56%\n",
      "\n",
      "üõë Stopping: No improvement for 3 consecutive iterations\n",
      "\n",
      "‚úÖ Iterative process completed!\n",
      "üèÜ Final best MAPE: 9.21%\n",
      "üìä Total iterations: 7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the enhanced iterative feature selector\n",
    "feature_selector = EnhancedIterativeLLMFeatureSelector(ANTHROPIC_API_KEY)\n",
    "\n",
    "# Iterative improvement loop\n",
    "max_iterations = 10\n",
    "min_improvement_threshold = 0.1  # Minimum improvement in MAPE to continue\n",
    "patience = 3  # Number of iterations without improvement before stopping\n",
    "\n",
    "print(f\"\\nüîÑ Starting iterative improvement process...\")\n",
    "print(f\"Max iterations: {max_iterations}\")\n",
    "print(f\"Min improvement threshold: {min_improvement_threshold}%\")\n",
    "print(f\"Patience: {patience} iterations without improvement\")\n",
    "\n",
    "best_mape = baseline_mape\n",
    "iterations_without_improvement = 0\n",
    "\n",
    "for iteration in range(1, max_iterations + 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ITERATION {iteration}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Get feature engineering code from Claude\n",
    "    print(f\"ü§ñ Calling Claude for iteration {iteration}...\")\n",
    "    claude_response = feature_selector.call_claude_for_iterative_improvement(\n",
    "        iteration, iteration_results, \n",
    "        \"Stock prediction with short interest, volume, and OHLC data for iterative improvement\"\n",
    "    )\n",
    "    \n",
    "    if not claude_response:\n",
    "        print(\"‚ùå No response from Claude, using fallback\")\n",
    "        construct_func = feature_selector.fallback_construct_features\n",
    "        function_source = \"fallback\"\n",
    "        claude_code = None\n",
    "    else:\n",
    "        print(\"‚úÖ Claude response received!\")\n",
    "        print(f\"\\nüìù Claude's Response:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(claude_response)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Extract and execute the function\n",
    "        function_code = feature_selector.extract_function_from_response(claude_response)\n",
    "        print(f\"\\nüîß Extracted Function Code:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(function_code)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        construct_func = feature_selector.execute_feature_construction_code(function_code)\n",
    "        \n",
    "        if construct_func:\n",
    "            print(\"‚úÖ Function executed successfully!\")\n",
    "            function_source = \"claude\"\n",
    "            claude_code = function_code\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Function execution failed, using fallback\")\n",
    "            construct_func = feature_selector.fallback_construct_features\n",
    "            function_source = \"fallback\"\n",
    "            claude_code = None\n",
    "    \n",
    "    # Apply feature selection to data\n",
    "    print(f\"\\nüîß Applying feature selection using {function_source} function...\")\n",
    "    X_train_processed = feature_selector.apply_feature_selection_to_data(X_train_raw, construct_func)\n",
    "    X_test_processed = feature_selector.apply_feature_selection_to_data(X_test_raw, construct_func)\n",
    "    \n",
    "    print(f\"Training data shape: {X_train_raw.shape} -> {X_train_processed.shape}\")\n",
    "    print(f\"Test data shape: {X_test_raw.shape} -> {X_test_processed.shape}\")\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    iteration_results_model = train_and_evaluate_model(\n",
    "        X_train_processed, X_test_processed, y_train, y_test, prev_log_test,\n",
    "        model_name=f\"Iteration {iteration} ({function_source})\", epochs=50\n",
    "    )\n",
    "    \n",
    "    # Calculate improvement\n",
    "    improvement = best_mape - iteration_results_model['mape']\n",
    "    \n",
    "    # Store results\n",
    "    iteration_results.append({\n",
    "        'iteration': iteration,\n",
    "        'model_name': f'Iteration {iteration}',\n",
    "        'features_used': f'{function_source} feature engineering',\n",
    "        'feature_count': X_train_processed.shape[2],\n",
    "        'mape': iteration_results_model['mape'],\n",
    "        'mae': iteration_results_model['mae'],\n",
    "        'rmse': iteration_results_model['rmse'],\n",
    "        'improvement': improvement,\n",
    "        'predictions': iteration_results_model['predictions'],\n",
    "        'true_values': iteration_results_model['true_values'],\n",
    "        'claude_code': claude_code,\n",
    "        'function_source': function_source\n",
    "    })\n",
    "    \n",
    "    # Check for improvement\n",
    "    if improvement > min_improvement_threshold:\n",
    "        print(f\"üéâ IMPROVEMENT! MAPE improved by {improvement:.2f}%\")\n",
    "        best_mape = iteration_results_model['mape']\n",
    "        iterations_without_improvement = 0\n",
    "    else:\n",
    "        print(f\"üìä No significant improvement. Change: {improvement:+.2f}%\")\n",
    "        iterations_without_improvement += 1\n",
    "    \n",
    "    # Check stopping criteria\n",
    "    if iterations_without_improvement >= patience:\n",
    "        print(f\"\\nüõë Stopping: No improvement for {patience} consecutive iterations\")\n",
    "        break\n",
    "    \n",
    "    print(f\"\\nüìà Current best MAPE: {best_mape:.2f}%\")\n",
    "    print(f\"üîÑ Iterations without improvement: {iterations_without_improvement}/{patience}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Iterative process completed!\")\n",
    "print(f\"üèÜ Final best MAPE: {best_mape:.2f}%\")\n",
    "print(f\"üìä Total iterations: {len(iteration_results) - 1}\")  # -1 for baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9480e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERFORMANCE ANALYSIS AND SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìä PERFORMANCE SUMMARY TABLE:\n",
      "======================================================================\n",
      " Iteration       Model  Features  MAPE (%)          MAE         RMSE  Improvement (%)   Source\n",
      "         0    Baseline        62    9.3712 7301369.5718 9.576693e+06           0.0000 baseline\n",
      "         1 Iteration 1        10    9.9797 8277400.0124 1.061651e+07          -0.6084   claude\n",
      "         2 Iteration 2        10   11.1905 9720729.6835 1.238113e+07          -1.8193   claude\n",
      "\n",
      "üèÜ BEST PERFORMING MODEL:\n",
      "   Model: Baseline\n",
      "   MAPE: 9.37%\n",
      "   MAE: 7301369.5718\n",
      "   RMSE: 9576693.4427\n",
      "   Features: 62\n",
      "   Source: baseline\n",
      "\n",
      "üìà OVERALL IMPROVEMENT:\n",
      "   Baseline MAPE: 9.37%\n",
      "   Best MAPE: 9.37%\n",
      "   Total Improvement: 0.00% (0.0% relative)\n",
      "\n",
      "üîß FEATURE REDUCTION:\n",
      "   Baseline features: 62\n",
      "   Best model features: 62\n",
      "   Feature reduction: 0.0%\n",
      "\n",
      "‚ö° ITERATION EFFICIENCY:\n",
      "   Total iterations: 2\n",
      "   Successful improvements: 0\n",
      "   Success rate: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Performance Analysis and Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE ANALYSIS AND SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create performance summary DataFrame\n",
    "performance_data = []\n",
    "for result in iteration_results:\n",
    "    performance_data.append({\n",
    "        'Iteration': result['iteration'],\n",
    "        'Model': result['model_name'],\n",
    "        'Features': result['feature_count'],\n",
    "        'MAPE (%)': result['mape'],\n",
    "        'MAE': result['mae'],\n",
    "        'RMSE': result['rmse'],\n",
    "        'Improvement (%)': result['improvement'],\n",
    "        'Source': result.get('function_source', 'baseline')\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "print(\"\\nüìä PERFORMANCE SUMMARY TABLE:\")\n",
    "print(\"=\"*70)\n",
    "print(performance_df.round(4).to_string(index=False))\n",
    "\n",
    "# Find best performing model\n",
    "best_result = min(iteration_results, key=lambda x: x['mape'])\n",
    "print(f\"\\nüèÜ BEST PERFORMING MODEL:\")\n",
    "print(f\"   Model: {best_result['model_name']}\")\n",
    "print(f\"   MAPE: {best_result['mape']:.2f}%\")\n",
    "print(f\"   MAE: {best_result['mae']:.4f}\")\n",
    "print(f\"   RMSE: {best_result['rmse']:.4f}\")\n",
    "print(f\"   Features: {best_result['feature_count']}\")\n",
    "print(f\"   Source: {best_result.get('function_source', 'baseline')}\")\n",
    "\n",
    "# Calculate total improvement\n",
    "total_improvement = baseline_mape - best_result['mape']\n",
    "improvement_percentage = (total_improvement / baseline_mape) * 100\n",
    "\n",
    "print(f\"\\nüìà OVERALL IMPROVEMENT:\")\n",
    "print(f\"   Baseline MAPE: {baseline_mape:.2f}%\")\n",
    "print(f\"   Best MAPE: {best_result['mape']:.2f}%\")\n",
    "print(f\"   Total Improvement: {total_improvement:.2f}% ({improvement_percentage:.1f}% relative)\")\n",
    "\n",
    "# Feature reduction analysis\n",
    "baseline_features = iteration_results[0]['feature_count']\n",
    "best_features = best_result['feature_count']\n",
    "feature_reduction = ((baseline_features - best_features) / baseline_features) * 100\n",
    "\n",
    "print(f\"\\nüîß FEATURE REDUCTION:\")\n",
    "print(f\"   Baseline features: {baseline_features}\")\n",
    "print(f\"   Best model features: {best_features}\")\n",
    "print(f\"   Feature reduction: {feature_reduction:.1f}%\")\n",
    "\n",
    "# Iteration efficiency\n",
    "successful_iterations = len([r for r in iteration_results[1:] if r['improvement'] > 0])\n",
    "total_iterations = len(iteration_results) - 1\n",
    "efficiency = (successful_iterations / total_iterations) * 100 if total_iterations > 0 else 0\n",
    "\n",
    "print(f\"\\n‚ö° ITERATION EFFICIENCY:\")\n",
    "print(f\"   Total iterations: {total_iterations}\")\n",
    "print(f\"   Successful improvements: {successful_iterations}\")\n",
    "print(f\"   Success rate: {efficiency:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb97b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced report generation with p-value information\n",
    "print(\"\\nüíæ Saving enhanced results and generating comprehensive report...\")\n",
    "\n",
    "# Save iteration results to pickle\n",
    "results_filename = f'cache/{stock}_iterative_results_enhanced.pkl'\n",
    "with open(results_filename, 'wb') as f:\n",
    "    pickle.dump(iteration_results, f)\n",
    "\n",
    "print(f\"‚úÖ Enhanced results saved to: {results_filename}\")\n",
    "\n",
    "# Generate detailed report with statistical analysis\n",
    "report_filename = f'cache/{stock}_iterative_report_enhanced.txt'\n",
    "with open(report_filename, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"ENHANCED ITERATIVE AGENT-BASED FEATURE SELECTION REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(f\"Stock: {stock}\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Total Iterations: {len(iteration_results) - 1}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE SUMMARY:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"Baseline MAPE: {baseline_mape:.2f}%\\n\")\n",
    "    f.write(f\"Best MAPE: {best_result['mape']:.2f}%\\n\")\n",
    "    f.write(f\"Total Improvement: {total_improvement:.2f}% ({improvement_percentage:.1f}% relative)\\n\")\n",
    "    f.write(f\"Feature Reduction: {feature_reduction:.1f}%\\n\")\n",
    "    f.write(f\"Success Rate: {efficiency:.1f}%\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"DETAILED RESULTS WITH STATISTICAL ANALYSIS:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    for result in iteration_results:\n",
    "        f.write(f\"Iteration {result['iteration']}: {result['model_name']}\\n\")\n",
    "        f.write(f\"  MAPE: {result['mape']:.2f}%\\n\")\n",
    "        f.write(f\"  Features: {result['feature_count']}\\n\")\n",
    "        f.write(f\"  Improvement: {result['improvement']:+.2f}%\\n\")\n",
    "        f.write(f\"  Source: {result.get('function_source', 'baseline')}\\n\")\n",
    "        \n",
    "        # Add statistical significance information\n",
    "        if 'feature_stats' in result and result['feature_stats']:\n",
    "            significant_count = len(result.get('significant_features', []))\n",
    "            highly_significant_count = len(result.get('highly_significant_features', []))\n",
    "            f.write(f\"  Statistical Analysis:\\n\")\n",
    "            f.write(f\"    ‚Ä¢ Significant features (p < 0.05): {significant_count}\\n\")\n",
    "            f.write(f\"    ‚Ä¢ Highly significant features (p < 0.01): {highly_significant_count}\\n\")\n",
    "            \n",
    "            # Add most significant feature\n",
    "            if result['feature_stats']:\n",
    "                min_pval_feature = min(result['feature_stats'].items(), key=lambda x: x[1]['p_value'])\n",
    "                f.write(f\"    ‚Ä¢ Most significant feature: {min_pval_feature[0]} (p={min_pval_feature[1]['p_value']:.4f})\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"BEST MODEL DETAILS:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"Model: {best_result['model_name']}\\n\")\n",
    "    f.write(f\"MAPE: {best_result['mape']:.2f}%\\n\")\n",
    "    f.write(f\"MAE: {best_result['mae']:.4f}\\n\")\n",
    "    f.write(f\"RMSE: {best_result['rmse']:.4f}\\n\")\n",
    "    f.write(f\"Features: {best_result['feature_count']}\\n\")\n",
    "    f.write(f\"Source: {best_result.get('function_source', 'baseline')}\\n\")\n",
    "    \n",
    "    # Add detailed statistical analysis for best model\n",
    "    if 'feature_stats' in best_result and best_result['feature_stats']:\n",
    "        f.write(f\"\\nSTATISTICAL SIGNIFICANCE ANALYSIS:\\n\")\n",
    "        f.write(f\"Total features: {len(best_result['feature_stats'])}\\n\")\n",
    "        f.write(f\"Significant features (p < 0.05): {len(best_result.get('significant_features', []))}\\n\")\n",
    "        f.write(f\"Highly significant features (p < 0.01): {len(best_result.get('highly_significant_features', []))}\\n\")\n",
    "        \n",
    "        # Top 10 most significant features\n",
    "        if best_result['feature_stats']:\n",
    "            sorted_features = sorted(best_result['feature_stats'].items(), key=lambda x: x[1]['p_value'])\n",
    "            f.write(f\"\\nTOP 10 MOST SIGNIFICANT FEATURES:\\n\")\n",
    "            for i, (name, stats) in enumerate(sorted_features[:10]):\n",
    "                significance = \"***\" if stats['p_value'] < 0.001 else \"**\" if stats['p_value'] < 0.01 else \"*\" if stats['p_value'] < 0.05 else \"\"\n",
    "                f.write(f\"{i+1:2d}. {name}: p={stats['p_value']:.4f} {significance}\\n\")\n",
    "    \n",
    "    if best_result.get('claude_code'):\n",
    "        f.write(\"\\nBEST MODEL FEATURE ENGINEERING CODE:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(best_result['claude_code'])\n",
    "\n",
    "print(f\"‚úÖ Enhanced detailed report saved to: {report_filename}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ ENHANCED ITERATIVE AGENT-BASED FEATURE SELECTION COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìä Final Results:\")\n",
    "print(f\"   ‚Ä¢ Baseline MAPE: {baseline_mape:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Best MAPE: {best_result['mape']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Total Improvement: {total_improvement:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Feature Reduction: {feature_reduction:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Iterations Completed: {len(iteration_results) - 1}\")\n",
    "print(f\"   ‚Ä¢ Success Rate: {efficiency:.1f}%\")\n",
    "\n",
    "# Statistical insights\n",
    "if 'feature_stats' in best_result and best_result['feature_stats']:\n",
    "    print(f\"\\nüìà Statistical Insights:\")\n",
    "    print(f\"   ‚Ä¢ Significant features: {len(best_result.get('significant_features', []))}/{len(best_result['feature_stats'])}\")\n",
    "    print(f\"   ‚Ä¢ Highly significant features: {len(best_result.get('highly_significant_features', []))}\")\n",
    "\n",
    "print(f\"\\nüíæ Files Saved:\")\n",
    "print(f\"   ‚Ä¢ Results: {results_filename}\")\n",
    "print(f\"   ‚Ä¢ Report: {report_filename}\")\n",
    "print(\"\\n‚úÖ Enhanced process completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3a8bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Creating comprehensive visualizations...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'true_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     56\u001b[0m best_predictions \u001b[38;5;241m=\u001b[39m best_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 57\u001b[0m best_true \u001b[38;5;241m=\u001b[39m \u001b[43mbest_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue_values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     58\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(best_true, best_predictions, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     59\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([best_true\u001b[38;5;241m.\u001b[39mmin(), best_true\u001b[38;5;241m.\u001b[39mmax()], [best_true\u001b[38;5;241m.\u001b[39mmin(), best_true\u001b[38;5;241m.\u001b[39mmax()], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr--\u001b[39m\u001b[38;5;124m'\u001b[39m, lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'true_values'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABmcAAAOCCAYAAACClQYWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1gUx/8H8PfRqyi9iGBFjV2jQb9GiA0Ejb2jqLFETayxxBi7REzsNUZFY+8tNmwYA8ZeYosmKhpBURFFpd78/rgfJycHHnDHHvB+PQ+Pzt7s7Gdm7273ZnZnZUIIASIiIiIiIiIiIiIiIioQBlIHQEREREREREREREREVJxwcIaIiIiIiIiIiIiIiKgAcXCGiIiIiIiIiIiIiIioAHFwhoiIiIiIiIiIiIiIqABxcIaIiIiIiIiIiIiIiKgAcXCGiIiIiIiIiIiIiIioAHFwhoiIiIiIiIiIiIiIqABxcIaIiIiIiIiIiIiIiKgAcXCGiIiIiIiIiIiIiIioAHFwhjQWFhYGmUym/DMyMkLp0qXRp08f/Pfff1rdVkpKCgYNGgQXFxcYGhqiVq1aWi2/uJk8ebLKvjMxMUHZsmUxbNgwvHjxQurwJHXixAnIZDKcOHFCku0LIbBhwwZ89tlnKFWqFExNTVGuXDkMGTIEDx48kCSmnGR8D5w7d065bP/+/Zg8ebJ0QWkQh6enJ4KDgws0HiKi/FD3fUv6Z+bMmdi1a5fUYeSKTCbD0KFDlelHjx5h8uTJuHTpknRBfSCOjHNZIiLS3Pt9OJn/Ro8erZNtXr9+HZMnT8a9e/d0Ur42PH78GOPGjUP16tVhZWUFMzMzVKxYEcOGDcPt27elDg8AEBkZicmTJ+tNf01wcLDK+8fU1BReXl6YNGkSkpKStLqte/fuISAgALa2tpDJZBg+fLhWyyfSN0ZSB0CFz+rVq1G5cmW8ffsWJ0+eREhICCIiInD16lVYWlpqZRtLly7F8uXLsXDhQtStWxdWVlZaKbe4O3jwIGxsbPDq1Svs378f8+fPx5kzZxAZGVlsf/DWqVMHUVFRqFq1aoFvWy6Xo3v37ti8eTO6deuGsLAw2NjY4MqVK5g9ezY2bNiAffv2oVGjRgUeW27s378fixcvlnyAJqc4du7ciRIlShR8UEREVKTNnDkTHTt2RNu2baUOJc8ePXqEKVOmwNPTU9ILonKK44svvoCfn580gRERFXIZfTiZubq66mRb169fx5QpU+Dj4wNPT0+dbCM/zpw5g8DAQAghMHToUHh7e8PExAS3bt3CunXrUL9+fcTHx0sdJiIjIzFlyhQEBwejZMmSUocDADA3N8exY8cAAPHx8di4cSOmTp2KmzdvYvPmzVrbzogRI/Dnn39i1apVcHZ2houLi9bKJtJHHJyhXKtWrRrq1asHAPD19UV6ejqmTZuGXbt2oUePHvkq+82bN7CwsMBff/0Fc3Nzlav68uvt27cwNzfXWnmFUd26dWFvbw8AaN68OZ49e4Zff/0VkZGR2Q4AZOyTglCQ28pQokQJfPLJJwW6zQyzZs3C5s2b8cMPP2Ds2LHK5T4+PujSpQsaNGiADh064ObNmwV6QibFftB1HLVr19ZKOURExZm+HB8oZ6mpqcq73KX09u1bmJmZaeUCoNKlS6N06dJaiIqIqPjJ3IdTWGnj2Pby5Ut8/vnnMDMzQ2RkpMpxxcfHBwMHDsS2bdu0EW6RZGBgoNJ34u/vj3v37mHLli2YM2cO3Nzc8ly2EAJJSUkwNzfHX3/9hfr162vtwpf09HSkpaXB1NRUK+URaRunNaN8y/hyvn//PgDFl+qSJUtQq1YtmJubo1SpUujYsSP+/fdflfV8fHxQrVo1nDx5Eg0bNoSFhQX69u0LmUyGX375BW/fvlXeMhkWFgYASEpKwvjx41G2bFmYmJjAzc0NQ4YMyXKrp6enJwIDA7Fjxw7Url0bZmZmmDJlinIKqw0bNmDs2LFwcXGBlZUVWrdujcePH+PVq1cYMGAA7O3tYW9vjz59+iAxMVGl7MWLF+PTTz+Fo6MjLC0tUb16dYSGhiI1NVVt/c6ePYvGjRvDwsIC5cqVww8//AC5XK6S98WLFxg1ahTKlSsHU1NTODo6olWrVrh586YyT0pKCqZPn47KlSvD1NQUDg4O6NOnD+Li4rS277LbJwAQHR2Nnj17wtHREaampqhSpQp++umnLHV5+PAhOnbsCGtra5QsWRI9evTA2bNnVfYjoLgt1srKClevXkWLFi1gbW2Npk2b5qqux44dg4+PD+zs7GBubo4yZcqgQ4cOePPmjTLP0qVLUbNmTVhZWcHa2hqVK1fGt99+q3w9u2nN9uzZA29vb1hYWMDa2hrNmzdHVFSUSp6MKTauXbuGbt26wcbGBk5OTujbty8SEhJybPuUlBTMnj0bVapUwZgxY7K87uTkhJCQEDx+/BgrV64EAAwfPhyWlpZ4+fJllvxdunSBk5OTyvtw8+bN8Pb2hqWlJaysrNCyZUtcvHhRZb2c9oMmgoODsXjxYgBQuc054zb2/H4fZNSjRYsWcHFxgbm5OapUqYJx48bh9evXGsehblozTd7T9+7dg0wmw48//og5c+agbNmysLKygre3N06fPq1S3r///ouuXbvC1dUVpqamcHJyQtOmTSWfJoaIio6M7+ybN2+iZcuWsLS0hIuLC3744QcAwOnTp/G///0PlpaWqFSpEtasWaOyfsb0JuHh4ejTpw9sbW1haWmJ1q1b5+p7+UPfn6mpqXB0dERQUFCWOrx48QLm5uYYOXKkctnLly8xevRolfO74cOHq3zPA++m41q9ejW8vLxgbm6OevXq4fTp0xBCYPbs2crv6c8++wx37tzJsv0jR46gadOmKFGiBCwsLNCoUSMcPXpUJY+mx3eZTIbXr19jzZo1yuOOj49Ptvsv45gSGhqKGTNmoEyZMjAzM0O9evWyxAAAt2/fRvfu3VXaOeNYlyHjPObXX3/FqFGj4ObmBlNTU7V1V+fEiRP4+OOPAQB9+vRR1iPzXajnzp1DmzZtYGtrCzMzM9SuXRtbtmxRKSfjvXX48GH07dsXDg4OsLCwQHJyMu7cuYM+ffqgYsWKsLCwgJubG1q3bo2rV69qHIe6ac3kcjlCQ0OV54uOjo7o1asXHj58qJIvN+fkRETFkSa/G8+dO4euXbvC09MT5ubm8PT0RLdu3ZR9CYDiWNCpUycAigt53+/PyW6qaR8fH5Xj54eObZocy9VZsWIFYmNjERoamu2Af8eOHVXSmvQLBAcHq71LSN2xK+Nc5tdff0WVKlVgYWGBmjVrYt++fSrrffPNNwCAsmXLKtsxu6nY582bB5lMpvbYP3bsWJiYmODp06cAgIsXLyIwMFB5buHq6oqAgIAsx05Nvd+nlNtzumXLlqFKlSowNTVVnk/duXMHBw4cyPKbPje/30NDQzF9+nSULVsWpqamOH78uHJ/XLlyBZ06dYKNjQ1sbW0xcuRIpKWl4datW/Dz84O1tTU8PT0RGhqqEnNSUhJGjRqFWrVqKdf19vbG7t27s7SLJvs5w82bN9GtWzc4OTnB1NQUZcqUQa9evZCcnKzMExsbi4EDB6J06dLKxxRMmTIFaWlpedpvpGcEkYZWr14tAIizZ8+qLJ8/f74AIH7++WchhBD9+/cXxsbGYtSoUeLgwYNiw4YNonLlysLJyUnExsYq12vSpImwtbUV7u7uYuHCheL48eMiIiJCREVFiVatWglzc3MRFRUloqKixJMnT4RcLhctW7YURkZGYuLEieLw4cPixx9/FJaWlqJ27doiKSlJWbaHh4dwcXER5cqVE6tWrRLHjx8XZ86cEcePHxcAhIeHhwgODhYHDx4Uy5YtE1ZWVsLX11c0b95cjB49Whw+fFjMmjVLGBoaiq+++kqlviNGjBBLly4VBw8eFMeOHRNz584V9vb2ok+fPir5mjRpIuzs7ETFihXFsmXLRHh4uBg8eLAAINasWaPM9/LlS/HRRx8JS0tLMXXqVHHo0CGxfft2MWzYMHHs2DEhhBDp6enCz89PWFpaiilTpojw8HDxyy+/CDc3N1G1alXx5s2bHPfdpEmTBAARFxeXpS4AxOHDh3PcJ0+ePBFubm7CwcFBLFu2TBw8eFAMHTpUABBffvmlsrzExERRoUIFYWtrKxYvXiwOHTokRowYIcqWLSsAiNWrVyvz9u7dWxgbGwtPT08REhIijh49Kg4dOqRxXe/evSvMzMxE8+bNxa5du8SJEyfE+vXrRVBQkIiPjxdCCLFx40YBQHz11Vfi8OHD4siRI2LZsmXi66+/VsaR8Z44fvy4ctn69esFANGiRQuxa9cusXnzZlG3bl1hYmIifv/99yzt6uXlJb7//nsRHh4u5syZI0xNTbO8H94XGRkpAIixY8dmm+fVq1fCwMBAtGzZUgghxOXLlwUAsWLFCpV88fHxwtTUVIwcOVK5bMaMGUImk4m+ffuKffv2iR07dghvb29haWkprl279sH9kJ33vwfu3LkjOnbsKAAoP69RUVHKz2N+vw+EEGLatGli7ty54rfffhMnTpwQy5YtE2XLlhW+vr7K9T8Uh4eHh+jdu7cyv6bv6bt37woAwtPTU/j5+Yldu3aJXbt2ierVq4tSpUqJFy9eKPN6eXmJChUqiF9//VVERESI7du3i1GjRqm8t4iINKXuvKt3797CxMREVKlSRcyfP1+Eh4eLPn36CABi/PjxolKlSmLlypXi0KFDIjAwUAAQ586dy1Kmu7u76Nu3rzhw4ID4+eefhaOjo3B3d1ceP4XI/znBiBEjhLm5uUhISFCp15IlSwQAceXKFSGEEK9fvxa1atUS9vb2Ys6cOeLIkSNi/vz5wsbGRnz22WdCLpcr1804h2vYsKHYsWOH2Llzp6hUqZKwtbUVI0aMEJ9//rnYt2+fWL9+vXBychI1atRQWf/XX38VMplMtG3bVuzYsUPs3btXBAYGCkNDQ3HkyBFlPk2P71FRUcLc3Fy0atVKedzJfIx9X8Yxxd3dXfzvf/8T27dvF1u3bhUff/yxMDY2FpGRkcq8165dEzY2NqJ69epi7dq14vDhw2LUqFHCwMBATJ48WZkv4zzGzc1NdOzYUezZs0fs27dPPHv2LNs4AIghQ4YIIYRISEhQvi++++47ZT0ePHgghBDi2LFjwsTERDRu3Fhs3rxZHDx4UAQHB2c5r8sow83NTQwYMEAcOHBAbNu2TaSlpYmIiAgxatQosW3bNhERESF27twp2rZtK8zNzcXNmzc1iiNjn2Q2YMAAAUAMHTpUeU7v4OAg3N3dVc55NT0nJyIqajK+V0+fPi1SU1NV/jJo+rtx69at4vvvvxc7d+4UERERYtOmTaJJkybCwcFB+Z375MkTMXPmTAFALF68WKU/R4isv8kyNGnSRDRp0kSZzunYpumxXJ0WLVoIQ0NDkZiYqFH7adov0Lt3b+Hh4ZFlfXXHrozflvXr1xdbtmwR+/fvFz4+PsLIyEj8888/QgghHjx4IL766isBQOzYsUPZju+fU2WIi4sTJiYmYsKECSrL09LShKurq2jfvr0QQtFfY2dnJ+rVqye2bNkiIiIixObNm8WgQYPE9evXc2yL3r17C0tLyyzL27VrJwCIv//+O9fndG5ubqJGjRpiw4YN4tixY+LSpUsiKipKODs7i0aNGqn8ps/t73c3Nzfh6+srtm3bJg4fPizu3r2rcn43bdo0ER4eLsaMGaM8l6hcubJYsGCByvn19u3blWW/ePFCBAcHi19//VUcO3ZMHDx4UIwePVoYGBhkOZ/QZD8LIcSlS5eElZWV8PT0FMuWLRNHjx4V69atE507dxYvX74UQggRExMj3N3dhYeHh1i+fLk4cuSImDZtmjA1NRXBwcE57jcqHDg4Qxp7/8D+6tUrsW/fPuHg4CCsra1FbGysiIqKEgDETz/9pLLugwcPhLm5uRgzZoxyWZMmTQQAcfTo0SzbUvfFf/DgQQFAhIaGqizfvHmzyuCQEIqDvqGhobh165ZK3oyDfOvWrVWWDx8+XABQ6bQXQoi2bdsKW1vbbNskPT1dpKamirVr1wpDQ0Px/PnzLPX7888/VdapWrWqsrNdCCGmTp0qAIjw8PBst5MxyJD5wCCEEGfPnhUAxJIlS7JdV4h3JwWxsbEiNTVVxMfHi3Xr1glzc3Ph7u4u3r59qxLz+/tk3Lhxauvy5ZdfCplMpmznxYsXCwDiwIEDKvkGDhyodnAGgFi1alWe6rpt2zYBQFy6dCnbeg8dOlSULFkyx7Z5f3AmPT1duLq6iurVq4v09HRlvlevXglHR0fRsGFD5bKMdn3/PTl48GBhZmamcvLxvk2bNgkAYtmyZTnG5+TkJKpUqaJM16lTRyUGId51dF29elUIIUR0dLQwMjLKMrD46tUr4ezsLDp37qxclt1+yI66zsIhQ4ZkOekUQmjt+yAzuVwuUlNTRUREhAAgLl++/ME4hMj6Q0DT93TGyV316tVFWlqaMt+ZM2cEALFx40YhhBBPnz4VAMS8efNyjJ+ISFPZDc68f4xMTU0VDg4OAoC4cOGCcvmzZ8+EoaGhysB9Rpnt2rVT2dYff/whAIjp06crl+X3nODKlStZzs+EEKJ+/fqibt26ynRISIgwMDDIcvFPxnF+//79ymUAhLOzs0qnyq5duwQAUatWLZXj7rx587IMAtna2mY5B0xPTxc1a9YU9evXVy7LzfHd0tJSbUeTOhnHFFdXV+W5lxCKC3VsbW1Fs2bNlMtatmwpSpcunaUjZujQocLMzEx5zplxHvPpp59qFIMQqoMzQrw7x8p8npahcuXKonbt2iodeUIIERgYKFxcXJTnShnvrV69en1w+2lpaSIlJUVUrFhRjBgxQqM43u/gunHjhgAgBg8erJLvzz//FADEt99+q1ym6Tk5EVFRk/HdrO4vNTU1V78b35eWliYSExOFpaWlmD9/vnL51q1bs1z8mCG3gzPvH9tycyxXp3LlysLZ2TnHPJnL1LRfILeDM05OTsqOdyGEiI2NFQYGBiIkJES5bPbs2QKAuHv3rkbxtm/fXpQuXVol1v379wsAYu/evUIIIc6dOycAiF27dmlUZmYZfXQZg3txcXFi/vz5QiaTiY8//lgIkftzOhsbG5U+tAweHh4iICBAZVluf7+XL19epKSkqOTN2B/v90/UqlVLORCWIeP8OmNgS520tDSRmpoq+vXrJ2rXrq3ymqb7+bPPPhMlS5ZUDmCqM3DgQGFlZSXu37+vsvzHH38UAHK8MIgKB05rRrn2ySefwNjYGNbW1ggMDISzszMOHDgAJycn7Nu3DzKZDD179kRaWpryz9nZGTVr1sxyG2apUqXw2WefabTdjAePvX8bbKdOnWBpaZnlNtYaNWqgUqVKassKDAxUSVepUgUAEBAQkGX58+fPVaY2u3jxItq0aQM7OzsYGhrC2NgYvXr1Qnp6Ov7++2+V9Z2dnVG/fv0scWW+9ffAgQOoVKkSmjVrll3VsW/fPpQsWRKtW7dWaddatWrB2dk529tb3+fs7AxjY2OUKlUKPXv2RJ06dXDw4EGYmZkp86jbJ8eOHUPVqlWz1CU4OBhCCOW+iYiIgLW1dZYHtnbr1i3bmDp06JCnutaqVQsmJiYYMGAA1qxZk2U6FgCoX78+Xrx4gW7dumH37t3KW3lzcuvWLTx69AhBQUEwMHj3FWllZYUOHTrg9OnTKtOmAUCbNm1U0jVq1EBSUhKePHnywe19iBBC5VboPn36IDIyErdu3VIuW716NT7++GNUq1YNAHDo0CGkpaWhV69eKm1oZmaGJk2aqH2/vL8ftEFb3wf//vsvunfvDmdnZ+VnrkmTJgCAGzdu5Ck2Td/TGQICAmBoaKhM16hRA8C727dtbW1Rvnx5zJ49G3PmzMHFixc5VQoR6YRMJkOrVq2UaSMjI1SoUAEuLi4qz9eytbWFo6OjyjlHhvefEdiwYUN4eHjg+PHjKsvzc05QvXp11K1bF6tXr1bmuXHjBs6cOaOcHg1QHCuqVauGWrVqqRwrWrZsqXYKD19fX1haWirTGedw/v7+KsfLjOUZ9Y+MjMTz58/Ru3dvle3I5XL4+fnh7NmzWabc0NXxvX379irnXtbW1mjdujVOnjyJ9PR0JCUl4ejRo2jXrh0sLCxU4m3VqhWSkpKyTK2pi+P4nTt3cPPmTeX75f04YmJiVM5HsosjLS0NM2fORNWqVWFiYgIjIyOYmJjg9u3beT6OZ7xX3/9dUL9+fVSpUiXL7wJNzsmJiIqqtWvX4uzZsyp/RkZGufrdmJiYiLFjx6JChQowMjKCkZERrKys8Pr16zx/l3/I+8eUvBzL8yov/QKa8vX1hbW1tTLt5OSU7Tmbpvr06YOHDx/iyJEjymWrV6+Gs7Mz/P39AQAVKlRAqVKlMHbsWCxbtgzXr1/P1TZev34NY2NjGBsbw8HBAcOHD4e/vz927twJIPfndJ999hlKlSql0bZz+/u9TZs2MDY2VluWuv5AmUymbCfg3fn1+/tk69ataNSoEaysrGBkZARjY2OsXLlS7WfgQ/v5zZs3iIiIQOfOneHg4JBt3fft2wdfX1+4urqqtGtGvBEREdmuS4WDtE+JpEJp7dq1qFKlCoyMjODk5AQXFxfla48fP4YQAk5OTmrXLVeunEo687of8uzZMxgZGWX50pLJZHB2dsazZ880LtvW1lYlbWJikuPypKQkWFlZITo6Go0bN4aXlxfmz58PT09PmJmZ4cyZMxgyZAjevn2rsr6dnV2WbZuamqrki4uLQ5kyZbKNFVC064sXL5TxvE+TQQdAMTerjY0NjI2NUbp0abXxqWu3Z8+eqZ1D1dXVVfl6xr/q9n127wcLCwuUKFFCZZmmdS1fvjyOHDmC0NBQDBkyBK9fv0a5cuXw9ddfY9iwYQCAoKAgpKWlYcWKFejQoQPkcjk+/vhjTJ8+Hc2bN1dbfkZd1LWDq6sr5HI54uPjVR6I/H47Zjxo7v33Q2YZ+/zu3bvZ5nn9+jWePn2q0tnWo0cPjB49GmFhYQgJCcH169dx9uxZLFmyRJnn8ePHAKCcu/19mU8uAfX7QRu08X2QmJiIxo0bw8zMDNOnT0elSpVgYWGBBw8eoH379jm2cU40fU9n+NA+lslkOHr0KKZOnYrQ0FCMGjUKtra26NGjB2bMmKFyUkZElB8WFhYqHfuA4nzl/XOYjOVJSUlZljs7O6tdpsm5VG6+P/v27YshQ4bg5s2bqFy5MlavXg1TU1OVizYeP36MO3fuZPsD+v1znLycw2VsB8g6l3xmz58/Vxn4ycvxXRPZtX9KSgoSExORmJiItLQ0LFy4EAsXLlRbxvvtkptzak1ltNno0aMxevToPMcxcuRILF68GGPHjkWTJk1QqlQpGBgY4IsvvsjXcTy77bm6umbpTNHknJyIqKiqUqUK6tWrl2V5bn43du/eHUePHsXEiRPx8ccfo0SJEsoLRnT1Xfr+d3xejuWZlSlTBrdv38br16+zzZMhL/0CmtLFMcnf3x8uLi5YvXo1WrRogfj4eOzZswfDhg1TXmRoY2ODiIgIzJgxA99++y3i4+Ph4uKC/v3747vvvsv2XCyDubk5Tp48qYzXw8NDpR8ht+d0ue0PzM3v99z2B2Z3fp35eb87duxA586d0alTJ3zzzTdwdnaGkZERli5dilWrVmXZzof2c3x8PNLT07N9/lGGx48fY+/evRq3KxU+HJyhXMvuwA4A9vb2kMlk+P3335U/YDN7f9n7D0fLiZ2dHdLS0hAXF6cyQCOEQGxsbJYTityUraldu3bh9evX2LFjBzw8PJTL8/PAbwcHhw8+fM3e3h52dnY4ePCg2tc17fitWbMm7O3tc8yjrt3s7OwQExOTZfmjR4+U8WXkO3PmTJZ8sbGxGm8rN3Vt3LgxGjdujPT0dJw7dw4LFy7E8OHD4eTkhK5duwJQXEHSp08fvH79GidPnsSkSZMQGBiIv//+W2UfZq4rgGzra2BgoPHVHTmpW7cuSpUqhT179iAkJERtW+zZswdyuVxlIKlUqVL4/PPPsXbtWkyfPh2rV6+GmZmZSkdXxv7Ytm2b2jq+TxeflYw48vt9cOzYMTx69AgnTpxQ3i0DKB4onR+avqdzw8PDAytXrgQA/P3339iyZQsmT56MlJQULFu2LF/xEhFpk7rjcmxsLCpUqKCyLD/nBIDiztmRI0ciLCwMM2bMwK+//oq2bduqHEft7e1hbm6u9kft++XlR0Y5CxcuVD689n3ZXUygbdm1v4mJCaysrGBsbAxDQ0MEBQVhyJAhassoW7asSloXx/KMNhs/fjzat2+vNo+Xl9cH41i3bh169eqFmTNnqix/+vQpSpYsmafYMp+vvd+p8ejRI629b4iIijJNfzcmJCRg3759mDRpEsaNG6dcnpycjOfPn2u8PTMzM5WHnGd4+vSp2u/t948p+T2Wt2zZEocPH8bevXuV/QXZyU2/QE71KigZ5w0LFizAixcvsGHDBiQnJ6NPnz4q+apXr45NmzZBCIErV64gLCwMU6dOhbm5ucq+VcfAwCDbvkAg9+d0ue0PzM3vd12cF61btw5ly5bF5s2bVcpXt+81YWtrC0NDQ436A2vUqIEZM2aofT1jgIoKL05rRloVGBgIIQT+++8/1KtXL8tf9erV81x206ZNASi+EDPbvn07Xr9+rXxdlzK+gDN3KgshsGLFijyX6e/vj7///jvLbZiZBQYG4tmzZ0hPT1fbru//MNa2pk2b4vr167hw4YLK8rVr10Imk8HX1xcA0KRJE7x69QoHDhxQybdp0yaNt5WXuhoaGqJBgwZYvHgxAGSJEwAsLS3h7++PCRMmICUlBdeuXVO7fS8vL7i5uWHDhg0QQiiXv379Gtu3b4e3t3eero55n4mJCb755hvcuHEDs2fPzvL6kydPMH78eDg5OeGLL75Qea1Pnz549OgR9u/fj3Xr1qFdu3YqnRstW7aEkZER/vnnH7VtmNMJVV5kdyWxNr4P1H3mAGD58uUax6GOpu/pvKpUqRK+++47VK9eXe37kYhISuvXr1dJR0ZG4v79+/Dx8fngurn5/ixVqhTatm2LtWvXYt++fYiNjVWZ0gxQHCv++ecf2NnZqT1WqLtKMi8aNWqEkiVL4vr169keG7O7azcnebnSdceOHSp3NL169Qp79+5F48aNYWhoCAsLC/j6+uLixYuoUaOG2ljVXY2ZV9kdP728vFCxYkVcvnw52zbT5AIhmUyW5Tj+22+/4b///tMoDnUyptt7/3fB2bNncePGjQL5XUBEVNhp+rtRJpNBCJHlu/yXX35Benq6yrKcvss9PT1x5coVlWV///13likys5PfY3m/fv3g7OyMMWPGZDkGZdixYweA3PULeHp64smTJ8o7ewAgJSUFhw4d0qhe6uTlbt0+ffogKSkJGzduRFhYGLy9vVG5cmW1eWUyGWrWrIm5c+eiZMmSWvnNqstzOl3/fteETCaDiYmJysBMbGwsdu/enafyzM3N0aRJE2zdujXHgbzAwED89ddfKF++vNp25eBM4cc7Z0irGjVqhAEDBqBPnz44d+4cPv30U1haWiImJganTp1C9erV8eWXX+ap7ObNm6Nly5YYO3YsXr58iUaNGuHKlSuYNGkSateujaCgIC3XRn0MJiYm6NatG8aMGYOkpCQsXboU8fHxeS5z+PDh2Lx5Mz7//HOMGzcO9evXx9u3bxEREYHAwED4+vqia9euWL9+PVq1aoVhw4ahfv36MDY2xsOHD3H8+HF8/vnnaNeunRZrqmrEiBFYu3YtAgICMHXqVHh4eOC3337DkiVL8OWXXyqf7dO7d2/MnTsXPXv2xPTp01GhQgUcOHBAeVLy/nRa6mha12XLluHYsWMICAhAmTJlkJSUpLxCI+P5Pf3794e5uTkaNWoEFxcXxMbGIiQkBDY2Njneuh0aGooePXogMDAQAwcORHJyMmbPno0XL17ghx9+0EaTAgDGjh2Ly5cvK//t0qULbGxscOXKFcyePRuvXr3Cvn37YGNjo7JeixYtULp0aQwePBixsbFZrobx9PTE1KlTMWHCBPz777/w8/NDqVKl8PjxY5w5cwaWlpaYMmWK1uqRMcgya9Ys+Pv7w9DQEDVq1NDK90HDhg1RqlQpDBo0CJMmTYKxsTHWr1+Py5cvaxyHuhN0Td/Tmrpy5QqGDh2KTp06oWLFijAxMcGxY8dw5cqVD16BRERU0M6dO4cvvvgCnTp1woMHDzBhwgS4ublh8ODBH1w3t9+fffv2xebNmzF06FCULl06yzP2hg8fju3bt+PTTz/FiBEjUKNGDcjlckRHR+Pw4cMYNWoUGjRokO86W1lZYeHChejduzeeP3+Ojh07wtHREXFxcbh8+TLi4uKwdOnSXJdbvXp1nDhxAnv37oWLiwusra0/eNGMoaEhmjdvjpEjR0Iul2PWrFl4+fKlyrF5/vz5+N///ofGjRvjyy+/hKenJ169eoU7d+5g7969OV7Uk1vly5eHubk51q9fjypVqsDKygqurq5wdXXF8uXL4e/vj5YtWyI4OBhubm54/vw5bty4gQsXLmDr1q0fLD8wMBBhYWGoXLkyatSogfPnz2P27NlZ7njJKY73eXl5YcCAAVi4cCEMDAzg7++Pe/fuYeLEiXB3d8eIESO01j5EREWVpr8bS5QogU8//RSzZ8+Gvb09PD09ERERgZUrV2a5AzLjOag///wzrK2tYWZmhrJly8LOzg5BQUHo2bMnBg8ejA4dOuD+/fsIDQ3N8XkbmeX3WG5jY4Pdu3cjMDAQtWvXxtChQ+Ht7a18Dtq6detw+fJltG/fPlf9Al26dMH333+Prl274ptvvkFSUhIWLFiQZeAqNzJ+286fPx+9e/eGsbExvLy8crwoonLlyvD29kZISAgePHiAn3/+WeX1ffv2YcmSJWjbti3KlSsHIQR27NiBFy9eZDvte27o8pxO27/f8yIwMBA7duzA4MGD0bFjRzx48ADTpk2Di4sLbt++nacy58yZg//9739o0KABxo0bhwoVKuDx48fYs2cPli9fDmtra0ydOhXh4eFo2LAhvv76a3h5eSEpKQn37t3D/v37sWzZsg9OjUZ6ThBpaPXq1QKAOHv27Afzrlq1SjRo0EBYWloKc3NzUb58edGrVy9x7tw5ZZ4mTZqIjz76SO36vXv3FpaWllmWv337VowdO1Z4eHgIY2Nj4eLiIr788ksRHx+vks/Dw0MEBARkWf/48eMCgNi6datGdZs0aZIAIOLi4pTL9u7dK2rWrCnMzMyEm5ub+Oabb8SBAwcEAHH8+PEP1q93797Cw8NDZVl8fLwYNmyYKFOmjDA2NhaOjo4iICBA3Lx5U5knNTVV/Pjjj8ptW1lZicqVK4uBAweK27dvZ9nOh+qhTk775P79+6J79+7Czs5OGBsbCy8vLzF79myRnp6uki86Olq0b99eWFlZCWtra9GhQwexf/9+AUDs3r1bpR3U7WNN6xoVFSXatWsnPDw8hKmpqbCzsxNNmjQRe/bsUZazZs0a4evrK5ycnISJiYlwdXUVnTt3FleuXFHmyXhPZN53Qgixa9cu0aBBA2FmZiYsLS1F06ZNxR9//KFRu2a8n+7evau+oTORy+Vi/fr1wsfHR5QsWVKYmJiIsmXLii+//FLcv38/2/W+/fZbAUC4u7tn2QeZ6+Dr6ytKlCghTE1NhYeHh+jYsaM4cuSIMk9O+0EddZ+V5ORk8cUXXwgHBwchk8my1D2/3weRkZHC29tbWFhYCAcHB/HFF1+ICxcuCABi9erVGsXh4eEhevfurVKuJu/pu3fvCgBi9uzZWeICICZNmiSEEOLx48ciODhYVK5cWVhaWgorKytRo0YNMXfuXJGWlqZh6xIRvaPu+za77+zsvkPfPx/KKPPw4cMiKChIlCxZUpibm4tWrVplOZfQxjmBEEKkp6cLd3d3AUBMmDBBbXmJiYniu+++E15eXsLExETY2NiI6tWrixEjRojY2FhlPgBiyJAhKutm9z2d3TlfRESECAgIELa2tsLY2Fi4ubmJgIAAlXy5Ob5funRJNGrUSFhYWAgAokmTJmrrmDnWWbNmiSlTpojSpUsLExMTUbt2bXHo0CG1+fv27Svc3NyEsbGxcHBwEA0bNhTTp0//YD1zoq4dN27cKCpXriyMjY1Vjm9CCHH58mXRuXNn4ejoKIyNjYWzs7P47LPPxLJly7K0jbrfCfHx8aJfv37C0dFRWFhYiP/973/i999/F02aNMnSXtnFkbFPMktPTxezZs0SlSpVEsbGxsLe3l707NlTPHjwQCVfbs7JiYiKEk37cDT53fjw4UPRoUMHUapUKWFtbS38/PzEX3/9pfZ31rx580TZsmWFoaGhym82uVwuQkNDRbly5YSZmZmoV6+eOHbsWJbjwYeObZocy3MSGxsrxo4dKz766CNhYWEhTE1NRYUKFcTAgQPF1atXs7TNh/oFhBBi//79olatWsLc3FyUK1dOLFq0SO2xS90xWAj1v1fHjx8vXF1dhYGBgdo+C3V+/vlnAUCYm5uLhIQElddu3rwpunXrJsqXLy/Mzc2FjY2NqF+/vggLC/tguZr2G+TnnC5Ddv15+f39nt35XW7Or3/44Qfh6ekpTE1NRZUqVcSKFSvyvZ+vX78uOnXqJOzs7ISJiYkoU6aMCA4OFklJSco8cXFx4uuvvxZly5YVxsbGwtbWVtStW1dMmDBBJCYmZtkOFS4yITLdn0dEpAMzZ87Ed999h+joaI7oExERSSQsLAx9+vTB2bNntT7FJX3YvXv3ULZsWcyePRujR4+WOhwiIiIiIpIYpzUjIq1atGgRAMUttampqTh27BgWLFiAnj17cmCGiIiIiIiIiIiICBycISIts7CwwNy5c3Hv3j0kJyejTJkyGDt2LL777jupQyMiIiIiIiIiIiLSC5zWjIiIiIiIiIiIiIiIqAAZSB0AERERkb5bsmQJypYtCzMzM9StWxe///57jvkjIiJQt25dmJmZoVy5cli2bFmWPNu3b0fVqlVhamqKqlWrYufOnboKn4iIiIiIiIj0DAdniIiIiHKwefNmDB8+HBMmTMDFixfRuHFj+Pv7Izo6Wm3+u3fvolWrVmjcuDEuXryIb7/9Fl9//TW2b9+uzBMVFYUuXbogKCgIly9fRlBQEDp37ow///yzoKpFRERERERERBLitGZEREREOWjQoAHq1KmDpUuXKpdVqVIFbdu2RUhISJb8Y8eOxZ49e3Djxg3lskGDBuHy5cuIiooCAHTp0gUvX77EgQMHlHn8/PxQqlQpbNy4UYe1ISIiIiIiIiJ9YCR1AIWVXC7Ho0ePYG1tDZlMJnU4REREekEIgVevXsHV1RUGBoX/Bt2UlBScP38e48aNU1neokULREZGql0nKioKLVq0UFnWsmVLrFy5EqmpqTA2NkZUVBRGjBiRJc+8efOyjSU5ORnJycnKtFwux/Pnz2FnZ8dzESIiov9X1M5F9Bn7RYiIiLLKzbkIB2fy6NGjR3B3d5c6DCIiIr304MEDlC5dWuow8u3p06dIT0+Hk5OTynInJyfExsaqXSc2NlZt/rS0NDx9+hQuLi7Z5smuTAAICQnBlClT8lgTIiKi4qWonIvoM/aLEBERZU+TcxEOzuSRtbU1AEUjlyhRQitlyuVyxMXFwcHBoUhc4VOU6lOU6gKwPvqO9dFvRak+uqjLy5cv4e7urjxOFhXvXw0qhMjxClF1+d9fntsyx48fj5EjRyrTCQkJKFOmDO7cuaPd9n5v0EgKcgMDPK1ZE/aXL8NALpc6HJ1hPSXw+LFOipXL5Xj69Cns7e11c2zQg88loGf7UkeKQx0BPaunlj+Xr169QoUKFYrcuYg+Yr+I/mH75R3bLn/YfvnD9ss7fWy73PSLSDo4c/LkScyePRvnz59HTEwMdu7cibZt2ypf37FjB5YvX47z58/j2bNnuHjxImrVqpVjmStWrMDatWvx119/AQDq1q2LmTNnon79+so8kydPznLl6YeuVn1fRudJiRIltHoSkpSUhBIlSujNmyk/ilJ9ilJdANZH37E++q0o1UeXdSkqU1vY29vD0NAwyznCkydPstz5ksHZ2VltfiMjI9jZ2eWYJ7syAcDU1BSmpqZZljs4OGjtXERfyAHAyAiOAAr3pyxnrKcEHB11Uqz8/zu3HR0dC/2xISd6tS91pDjUEdCzemr5c2lmZgag8JyLsF9EVVE615YC2y/v2Hb5w/bLH7Zf3ulz22lyLiJpxK9fv0bNmjWxaNGibF9v1KgRfvjhB43LPHHiBLp164bjx48jKioKZcqUQYsWLfDff/+p5Pvoo48QExOj/Lt69Wq+6kJERERFj4mJCerWrYvw8HCV5eHh4WjYsKHadby9vbPkP3z4MOrVqwdjY+Mc82RXJhERERVN7BchIiIqviS9c8bf3x/+/v7Zvh4UFAQAuHfvnsZlrl+/XiW9YsUKbNu2DUePHkWvXr2Uy42MjODs7Kxxue8/hPfly5cAFKNzci3dBi6XyyGE0Fp5UitK9SlKdQFYH33H+ui3olQfXdSlKLTL+0aOHImgoCDUq1cP3t7e+PnnnxEdHY1BgwYBUEw39t9//2Ht2rUAgEGDBmHRokUYOXIk+vfvj6ioKKxcuRIbN25Uljls2DB8+umnmDVrFj7//HPs3r0bR44cwalTpySpIxEREUmD/SKqitK5thTYfnnHtssftl/+sP3yTh/bLjexFPlnzrx58wapqamwtbVVWX779m24urrC1NQUDRo0wMyZM1GuXLlsy8nuIbxxcXFISkrSSqxyuRwJCQkQQujdbVh5UZTqU5TqArA++o710W9FqT66qMurV6+0Uo4+6dKlC549e4apU6ciJiYG1apVw/79++Hh4QEAiImJQXR0tDJ/2bJlsX//fowYMQKLFy+Gq6srFixYgA4dOijzNGzYEJs2bcJ3332HiRMnonz58ti8eTMaNGhQ4PUjIiKioo39IsUH2y/v2Hb5w/bLH7Zf3ulj2+WmX6TID86MGzcObm5uaNasmXJZgwYNsHbtWlSqVAmPHz/G9OnT0bBhQ1y7dk05F/z73n8Ib8aDfXKa510IgbS0NKSnp2sUq1wuR1paml7OkZcXhaU+hoaGMDIyynEeQLlcDplMplcPl8oP1ke/sT76rSjVRxd1yZjnvagZPHgwBg8erPa1sLCwLMuaNGmCCxcu5Fhmx44d0bFjR22ER0RERJQtKftFcqsonWtLge2Xd2y7/GH75Q/bL+/0se1y0y9SpAdnQkNDsXHjRpw4cUKlUTLfMly9enV4e3ujfPnyWLNmjcqJRmbZPYTXwMBA7Y5PSUlBTEwM3rx5o3G8GbdgJSYmFpqHF+akMNXHwsICLi4uMDExyTaPTCbLdn8XRqyPfmN99FtRqo+261IU2oSIiIioqJCyXySvitK5thTYfnnHtssftl/+sP3yTt/aLjdxFNnBmR9//BEzZ87EkSNHUKNGjRzzWlpaonr16rh9+7ZWti2Xy3H37l0YGhrC1dUVJiYmGg1OZNxp86G7OAqLwlAfIQRSUlIQFxeHu3fvomLFinrzQSYiIiIiIiLKKyn7RXItLg6IiACePwdMTABra6BJE8DeXpp4iIiICkCRHJyZPXs2pk+fjkOHDqFevXofzJ+cnIwbN26gcePGWtl+SkoK5HI53N3dYWFhofF6hWEwIzcKS33Mzc1hbGyM+/fvIyUlpchOyUNERERERETFg9T9Ihr7919g3Trg0CHFwIyBAeDlBdy6BZQqBfj5AT17Ap6eBRsXERFRAZB0cCYxMRF37txRpu/evYtLly7B1tYWZcqUwfPnzxEdHY1Hjx4BAG7dugUAcHZ2hrOzMwCgV69ecHNzQ0hICADFLbsTJ07Ehg0b4OnpidjYWACAlZUVrKysAACjR49G69atUaZMGTx58gTTp0/Hy5cv0bt3b63Wj3dgFB7cV0RUnCQlAVu3Ajt3yhAbWwrOzjK0awd06gRwfJqIiIio4BT1fpEcnT8PjBsHREcDJUsCZcsCRkaAiwuQnKy4m+bXX4GTJ4HQUKBWrYKLjYiIqABI2iN97tw51K5dG7Vr1wYAjBw5ErVr18b3338PANizZw9q166NgIAAAEDXrl1Ru3ZtLFu2TFlGdHQ0YmJilOklS5YgJSUFHTt2hIuLi/Lvxx9/VOZ5+PAhunXrBi8vL7Rv3x4mJiY4ffo0PDw8CqLaREREktmzB3B1BXr1AnbvBqKiTLF7tyLt6grs3St1hERERETFR7HtF7lzBxgzBnj4EChfHnB0BAwN371uaAg4OSlee/BAkffffwsmNiIiogIi6Z0zPj4+EEJk+3pwcDCCg4NzLOPEiRMq6Xv37n1wu5s2bdIgOullXNm8axfw7BlgZwe0bcsrm4mIKG/27FEcRzLI5TKVf1+8AD7/XHHcadOmwMMjIiIiKnaKbb9IWJhi0KViRcVUZtkxNFTcUXPnDrBmDTBlSoGFSEREpGucy0lPZb6yedcuxXPxdu3ilc1ERJQ3SUlAxu/67H7/ZywPDlbkJyIiIiLSupgY4OhRxRWomkwxbmgI2NoC4eHAkye6j4+IiKiAcHBGD2Vc2fzihSItl6v+m3Fl85492t92cHAwZDIZBg0alOW1wYMHQyaTZblqJzIyEoaGhvDz88uyzr1792BgYACZTAaZTIZSpUrh008/RURERJZtvv+nrjwiIsqbrVuB+PjsB2YyCKHIt21bwcRFRERERMXMsWOKjg1bW83XsbVVnKQeP66zsIiIiAoaB2f0TFIS0KeP4v9SXdns7u6OTZs24e3bt5niSsLGjRtRpkyZLPlXrVqFr776CqdOnUJ0dLTaMo8cOYKYmBhERESgRIkSaNWqFe7evat83c/PDzExMSp/Gzdu1H7liIiKqV27NLswEVDk27lTp+EQERERUXH19KniX01PTgHF3TMy2bt1iYiIigAOzuiZbdtkiI+XSXplc506dVCmTBns2LFDuWzHjh1wd3dXPqQww+vXr7FlyxZ8+eWXCAwMRFhYmNoy7ezs4OzsjBo1amD58uV48+YNDh8+rHzd1NQUzs7OKn+lSpXSfuWIiIqpZ8/e3YH5IXI58Py5buMhIiIiomLqQx0eulqXiIhIz3BwpgDVqweULp39n7s7MHiwIQDNTzb698+5zHr18hZrnz59sHr1amV61apV6Nu3b5Z8mzdvhpeXF7y8vNCzZ0+sXr06x4cZAoCFhQUAIDU1NW/BERFRrmk6pTegyJebWSaIiIiIiDRmZ6f4V9MrhzLyCgHwIk4iIipCODhTgGJjgf/+y+lPhqQkGQCZxmUmJeVcZmxs3mINCgrCqVOncO/ePdy/fx9//PEHevbsmSXfypUrlcv9/PyQmJiIo0ePZlvu69evMX78eBgaGqJJkybK5fv27YOVlZXK37Rp0/IWPBERZdG2be7unGnXTqfhEBEREVFx1aQJUKKEYjoQTT1/DtjYAD4+OguLiIiooBlJHUBx4uz8oRwCz55lPEdGswEaM7N3F53kbZvq2dvbIyAgAGvWrIEQAgEBAbC3t1fJc+vWLZw5c0Y5/ZmRkRG6dOmCVatWoVmzZip5GzZsCAMDA7x58wYuLi4ICwtD9erVla/7+vpi6dKlKuvY8rJtIiKtad5cMVV3enrO+WQyoGRJoGPHAgmLiIiIiIqbMmWATz8F9uxR3Anzodu75XLFHL0dOgBubgUTIxERUQHg4EwBOncu59eFAMLC0tG3r+a7ZcUKQM0NLVrRt29fDB06FACwePHiLK+vXLkSaWlpcMt0ciSEgLGxMeLj41GyZEnl8s2bN6Nq1aooWbIk7NSMJllaWqJChQrarwQRESExEWjfXrOBGQBYs0Yx+E9EREREpBO9ewN//gncuwd4emY/QCOXA3fvAq6uQK9eBRkhERGRznFaMz3TsaNAqVJC2UGWHZlMcYGJLq9s9vPzQ0pKClJSUtCyZUuV19LS0rB27Vr89NNPuHTpkvLv8uXL8PDwwPr161Xyu7u7o3z58moHZoiISHeSkhRTmkVFKdIlSij+AMDAQKj8W7IksHs30Lp1wcdJRERERMVItWrA9OmKqUBu31ZMW5Z5Dl65XLHszh3AwUGRt0oV6eIlIiLSAd45o2fMzICwMEVHmkymuJvmfQV1ZbOhoSFu3Lih/H9m+/btQ3x8PPr16wcbGxuV1zp27IiVK1diyJAhGm8rOTkZse89IMfIyCjLVGpERKS51FSga1cg41FgJUsCJ04AXl7Atm3Ajh1AbGwynJ1N0L69YsCfd8wQERERUYH49FNgyRJg5Urgjz+Af/5R3EFjaAj8+y9gZQUEBgJ9+wIffSR1tERERFrHwRk91Lo1sGsXEByseD6egYHiopGMf0uWVAzMFMSVzSUyLq9+z8qVK9GsWbMsAzMA0KFDB8ycORMXLlzIdv33HTx4EC4uLirLvLy8cPPmzdwHTUREkMsVx5HduxVpS0tg/36gZk1FumdPoHt3gSdP4uHo6AgDA82edUZEREREpDXVqgFz5yqmLjt+XPFsGUtLoE0bwNdXMeUZERFREcXBGT3Vpg3w6JHiyuadOxV389raAu3a6fbK5rCwsBxf37Vr1wfLqFOnDoQQEEIgLS0NcrkcshzmaQsLC/vgdomISHNCAIMHAxs2KNKmpopBGm9vaeMiIiIiIlKrbFnFn1wOPHkCODpm/xwaIiKiIoKDM3rMzExxZXPPnlJHQkREhYUQwJgxwPLlirShIbB1K9C0qbRxERERERERERHRO7wMgYiIqAiZMQP48UfF/2Uy4NdfC2YaTCIiIiIiIiIi0hwHZ4iIiIqI+fOBiRPfpZcvB7p1ky4eIiIiIiIiIiJSj4MzRERERcCqVcDw4e/SP/0E9O8vWThERERERERERJQDDs4QEREVclu2qA7ETJoEjBwpXTxERERERERERJQzDs4QEREVYvv3Az16AHK5Ij1ihGJwhoiIiIiIiIiI9BcHZ4iIiAqpEyeADh2AtDRF+osvFNOZyWSShkVERERERERERB/AwRkiIqJC6MwZoHVrIClJke7SBVi2jAMzRERERERERESFAQdniIiICpmrVwE/PyAxUZEODAR+/RUwNJQ2LiIiIiIiIiIi0gwHZ0jveHp6Yt68ecq0TCbDrl27JIuHiEif3L4NNG8OxMcr0r6+wJYtgLGxtHEREREREREREZHmODhDKoKDgyGTyZR/dnZ28PPzw5UrVySLKSYmBv7+/pJtn4hIX0RHA82aAY8fK9INGgC7dwPm5tLGRUREREREREREucPBGcrCz88PMTExiImJwdGjR2FkZITAwEDJ4nF2doapqalk2yci0gePHysGZqKjFenq1YH9+wFra2njIiIiIiIiIiKi3OPgTEFLSsr+LyVFu3nzyNTUFM7OznB2dkatWrUwduxYPHjwAHFxcQCAsWPHolKlSrCwsEC5cuUwceJEpKamKte/fPkyfH19UaJECdjZ2aFevXo4d+6c8vXIyEh8+umnMDc3h7u7O77++mu8fv0623gyT2t27949yGQy7NixA76+vrCwsEDNmjURFRWlsk5ut0FEpM+eP1dMZXb7tiJdsSJw+DBgayttXERERERERERElDdGUgdQ7HTqlP1rdesCEya8S/fsCSQnq89brRoQEvIu3a8f8PKlap69e/Me5/9LTEzE+vXrUaFCBdjZ2QEArK2tERYWBldXV1y9ehX9+/eHtbU1xowZAwDo0aMHateujSVLlkAIgb/++gvG//8whKtXr6Jly5aYNm0aVq5cibi4OAwdOhRDhw7F6tWrNY5rwoQJ+PHHH1GxYkVMmDAB3bp1w507d2BkZKS1bRAR6YNXr4BWrYCrVxVpd3fgyBHA2VnauIiIiIiIiIiIKO84OENZ7Nu3D1ZWVgCA169fw8XFBfv27YOBgeJGq++++06Z19PTE6NGjcLmzZuVgzPR0dH45ptvULlyZaSlpaFKlSqQyWQAgNmzZ6N79+4YPnw4AKBixYpYsGABmjRpgqVLl8LMzEyjGEePHo2AgAAAwJQpU/DRRx/hzp07qFy5sta2QUQktbdvgc8/B/78U5F2cgKOHgXKlJE2LiIiIiIiIiIiyh8OzhS0rVuzf+3/BzCU1q3LPq/BezPSrVyZ95je4+vri6VLlwIAnj9/jiVLlsDf3x9nzpyBh4cHtm3bhnnz5uHOnTtITExEWloaSpQooVx/5MiR+OKLL/Drr7/C19cXXbp0QYUKFQAA58+fx507d7B+/XplfiEE5HI57t69iypVqmgUY40aNZT/d3FxAQA8efIElStX1to2iIiklJqquNny+HFFulQpxVRmFStKGxcREREREREREeUfB2cKWk53bQgBpKVpljc35eaSpaWlcjAFAOrWrQsbGxusWLECgYGB6Nq1K6ZMmYKWLVvCxsYGmzZtwk8//aTMP3nyZHTv3h379u3DgQMHMHXqVGzatAnt2rWDXC7HwIED8fXXX2fZbplcXAqeMU0aAOVdOXK5XPmvNrZBRCSV9HQgKAj47TdF2soKOHAAyDQuTUREREREREREhRgHZ+iDZDIZDAwM8PbtW/zxxx/w8PDAhEzPxrl//36WdSpVqoQRI0bgq6++Qq9evbB69Wq0a9cOderUwbVr11QGf7StILZBRKQrQgCDBgGbNyvSZmaKR4g1aCBtXEREREREREREpD0GH85CxU1ycjJiY2MRGxuLGzdu4KuvvkJiYiJat26NChUqIDo6Gps2bcI///yDBQsWYOfOncp13759i6FDh+LEiRO4f/8+IiMjcfbsWeVUYmPHjkVUVBSGDBmCS5cu4fbt29izZw+++uorrcVfENsgItIFIYBRo4BfflGkjYyAbdsAHx9JwyrW4uPjERQUBBsbG9jY2CAoKAgvXrzINn9qairGjh2L6tWrw9LSEq6urujVqxcePXqkks/HxwcymUzlr2vXrjquDRERERERERHpC945Q1kcPHhQ+RwXa2trVK5cGVu3boXP//cOjhgxAkOHDkVycjICAgIwceJETJ48GQBgaGiIZ8+eoVevXnj8+DHs7e3Rrl07TJkyBYDiWTERERGYMGECGjduDCEEypcvjy5dumgt/oLYBhGRLkydCsydq/i/gQGwfj0QECBtTMVd9+7d8fDhQxw8eBAAMGDAAAQFBWHv3r1q87958wYXLlzAxIkTUbNmTcTHx2P48OFo06YNzp07p5K3f//+mDp1qjJtbm6uu4oQERERERERkV7h4AypCAsLQ1hYWI55QkNDERoaqrJs+PDhAAATExNs3LgRACCEQFpaGoyMjJTPhQGAjz/+GIcPH862/Hv37qmkhRDK/3t6eqqkAaBkyZJZln1oG0RE+mbOHOD/x7kBACtWAJ07SxYOAbhx4wYOHjyI06dPo8H/zyu3YsUKeHt749atW/Dy8sqyjo2NDcLDw1WWLVy4EPXr10d0dLTKs88sLCzg7Oys20oQERERERERkV7i4AwREZHEVqxQTGeWYe5coG9f6eIhhaioKNjY2CgHZgDgk08+gY2NDSIjI9UOzqiTkJAAmUyGkiVLqixfv3491q1bBycnJ/j7+2PSpEmwtrbOtpzk5GQkJycr0y9fvgQAyOVyyOXyXNTsAwykn/VWbmAAIZNBrgex6BLrKUUwWvysqBQrhxBCu5/FzPSh7aBn+1JHikMdAT2rp5Y/Nzr7HBIRERFpmaSDMydPnsTs2bNx/vx5xMTEYOfOnWjbtq3y9R07dmD58uU4f/48nj17hosXL6JWrVofLHf79u2YOHEi/vnnH5QvXx4zZsxAu3btVPIsWbIEs2fPRkxMDD766CPMmzcPjRs31nINiYiIcrZpEzBw4Lv01KnA/9+MSBKLjY2Fo6NjluWOjo6IjY3VqIykpCSMGzcO3bt3R4kSJZTLe/TogbJly8LZ2Rl//fUXxo8fj8uXL2e56yazkJAQ5TShmcXFxSEpKUmjeDRSt672ysojuUyGhAoVIAAYvHd3bFHCekrgyROdFCuXy5GQkAAhBAx00dmtB59LQM/2pY4UhzoCelZPLX8uX716pdXydI39IkRERMWXpIMzr1+/Rs2aNdGnTx906NBB7euNGjVCp06d0L9/f43KjIqKQpcuXTBt2jS0a9cOO3fuROfOnXHq1Cnlla+bN2/G8OHDsWTJEjRq1AjLly+Hv78/rl+/rjLdCBERkS7t3QsEBQEZfSKjRwPffSdtTMXB5MmT1Q5yZHb27FkAUJmWM4MQQu3y96WmpqJr166Qy+VYsmSJymuZz2uqVauGihUrol69erhw4QLq1Kmjtrzx48dj5MiRyvTLly/h7u4OBwcHlYGffDt/Xntl5ZHcwAAyAA4XLsCgCF8BzXpKQM2AqzbI5XLIZDI4ODjoZnBGDz6XgJ7tSx0pDnUE9KyeWv5cmpmZabU8XWO/CBERUfEl6eCMv78//P39s309KCgIQNZnkORk3rx5aN68OcaPHw9A0ZERERGBefPmKZ+FMmfOHPTr1w9ffPGFcp1Dhw5h6dKlCAkJyWNtiIiINHfsGNCpE5CWpkgPGACEhgIa9PlTPg0dOhRdu3bNMY+npyeuXLmCx48fZ3ktLi4OTk5OOa6fmpqKzp074+7duzh27NgHB0/q1KkDY2Nj3L59O9vBGVNTU5iammZZbmBgoN3OYKk76f6fTAgYyOXSdxrqGOtZwHQ4hZNMJtP+5zGD1O2Wid7sSx0qDnUE9KieWv7M6OQzqEPsFyEiIiq+itwzZ6KiojBixAiVZS1btsS8efMAACkpKTh//jzGjRunkqdFixaIjIzMttzczPOeec7p9x9U/yEZ+XO7nr4qLPXJvM/UzVGs83nECxjro99YH/2mjfqcPg20aSNDcrJiJKZbN4FFiwSEeHcXTUHQxb4pDPvZ3t4e9vb2H8zn7e2NhIQEnDlzBvXr1wcA/Pnnn0hISEDDhg2zXS9jYOb27ds4fvw47OzsPrita9euITU1FS4uLppXhIiIiEgNfegXyaui9tuhoLH98o5tlz9sv/xh++WdPrZdbmIpcoMzsbGxWa5mdXJyUs4N//TpU6Snp+eYR53czPMul8uRnp6OxMREGBsbaxy7EALp6ekA1E+jUtgUpvokJiYiPT0dL168UHullc7nES9grI9+Y330W37rc+2aETp0sMXr14rvxZYtkzBr1gs8e6btSD9MF/umsM3znpMqVarAz88P/fv3x/LlywEAAwYMQGBgILy8vJT5KleujJCQELRr1w5paWno2LEjLly4gH379iE9PV15fmFrawsTExP8888/WL9+PVq1agV7e3tcv34do0aNQu3atdGoUSNJ6kpERERFhz70i+RVUfvtUNDYfnnHtssftl/+sP3yTh/bLjf9IkVucAbIOhCgbm54TfJklpd53p89ewYDAwNYWFhoPDiRmpqqUb7CQt/rI4TAmzdv8OzZM9jZ2cHZ2VltPp3PI17AWB/9xvrot/zU59YtoHt3GRISFMeEpk0FduwwgZmZbp6B8CG62DeFbZ73D1m/fj2+/vprtGjRAgDQpk0bLFq0SCXPrVu3kJCQAAB4+PAh9uzZAwBZHtZ7/Phx+Pj4wMTEBEePHsX8+fORmJgId3d3BAQEYNKkSTA0NNR9pYiIiKjI05d+kdwqar8dChrbL+/YdvnD9ssftl/e6WPb5aZfpMgNzjg7O2e50uPJkyfKK0Ls7e1haGiYYx51cjvPu4uLC2QyGeLi4jSOPeMWLAMDA72/00QThak+JUuWhLOzc45x6nQecQmwPvqN9dFveanP/ftAixbAkyeKtLc3sGuXDBYW0n4/anvfFJV9nMHW1hbr1q3LMU/mqTs9PT0/OJWnu7s7IiIitBIfERER0fv0pV8kr4rab4eCxvbLO7Zd/rD98oftl3f61na5iaPIDc54e3sjPDxcZX7Vw4cPK+eGNzExQd26dREeHo527dop84SHh+Pzzz/XWhwymQwuLi5wdHTU+O4RuVyuvINDX95M+VFY6mNsbMwrlYlIp2JigKZNgYcPFelatYD9+wErK0nDIiIiIqIiSF/6RYiIiChnkg7OJCYm4s6dO8r03bt3cenSJdja2qJMmTJ4/vw5oqOj8ejRIwCKaUMAxVUgGdNP9erVC25ubggJCQEADBs2DJ9++ilmzZqFzz//HLt378aRI0dw6tQp5XZGjhyJoKAg1KtXD97e3vj5558RHR2NQYMGab2OhoaGGnf8y+VyGBsbw8zMTK8HMzRV1OpDRJQXz54p7pj55x9F2ssLOHQIKFlS0rCIiIiISA8Uh34RIiIiUk/SwZlz587B19dXmc6Yu7R3794ICwvDnj170KdPH+XrXbt2BQBMmjQJkydPBgBER0erdPw3bNgQmzZtwnfffYeJEyeifPny2Lx5Mxo0aKDM06VLFzx79gxTp05FTEwMqlWrhv3798PDw0OX1SUiomLm5UvA3x/46y9F2sMDOHIEcJTmETNEREREpGfYL0JERFR8STo44+Pjk+O87MHBwQgODs6xjBMnTmRZ1rFjR3Ts2DHH9QYPHozBgwdrEiYREVGuvXkDtG4NnD2rSLu4AEePAqVLSxsXEREREekP9osQEREVX5xrioiISMtSUoCOHYGTJxVpW1sgPBwoX17auIiIiIiIiIiISD9wcIaIiEiL0tKAHj2AAwcUaWtrxTNmPvpI2riIiIiIiIiIiEh/cHCGiIhIS+RyoH9/YNs2RdrcHPjtN6BePWnjIiIiIiIiIiIi/cLBGSIiIi0QAhgxAggLU6SNjYEdO4DGjSUNi4iIiIiIiIiI9BAHZ4iIiLTg+++BBQsU/zcwADZuBPz8pI2JiIiIiIiIiIj0EwdniIiI8ik0FJg+/V165UqgQwfp4iEiIiIiIiIiIv3GwRkiIqJ8WLYMGDv2XXrBAiA4WLJwiIiIiIiIiIioEODgDBERUR6tWwcMHvwuPWMG8NVX0sVDRERERERERESFAwdniIiI8mDXLsUdMkIo0mPHAuPHSxkREREREREREREVFhycISIiyqWTJ03QrZsM6emK9JdfAiEhgEwmbVxERERERERERFQ4cHCGiIgoFyIjgeDgkkhJUYzEBAUBixZxYIaIiIiIiIiIiDRnJHUAREREhcXFi0BgoAxv3ypGYtq1A1atAgx4qQMREREREREREeUCu5OIiIg0cOMG0KIFkJCgGJhp1kxg40bAiJc5EBERERERERFRLnFwhoiI6APu3gWaNweePlWkP/44BTt2CJiaShsXEREREREREREVThycISIiysGjR0CzZsB//ynSdeoIrFsXD0tLaeMiIiIiIiIiIqLCi5OxEBERZePpU8UdM//+q0hXqQLs3y8ghJA2MCIiIiIiIiIiKtR45wwREZEaCQmAnx9w/boiXbYsEB4OODhIGxcRERERERERERV+HJwhIiJ6z5s3QGAgcP68Iu3qChw5Ari5SRsXEREREREREREVDRycISIiyiQ5GWjXDjh1SpG2t1fcMVOunLRxERERERERERFR0cHBGSIiov+XlgZ07w4cPqxIlygBHDoEVK0qbVxERERERERERFS0cHCGiIgIgFwO9OsH7NihSFtYAPv3A3XqSBsXEREREREREREVPRycISKiYk8I4OuvgbVrFWkTE2DXLqBRI0nDIiIiIiIiIiKiIoqDM0REVOxNmAAsXqz4v6EhsGkT0Ly5tDEREREREREREVHRxcEZIiIq1kJCFH8ZwsKAdu0kC4eIiIiIiIiIiIoBDs4QEVGxtXgx8O2379JLlgA9e0oXDxERERERERERFQ8cnCEiomJpzRpg6NB36VmzgC+/lC4eIiIiIiIiIiIqPjg4Q0RExc727UDfvu/SEyYAY8ZIFw8RERERERERERUvHJwhIqJi5dAhoFs3QC5XpL/6Cpg2TdqYiIiIiIiIiIioeOHgDBERFRu//w60awekpirSwcHAvHmATCZlVEREREREREREVNxwcIaIiIqFc+eAgADg7VtFumNHYMUKwIBHQiIiIiIiIiIiKmDskiIioiLv2jXAzw949UqR9vMD1q8HjIykjYuIiIiIiIiIiIonDs4QEVGR9s8/QPPmwLNninTjxsD27YCJibRxERERERERERFR8cXBGSIiKrIePgSaNQNiYhTpevWAffsACwtp4yIiIiIiIiIiouKNgzNERFQkxcUp7pi5d0+R/ugj4OBBoEQJScOiQiY+Ph5BQUGwsbGBjY0NgoKC8OLFixzXCQ4OhkwmU/n75JNPVPIkJyfjq6++gr29PSwtLdGmTRs8fPhQhzUhIiIiIiIiIn0i6eDMyZMn0bp1a7i6ukImk2HXrl0qrwshMHnyZLi6usLc3Bw+Pj64du1ajmX6+Phk6RCRyWQICAhQ5pk8eXKW152dnXVRRSIiksCLF0DLlsDNm4p0+fJAeDhgZydpWFQIde/eHZcuXcLBgwdx8OBBXLp0CUFBQR9cz8/PDzExMcq//fv3q7w+fPhw7Ny5E5s2bcKpU6eQmJiIwMBApKen66oqREREpIfYL0JERFR8Sfoo5NevX6NmzZro06cPOnTokOX10NBQzJkzB2FhYahUqRKmT5+O5s2b49atW7C2tlZb5o4dO5CSkqJMP3v2DDVr1kSnTp1U8n300Uc4cuSIMm1oaKilWhERkZRevwYCAoCLFxVpNzfgyBHAxUXauKjwuXHjBg4ePIjTp0+jQYMGAIAVK1bA29sbt27dgpeXV7brmpqaZtvBkZCQgJUrV+LXX39Fs2bNAADr1q2Du7s7jhw5gpYtW6pdLzk5GcnJycr0y5cvAQByuRxyuTxPdVTLQPobq+UGBhAyGeR6EIsusZ5SBKPFz4pKsXIIIbT7WcxMH9oOerYvdaQ41BHQs3pq+XOjs8+hjrBfhIiIqPiSdHDG398f/v7+al8TQmDevHmYMGEC2rdvDwBYs2YNnJycsGHDBgwcOFDtera2tirpTZs2wcLCIstJiJGREa8KISIqYpKSgLZtgchIRdrBQTEw4+kpZVRUWEVFRcHGxkY5MAMAn3zyCWxsbBAZGZnj4MyJEyfg6OiIkiVLokmTJpgxYwYcHR0BAOfPn0dqaipatGihzO/q6opq1aohMjIy28GZkJAQTJkyJcvyuLg4JCUl5bWaWdWtq72y8kgukyGhQgUIAAZCSB2OzrCeEnjyRCfFyuVyJCQkQAgBA110duvB5xLQs32pI8WhjoCe1VPLn8tXr15ptTxdY78IERFR8SXp4ExO7t69i9jYWJWOC1NTUzRp0gSRkZHZnoS8b+XKlejatSssLS1Vlt++fRuurq4wNTVFgwYNMHPmTJQrVy7bcgrialWdX3FXwIpSfYpSXQDWR9+xPnmTmgp06SLDkSMyAICNjcDBgwKVKmn3gsyitH90UZei0C4ZYmNjlQMqmTk6OiI2Njbb9fz9/dGpUyd4eHjg7t27mDhxIj777DOcP38epqamiI2NhYmJCUqVKqWynpOTU47ljh8/HiNHjlSmX758CXd3dzg4OKCENh+mdP689srKI7mBAWQAHC5cgEERek+9j/WUgJrPtDbI5XLIZDI4ODjoZnBGDz6XgJ7tSx0pDnUE9KyeWv5cmpmZabU8KbFfhHKL7Zd3bLv8YfvlD9sv7/Sx7XITi94OzmR0Tjg5Oaksd3Jywv379zUq48yZM/jrr7+wcuVKleUNGjTA2rVrUalSJTx+/BjTp09Hw4YNce3aNdhl80CCgrhaVedX3BWwolSfolQXgPXRd6xPXrYBfPWVDfbsMQcAWFjIsW5dPFxdU7V+kXRR2j+6qEthuFp18uTJao/pmZ09exYAIJPJsrwmhFC7PEOXLl2U/69WrRrq1asHDw8P/Pbbb8qrXtX5ULmmpqYwNTXNstzAwEC770U9OamVCQEDuVz6TkMdYz0LmA6/t2UymfY/jxmkbrdM9GZf6lBxqCOgR/XU8memsJ+fZcZ+kaKzLwsK2y/v2Hb5w/bLH7Zf3ulj2+WmX0RvB2cyvN9J8aGOi8xWrlyJatWqoX79+irLM98yXL16dXh7e6N8+fJYs2aNyhWpmRXE1ao6v+KugBWl+hSlugCsj75jfXJHCGDIEBl27FAcG0xMBHbtApo2LZXzinlUlPaPLupSGK5WHTp0KLp27ZpjHk9PT1y5cgWPHz/O8lpcXFyWTpKcuLi4wMPDA7dv3wYAODs7IyUlBfHx8Sp3zzx58gQNGzbUuFwiIiIqHtgvQppi++Ud2y5/2H75w/bLO31su9z0i+jt4EzGvKexsbFwyfQU5ydPnmjUIfLmzRts2rQJU6dO/WBeS0tLVK9eXdlpok5BXa2q0yvuJFCU6lOU6gKwPvqO9dGMEMC4ccDy5Yq0oSGwdasMzZtr9mM1r4rS/tF2XQpDm9jb28Pe3v6D+by9vZGQkIAzZ84oOzT+/PNPJCQk5GoQ5dmzZ3jw4IHyfKZu3bowNjZGeHg4OnfuDACIiYnBX3/9hdDQ0DzUiIiIiIoi9ovo/3mlPmL75R3bLn/YfvnD9ss7fWu73MShHxGrUbZsWTg7OyM8PFy5LCUlBRERERp1iGzZsgXJycno2bPnB/MmJyfjxo0bKic7RESk/2bOBGbPVvxfJgPWrgXatJE2Jio6qlSpAj8/P/Tv3x+nT5/G6dOn0b9/fwQGBsLLy0uZr3Llyti5cycAIDExEaNHj0ZUVBTu3buHEydOoHXr1rC3t0e7du0AADY2NujXrx9GjRqFo0eP4uLFi+jZsyeqV6+OZs2aSVJXIiIi0j/sFyEiIiraJL1zJjExEXfu3FGm7969i0uXLsHW1hZlypTB8OHDMXPmTFSsWBEVK1bEzJkzYWFhge7duyvX6dWrF9zc3BASEqJS9sqVK9G2bVu1c6WOHj0arVu3RpkyZfDkyRNMnz4dL1++RO/evXVXWSIi0qoFC4DvvnuXXrYMyHR4INKK9evX4+uvv1Y+iLdNmzZYtGiRSp5bt24hISEBAGBoaIirV69i7dq1ePHiBVxcXODr64vNmzfD2tpauc7cuXNhZGSEzp074+3bt2jatCnCwsJgaGhYcJUjIiIiybFfhIiIqPiSdHDm3Llz8PX1VaYz5i7t3bs3wsLCMGbMGLx9+xaDBw9GfHw8GjRogMOHD6t0bkRHR2e5Vejvv//GqVOncPjwYbXbffjwIbp164anT5/CwcEBn3zyCU6fPg0PDw8d1JKIiLRt9Wpg2LB36R9/BAYMkC4eKrpsbW2xbt26HPMIIZT/Nzc3x6FDhz5YrpmZGRYuXIiFCxfmO0YiIiIqvNgvQkREVHxJOjjj4+Oj0qHxPplMhsmTJ2Py5MnZ5jlx4kSWZZUqVcqx3E2bNuUmTCIi0iNbtwJffPEu/f33wKhR0sVDRERERJRX7BchIiIqvvT2mTNERETv278f6NEDkMsV6eHDgRx+pxIREREREREREeklDs4QEVGhEBEBdOgApKYq0v36AXPmADKZtHERERERERERERHlFgdniIhI7505AwQGAklJinTnzsDy5RyYISIiIiIiIiKiwomDM0REpNeuXgX8/IDEREU6IAD49VfA0FDauIiIiIiIiIiIiPKKgzNERKS3bt8GmjcH4uMVaR8fYOtWwMRE0rCIiIiIiIiIiIjyhYMzRESklx48AJo1Ax4/VqTr1wf27AHMzaWNi4iIiIiIiIiIKL84OENERHrn8WPFwEx0tCJdvTpw4ABgbS1tXERERERERERERNrAwRkiItIr8fFAixbA338r0hUrAocPA7a20sZFRERERERERESkLRycISIivfHqFeDvD1y5oki7uwNHjgDOztLGRUREREREREREpE0cnCEiIr2QlAR8/jnw55+KtJMTcPQoUKaMtHERERERERERERFpGwdniIhIcqmpQKdOwPHjinSpUoqpzCpWlDYuIiIiIiIiIiIiXeDgDBERSSo9HejVC9i3T5G2tAQOHABq1JA2LiIiIiIiIiIiIl0xkjoAIiIqvoQABg0CNm1SpE1Ngb17gQYNpI2LqFgTQuoIALkcePIEcHQEDIrwtUSsJxERERERUbHFX0dERCQJIYDRo4FfflGkjYyAbdsAX19p4yIiIiIiIiIiItI1Ds4QEZEkpk0D5sxR/F8mA9atAwIDpY2JiIiIiIiIiIioIHBwhoiICtzcucCkSe/SK1YAXbpIFw8REREREREREVFB4uAMEREVqF9+AUaOfJeeOxfo10+6eIiIiIiIiIiIiAoaB2eIiKjAbN4MDBjwLj1lCjB8uGThEBERERERERERSYKDM0REVCD27QN69gSEUKRHjQImTpQ2JiIiIiIiIiIiIikYSR0AEREVfX/8YYIePWRIS1Ok+/cHZs8GZDJp46LC4969e/j9999x7949vHnzBg4ODqhduza8vb1hZmYmdXhERERERERERLnCwRkiItKp06eBXr1KIjlZMRLTrRuwdCkHZkgzGzZswIIFC3DmzBk4OjrCzc0N5ubmeP78Of755x+YmZmhR48eGDt2LDw8PKQOl4iIiIiIiIhIIxycISIinblyBQgIkOHNG8VITOvWwJo1gKGhxIFRoVCnTh0YGBggODgYW7ZsQZkyZVReT05ORlRUFDZt2oR69ephyZIl6NSpk0TREhERERERERFpjoMzRESkE3//DTRvDrx4oRiY+ewzgS1bZDA2ljgwKjSmTZuGgICAbF83NTWFj48PfHx8MH36dNy9e7cAoyMiIiIiIiIiyjsOzhARkdbdvw80awY8eaJI162bgp07jWBmxrnMSHM5Dcy8z97eHvb29jqMhoiIiIiIiIhIezg4Q0REWhUbqxiYefBAka5ZU2DdunhYWTlIGxgVGb/99htOnDiB9PR0NGrUCB06dJA6JCIiIiIiIiKiXDGQOgAiIio6nj9XTGV2544i7eUFHDwoULKkkDYwKjImTpyIMWPGQCaTQQiBESNGYOjQoVKHRURERERERESUK7xzhoiItOLVK8DPD/jrL0XawwMIDwccHd9Nb0aUW+fPn0fdunWV6c2bN+Py5cswNzcHAAQHB8PHxweLFi2SKkQiIiIiIiIiolzjnTNERJRvb98CrVsDZ88q0s7OwJEjgLu7tHFR4TdgwAAMHz4cb968AQCUK1cOc+bMwa1bt3D16lUsXboUlSpVkjhKIiIiIiIiIqLc4eAMERHlS0oK0LEjEBGhSNvaKu6YqVBB2rioaDhz5gycnZ1Rp04d7N27F6tWrcKFCxfQsGFDNG7cGA8fPsSGDRukDpOIiIiIiIiIKFc4rRkREeVZejrQsyewf78ibW0NHDwIVKsmbVxUdBgaGmLcuHHo3LkzvvzyS1haWmLRokVwdXWVOjQiIiIiIiIiojzjnTNERJQncjnQvz+wdasibWYG7NsHfPyxtHFR0VSuXDkcOnQIbdu2xaefforFixdLHRIRERERERERUZ5xcIaIiHJNCGDECGD1akXa2BjYuRP49FNp46KiJyEhAWPHjkXr1q3x3XffoX379vjzzz9x5swZfPLJJ7h69arUIRIRERERERER5RoHZ4iIKNcmTQIWLFD838AA2LAB8POTNiYqmnr37o3Tp08jICAAt27dwpdffgk7OzusWbMGM2bMQOfOnTF27FipwyQiIiIiIiIiyhU+c4aIiHJl9mxg2rR36ZUrgY4dpYuHirajR4/i4sWLqFChAvr3748KFSooX2vatCkuXLiAaZnfkEREREREREREhYCkd86cPHkSrVu3hqurK2QyGXbt2qXyuhACkydPhqurK8zNzeHj44Nr167lWGZYWBhkMlmWv6SkJJV8S5YsQdmyZWFmZoa6devi999/13b1iIiKnOXLgTFj3qUXLACCgyULh4qBihUr4ueff8bff/+NZcuWwcPDQ+V1c3NzzJw5U6LoiIiIiPKH/SJERETFl6SDM69fv0bNmjWxaNEita+HhoZizpw5WLRoEc6ePQtnZ2c0b94cr169yrHcEiVKICYmRuXPzMxM+frmzZsxfPhwTJgwARcvXkTjxo3h7++P6OhordaPiKgoWb8e+PLLd+kZM4CvvpIuHioeVq1ahWPHjqF27drYsGEDli5dWqDbj4+PR1BQEGxsbGBjY4OgoCC8ePEix3XUdYbIZDLMnj1bmcfHxyfL6127dtVxbYiIiEjfsF+EiIio+JJ0WjN/f3/4+/urfU0IgXnz5mHChAlo3749AGDNmjVwcnLChg0bMHDgwGzLlclkcHZ2zvb1OXPmoF+/fvjiiy8AAPPmzcOhQ4ewdOlShISE5KNGRERF0+7dQO/egBCK9NixwPjx0sZExUOtWrVw7tw5ybbfvXt3PHz4EAcPHgQADBgwAEFBQdi7d2+268TExKikDxw4gH79+qFDhw4qy/v374+pU6cq0+bm5lqMnIiIiAoD9osQEREVX3r7zJm7d+8iNjYWLVq0UC4zNTVFkyZNEBkZmeNJSGJiIjw8PJCeno5atWph2rRpqF27NgAgJSUF58+fx7hx41TWadGiBSIjI7MtMzk5GcnJycr0y5cvAQByuRxyuTxPdXyfXC6HEEJr5UmtKNWnKNUFYH30nb7V58gRoHNnGdLTZQCAQYMEZswQEOLdYE1O9K0++VWU6qOLukjZLkIIyGQyrZV348YNHDx4EKdPn0aDBg0AACtWrIC3tzdu3boFLy8vteu93xGye/du+Pr6oly5cirLLSwscuw0ISIiouKN/SKUW2y/vGPb5Q/bL3/Yfnmnj22Xm1j0dnAmNjYWAODk5KSy3MnJCffv3892vcqVKyMsLAzVq1fHy5cvMX/+fDRq1AiXL19GxYoV8fTpU6Snp6stN2Ob6oSEhGDKlClZlsfFxWWZtzWv5HI5EhISIISAgYGkM85pRVGqT1GqC8D66Dt9qs/Zs8bo0qUUUlIUHd4dOrzFxIkJiIvTvAx9qo82FKX66KIuH5piIzeqVKmCiRMnomPHjjAxMck23+3btzFnzhx4eHhk6WTIj6ioKNjY2CgHZgDgk08+gY2NDSIjI7MdnMns8ePH+O2337BmzZosr61fvx7r1q2Dk5MT/P39MWnSJFhbW2dbVkF0iOgLfTzB1gXWs+jQeR315HgjNzCAkMkg15N4dKE41BHQs3pq+XNTlL5r2C+iB+/PQobtl3dsu/xh++UP2y/v9LHtctMvoreDMxnevwL2Q1fFfvLJJ/jkk0+U6UaNGqFOnTpYuHAhFixYkOdyx48fj5EjRyrTL1++hLu7OxwcHFCiRAmN65MTuVwOmUwGBwcHvXkz5UdRqk9RqgvA+ug7fanPpUtAUJAMb98qvhs//1xgwwZTGBk55qocfamPthSl+uiiLpnnMs+vxYsXY+zYsRgyZAhatGiBevXqwdXVFWZmZoiPj8f169dx6tQpXL9+HUOHDsXgwYO1tm1A0SHi6Jj1/e7o6Jhjx0Vma9asgbW1tXIqkgw9evRA2bJl4ezsjL/++gvjx4/H5cuXER4enm1ZBdEhoi/08QRbF1jPokPndaxbV/tl5oFcJkNChQoQAAw0uX22ECoOdQT0rJ5Pnmi1OG1eKKIv2C9CmmL75R3bLn/YfvnD9ss7fWy73PSL6O3gTMY0H7GxsXBxcVEuf/LkSZarO3JiYGCAjz/+GLdv3wYA2Nvbw9DQMEunyofKNTU1hampqdrytbnjZTKZ1suUUlGqT1GqC8D66Dup63PzJuDnByQkKNLNmwObN8tgYpK3KaOkro+2FaX6aLsu2myTzz77DGfPnkVkZCQ2b96MDRs24N69e3j79i3s7e1Ru3Zt9OrVCz179kTJkiU1Lnfy5MlqBzkyO3v2LICsnRZA7qZPW7VqFXr06JHl5Kx///7K/1erVg0VK1ZEvXr1cOHCBdSpU0dtWQXRIaIv9PEEWxdYz6JD53U8f177ZeaB3MAAMgAOFy7AoAjdnZBZcagjoGf1VHMhRH5o80IRqbFfpGgeM3SN7Zd3bLv8YfvlD9sv7/St7XITh94OzmRcTRoeHq4yL2pERARmzZqlcTlCCFy6dAnVq1cHAJiYmKBu3boIDw9Hu3btlPnCw8Px+eefa7cSRESF0L17QLNmUE5d1rAhsHMnoOZ3GFGBaNiwIRo2bKi18oYOHYquXbvmmMfT0xNXrlzB48ePs7wWFxenUYfI77//jlu3bmHz5s0fzFunTh0YGxvj9u3b2Q7OFFSHiL7QtxNsXWE9iw6d1lHqzvNMZELAQC6XvkNfh4pDHQE9qqeWPzNF6XuG/SJERERFm6SDM4mJibhz544yfffuXVy6dAm2trYoU6YMhg8fjpkzZ6JixYqoWLEiZs6cCQsLC3Tv3l25Tq9eveDm5oaQkBAAwJQpU/DJJ5+gYsWKePnyJRYsWIBLly5h8eLFynVGjhyJoKAg1KtXD97e3vj5558RHR2NQYMGFVzliYj00KNHQNOmwH//KdK1awO//QZYWkobF5E22dvbw97e/oP5vL29kZCQgDNnzqB+/foAgD///BMJCQkaDRatXLkSdevWRc2aNT+Y99q1a0hNTVW5KpaIiIiKPvaLEBERFV+SDs6cO3cOvr6+ynTGVB29e/dGWFgYxowZg7dv32Lw4MGIj49HgwYNcPjwYZWH5UZHR6tcGfPixQsMGDAAsbGxsLGxQe3atXHy5EllpwoAdOnSBc+ePcPUqVMRExODatWqYf/+/fDw8CiAWhMR6aenTxXTl/37ryJduTJw6BCQi9miiIqUKlWqwM/PD/3798fy5csBAAMGDEBgYCC8vLyU+SpXroyQkBCVK09fvnyJrVu34qeffspS7j///IP169ejVatWsLe3x/Xr1zFq1CjUrl0bjRo10n3FiIiISG+wX4SIiKj4knRwxsfHByKHhw/KZDJMnjwZkydPzjbPiRMnVNJz587F3LlzP7jtwYMHa/3BwUREhdXLl4pnzFy/rkiXLQscOQI4OEgbF5HU1q9fj6+//hotWrQAALRp0waLFi1SyXPr1i0kZDyg6f9t2rQJQgh069YtS5kmJiY4evQo5s+fj8TERLi7uyMgIACTJk2CoaGh7ipDREREeof9IkRERMWX3j5zhoiICsabN0Bg4LtnDbu4KAZm3NykjYtIH9ja2mLdunU55lHXoTJgwAAMGDBAbX53d3dERERoJT4iIiIiIiIiKpyKzpPyiIgo15KTgfbtgd9/V6Tt7BQDM+XKSRsXERERERERERFRUZarO2du3bqFjRs34vfff8e9e/fw5s0bODg4oHbt2mjZsiU6dOgAU1NTXcVKRERalJYG9OiheK4MAJQoofh/1arSxkWkjqGhIWJiYuDo6Kiy/NmzZ3B0dER6erpEkREREVFxw74RIiIi0gaN7py5ePEimjdvjpo1a+LkyZP4+OOPMXz4cEybNg09e/aEEAITJkyAq6srZs2aheTkZF3HTURE+SCXA198AWzfrkibmwO//QbUrSttXETZyW4u9uTkZJiYmBRwNERERFQcsW+EiIiItEmjO2fatm2Lb775Bps3b4atrW22+aKiojB37lz89NNP+Pbbb7UWJBERaY8QwLBhwJo1irSJCbBrF/C//0kaFpFaCxYsAKB4GO4vv/wCKysr5Wvp6ek4efIkKleuLFV4REREVIywb4SIiIi0SaPBmdu3b2t0Vaq3tze8vb2RkpKS78CIiEg3vvsOWLRI8X9DQ2DTJqBFC2ljIsrO3LlzASjunFm2bBkMDQ2Vr5mYmMDT0xPLli2TKjwiIiIqRtg3QkRERNqk0eBMbqcL4fQiRET66YcfgJkz36VXrwbatZMuHqIPuXv3LgDA19cXO3bsQKlSpSSOiIiIiIor9o0QERGRNmn0zBl1YmJi0LFjRzg4OMDW1hatW7fGv//+q83YiIhIi5YsAcaPf5devBgICpIuHqLcOH78OAdmiIiISO+wb4SIiIjyKs+DM3379kW1atUQERGBY8eOwcnJCd27d9dmbEREpCVr1wJDhrxL//ADMHiwdPEQ5VZ6ejpWrlyJ7t27o1mzZvjss89U/oiIiIikwL4RIiIiyiuNpjUDgGHDhmHmzJmwtLQEANy5cwc7duyAubm58vVPP/1UN1ESEVGe7dgB9OnzLv3tt8DYsdLFQ5QXw4YNQ1hYGAICAlCtWjXIZDKpQyIiIqJiiH0jREREpC0aD864ubmhbt26CA0NRZs2bdClSxc0aNAArVq1QmpqKnbs2IEePXroMlYiIsqlQ4eArl0BuVyRHjoUmD5d2piI8mLTpk3YsmULWrVqJXUoREREVIyxb4SIiIi0RePBmTFjxqBTp04YPHgwwsLCsGDBAjRo0AAnTpxAeno6QkND0bFjR13GSkREuXDqFNCuHZCaqkj37g3Mnw/whgMqjExMTFChQgWpwyAiIqJijn0jREREpC0aD84AQNmyZXHgwAGsW7cOPj4+GDZsGH788UdOLUJEpGfOnwcCAoC3bxXpDh2AX34BDPL8pDEiaY0aNQrz58/HokWLeN5BREREkmLfCBEREWlDrrvpnj17hp49e+Ls2bO4cOECvL29ceXKFV3ERkREeXD9OtCyJfDypSLt5wesXw8Y5Wo4nki/nDp1CuvXr0f58uXRunVrtG/fXuWPiIiIqCCxb4SIiIjyS+PBmePHj8PZ2RkODg4oXbo0bt68idWrV2PmzJno2rUrxowZg7cZl2gTEZEk/v0XaNYMePZMkW7cGNi+HTA1lTYuovwqWbIk2rVrhyZNmsDe3h42NjYqf0REREQFgX0jREREpC0aX0c9ePBgfPPNNxgyZAgOHjyI4cOH488//8Rnn32GixcvYsqUKahVqxZu3bqly3iJiCgb//0HNG0KxMQo0vXqAfv2ARYW0sZFpA2rV6+WOgQiIiIi9o0QERGR1mh858yjR48QEBAAMzMz+Pn5IS4uTvmaqakpZs6ciR07dugkSCIiyllcnOKOmXv3FOmPPgIOHgRKlJA0LCKtSktLw5EjR7B8+XK8evUKgOL8JDExUeLIiIiIqLhg3wgRERFpi8Z3zrRp0wYdO3ZEmzZtcOrUKbRq1SpLno8++kirwRER0Ye9eKF4xszNm4p0+fJAeDhgZydpWERadf/+ffj5+SE6OhrJyclo3rw5rK2tERoaiqSkJCxbtkzqEImIiKgYYN8IERERaYvGd86sXLkSAwcOREJCAnr27Il58+bpMCwiItLE69dAQABw8aIi7eYGHDkCuLhIGxeRtg0bNgz16tVDfHw8zM3NlcvbtWuHo0ePShgZERERFSfsGyEiIiJt0fjOGRMTE3z11Ve6jIWIiHIhORlo1w6IjFSk7e0VAzOenpKGRaQTp06dwh9//AETExOV5R4eHvjvv/8kioqIiIiKG/aNEBERkbZodOdMVFSUxgW+fv0a165dy3NARET0YWlpQNeuiunLAMDGBjh8GKhcWdq4iHRFLpcjPT09y/KHDx/C2tpagoiIiIiouGHfCBEREWmTRoMzvXr1QvPmzbFly5ZsH7p7/fp1fPvtt6hQoQIuXLig1SCJiOgduRzo0wfYtUuRtrAA9u8HateWNCwinWrevLnKtCEymQyJiYmYNGmS2rneiYiIiLSNfSNERESkTRpNa3b9+nUsX74c33//PXr06IFKlSrB1dUVZmZmiI+Px82bN/H69Wu0b98e4eHhqFatmq7jJiIqloQAhg4F1q1TpE1MgN27gYYNpY2LSNfmzp0LX19fVK1aFUlJSejevTtu374Ne3t7bNy4UerwiIiIqBhg3wgRERFpk0aDM8bGxhg6dCiGDh2KCxcu4Pfff8e9e/fw9u1b1KxZEyNGjICvry9sbW11HS8RUbElBDBuHLB0qSJtaAhs2QI0ayZtXEQFwdXVFZcuXcLGjRtx4cIFyOVy9OvXDz169IC5ubnU4REREVExwL4RIiIi0iaNBmcyq1OnDurUqaOLWIiIKAchIUBoqOL/MhmwZg3w+efSxkRUkMzNzdG3b1/07dtX6lCIiIiomGPfCBEREeVXrgdniIio4C1cCEyY8C69dCnQo4d08RBJ4b///sMff/yBJ0+eQC6Xq7z29ddfSxQVEREREREREVHucXCGiEjPhYUBmfudZ88GBg6ULBwiSaxevRqDBg2CiYkJ7OzsIJPJlK/JZDIOzhARERERERFRocLBGSIiPbZtG9Cv37v0xInA6NHSxUMkle+//x7ff/89xo8fDwMDA6nDISIiIiIiIiLKF/ZuEBHpqQMHgO7dgYzZm4YNA6ZMkTYmIqm8efMGXbt25cAMERERERERERUJ7OEgItJDkZHG6NhRhtRURbpvX2DOHCDTTE5ExUq/fv2wdetWqcMgIiIiIiIiItIKjQdnWrVqhYSEBGV6xowZePHihTL97NkzVK1aVavBEREVR2fPAr17l0JSkmIkplMn4OefAd4wQMVZSEgIIiIi4OPjg6+++gojR45U+SMiIiIqCOwbISIiIm3R+Jkzhw4dQnJysjI9a9YsdOvWDSVLlgQApKWl4datW1oPkIioOPnrL6BVKxkSExUDM61aAevWAYaGEgdGJLGZM2fi0KFD8PLyAgDIMt1GJuMtZURERFRA2DdCRERE2qLx4IwQIsc0ERHlz507QPPmwPPnio7mJk0Etm2TwcRE4sCI9MCcOXOwatUqBAcHSx0KERERFWPsGyEiIiJt4SQ5RER64MEDoFkzIDZWka5dOwW7dwuYm0sbF5G+MDU1RaNGjaQOg4iIiIiIiIhIKzQenJHJZFmmDeE0IkRE+ffkiWJg5v59RbpaNYH16+NhbS1tXET6ZNiwYVi4cKHUYRAREVExx74RIiIi0haNB2eEEAgODkb79u3Rvn17JCUlYdCgQcp03759c73xkydPonXr1nB1dYVMJsOuXbuybHPy5MlwdXWFubk5fHx8cO3atRzLXLFiBRo3boxSpUqhVKlSaNasGc6cOaOSZ/LkycoTqow/Z2fnXMdPRJRf8fFAixbA338r0hUqAIcOCZQqxekRiDI7c+YM1qxZg3LlyqF169bK84+MPyIiIqKCoO2+EfaLEBERFV8aD8707t0bjo6OsLGxgY2NDXr27AlXV1dl2tHREb169crVxl+/fo2aNWti0aJFal8PDQ3FnDlzsGjRIpw9exbOzs5o3rw5Xr16lW2ZJ06cQLdu3XD8+HFERUWhTJkyaNGiBf777z+VfB999BFiYmKUf1evXs1V7ERE+ZWYCLRqBVy+rEi7uwNHjgD8TUSUVcmSJdG+fXs0adIE9vb2yvOPjD8iIiKigqDtvhH2ixARERVfRppmXL16tdY37u/vD39/f7WvCSEwb948TJgwQXlF7Jo1a+Dk5IQNGzZg4MCBatdbv369SnrFihXYtm0bjh49qnKCZGRklKurQpKTk5GcnKxMv3z5EgAgl8shl8s1LicncrkcQgitlSe1olSfolQXgPXRB0lJwOefy3D6tGIKBEdHgcOHBdzdC2d9csL66C9d1EVX7aKL8xAiIiKi3NL2OQn7RVQVpXNtKbD98o5tlz9sv/xh++WdPrZdbmLReHAGAO7fv4/Dhw8jNTUVPj4+qFq1aq6D09Tdu3cRGxuLFi1aKJeZmpqiSZMmiIyMzPYk5H1v3rxBamoqbG1tVZbfvn0brq6uMDU1RYMGDTBz5kyUK1cu23JCQkIwZcqULMvj4uKQlJSkYa1yJpfLkZCQACEEDAw0vqlJbxWl+hSlugCsj9RSU4EvviiJY8fMAAA2NnJs3PgcJUum4cmTwlefD2F99Jcu6pLTVZz5lZaWhhMnTuCff/5B9+7dYW1tjUePHqFEiRKwsrLSyTZnzJiB3377DZcuXYKJiQlevHjxwXWEEJgyZQp+/vlnxMfHo0GDBli8eDE++ugjZZ7k5GSMHj0aGzduxNu3b9G0aVMsWbIEpUuX1kk9iIiISHsKqm+E/SKF+1xbCmy/vGPb5Q/bL3/Yfnmnj22Xm34RjQdnTp48iVatWuHNmzeKFY2MsGbNGnTr1i33EWogNjYWAODk5KSy3MnJCfcznpqtgXHjxsHNzQ3NmjVTLmvQoAHWrl2LSpUq4fHjx5g+fToaNmyIa9euwc7OTm0548ePx8iRI5Xply9fwt3dHQ4ODihRokRuqpYtuVwOmUwGBwcHvXkz5UdRqk9RqgvA+kgpPR3o1UuGw4cVd8xYWgocOAA0aPDuh1Jhqo8mWB/9pYu6mJmZaaWc992/fx9+fn6Ijo5GcnIymjdvDmtra4SGhiIpKQnLli3TyXZTUlLQqVMneHt7Y+XKlRqtkzH9SFhYGCpVqoTp06ejefPmuHXrFqytrQEAw4cPx969e7Fp0ybY2dlh1KhRCAwMxPnz52FoaKiTuhAREVH+FWTfCPtFCve5thTYfnnHtssftl/+sP3yTh/bLjf9IhoPzkycOBG+vr5Yvnw5zM3NMX78eIwZM0ZngzMZZDKZSloIkWVZdkJDQ7Fx40acOHFCpVEy3zJcvXp1eHt7o3z58lizZo3KiUZmpqamMDU1zbLcwMBAqzteJpNpvUwpFaX6FKW6AKyPFIQAhgwBNm1SpE1Ngb17ZfD2zvqdVhjqkxusj/7Sdl101SbDhg1DvXr1cPnyZZUOg3bt2uGLL77QyTYBKK8ODQsL0yi/JtOPJCQkYOXKlfj111+VnSTr1q2Du7s7jhw5gpYtW6otuyCmEtEX+nhrui6wnkWHzuuoJ8cbuYEBhEwGuZ7EowvFoY6AntVTy58bXX/XSNE3wn4Ryg22X96x7fKH7Zc/bL+807e2y00cGg/OXL16FSdPnoSrqysA4KeffsKKFSsQHx+PUqVK5T7KD8iY9zQ2NhYuLi7K5U+ePMly1Yg6P/74I2bOnIkjR46gRo0aOea1tLRE9erVcfv27fwFTUSUDSGA0aOBFSsUaSMjYNs2wNdX2riICotTp07hjz/+gImJicpyDw+PLA+3lZIm04+cP38eqampKnlcXV1RrVo1REZGZjs4UxBTiegLfbw1XRdYz6JD53WsW1f7ZeaBXCZDQoUKEAAMhJA6HJ0oDnUE9KyeT55otThdTrEKFGzfCPtFiIiIijaNB2devHgBR0dHZdrS0hIWFhZ48eKFTgZnypYtC2dnZ4SHh6N27doAFFOLREREYNasWTmuO3v2bEyfPh2HDh1CvXr1Prit5ORk3LhxA40bN9ZK7ERE75s2DZgzR/F/mQxYtw4IDJQ2JqLCRC6XIz09Pcvyhw8fKqcK0weaTD8SGxsLExOTLOdPTk5OyvXVKYipRPSFPt6argusZ9Gh8zqeP6/9MvNAbmAAGQCHCxdgUETvhCoOdQT0rJ6Z+hm0QVdTrGYoyL4R9osQEREVbRoPzgDA9evXVToNhBC4ceOGypUpH7oaI7PExETcuXNHmb579y4uXboEW1tblClTBsOHD8fMmTNRsWJFVKxYETNnzoSFhQW6d++uXKdXr15wc3NDSEgIAMUtuxMnTsSGDRvg6empjNfKykr5sODRo0ejdevWKFOmDJ48eYLp06fj5cuX6N27d26ag4hII/PmAZMmvUuvWAF06SJZOESFUvPmzTFv3jz8/PPPABS3LScmJmLSpElo1apVrsqaPHmy2jtQMjt79qxGHRnZycv0Ix/KU1BTiegLfbs1XVdYz6JDp3WUuvM8E5kQMJDLpe/Q16HiUEdAj+qp5c9MQXzPaLNvhP0iRERExVeuBmeaNm0K8d4tz4GBgZDJZMoOBXVXtWbn3Llz8M00p0/G1aC9e/dGWFgYxowZg7dv32Lw4MGIj49HgwYNcPjwYZUrZKOjo1VOvpYsWYKUlBR07NhRZVuTJk3C5MmTASiusu3WrRuePn0KBwcHfPLJJzh9+jQ8PDw0jp2ISBMrVwIjRrxLz5kD9OsnXTxEhdXcuXPh6+uLqlWrIikpCd27d8ft27dhb2+PjRs35qqsoUOHomvXrjnm8fT0zFOcmkw/4uzsjJSUlCzTnzx58gQNGzbM03aJiIio4Gizb4T9IkRERMWXxoMzd+/e1frGfXx8spzQZCaTyTB58mTlyYM6J06cUEnfu3fvg9vdlPE0biIiHdq8Gejf/1168mTVgRoi0pyrqysuXbqEjRs34sKFC5DL5ejXrx969OgBc3PzXJVlb28Pe3t7ncSpyfQjdevWhbGxMcLDw9G5c2cAQExMDP766y+EhobqJC4iIiLSDm33jbBfhIiIqPjSeHBGk6snLl26xKssiIgA/PYb0LMnkPE7a+RI4PvvpY2JqDB78+YNLCws0LdvX/Tt27fAthsdHY3nz58jOjoa6enpuHTpEgCgQoUKymlBKleujJCQELRr1w4ymeyD04/Y2NigX79+GDVqFOzs7GBra4vRo0ejevXqaNasWYHVjYiIiHKPfSNERESkLbma1kydhIQErF+/Hr/88gsuX76cq2nNiIiKouPHgQ4dgLQ0RfqLL4AffwQ+8LgJIsqBo6Mj2rZti6CgIDRv3rzAnlvx/fffY82aNcp0xt0wx48fh4+PDwDg1q1bSEhIUObRZPqRuXPnwsjICJ07d8bbt2/RtGlThIWFwdDQsEDqRURERNrFvhEiIiLKrTz3bBw7dgw9e/aEi4sLFi5ciFatWuHcuXPajI2IqND580+gTRsgOVmR7toVWLaMAzNE+bV27VokJyejXbt2cHV1xbBhw3D27FmdbzcsLAxCiCx/GQMzgOIhwMHBwcp0xvQjMTExSEpKQkREBKpVq6ZSrpmZGRYuXIhnz57hzZs32Lt3L9zd3XVeHyIiItIu9o0QERFRXuXqzpmHDx8iLCwMq1atwuvXr9G5c2ekpqZi+/btqFq1qq5iJCIqFK5cAfz9gcRERbp1a2DtWoAXwhPlX/v27dG+fXu8evUK27Ztw8aNG9GwYUOULVsWPXv2xPecN5CIiIgKCPtGiIiISBs0vnOmVatWqFq1Kq5fv46FCxfi0aNHWLhwoS5jIyIqNP7+G2jRAoiPV6Q/+wzYsgUwNpY2LqKixtraGn369MHhw4dx+fJlWFpaYsqUKVKHRURERMUE+0aIiIhIWzS+c+bw4cP4+uuv8eWXX6JixYq6jImIqFCJjgaaNQMeP1akP/kE2L0bMDOTNi6ioigpKQl79uzBhg0bcPDgQTg6OmL06NFSh0VERETFBPtGiIiISFs0vnPm999/x6tXr1CvXj00aNAAixYtQlxcnC5jIyLSe7GxQNOmwIMHinSNGsD+/YCVlbRxERU1hw8fRu/eveHk5IRBgwbB0dERhw4dQnR0NGbNmiV1eERERFRMsG+EiIiItEXjwRlvb2+sWLECMTExGDhwIDZt2gQ3NzfI5XKEh4fj1atXuoyTiEjvPH+umMrszh1FulIl4PBhoFQpaeMiKoratm2LN2/eYM2aNXj8+DF+/vlnNGnSROqwiIiIqJhh3wgRERFpi8aDMxksLCzQt29fnDp1ClevXsWoUaPwww8/wNHREW3atNFFjEREeufVK8DfH7h6VZEuUwY4cgRwcpI2LqKiKjY2Flu3bkXbtm1hzIc5ERERkcTYN0JERET5levBmcy8vLwQGhqKhw8fYuPGjdqKiYhIr719C7RpA5w5o0g7OwNHjwLu7tLGRVSUlShRAunp6di+fTumT5+OGTNmYMeOHUhPT5c6NCIiIirm2DdCREREeWGkjUIMDQ3Rtm1btG3bVhvFERHprZQUoFMn4MQJRdrWFggPByr8H3v3HR5FufZx/LebTkloaUCkS+8gTQQEQUAQkaJIRz0cREBsBKVKfz0IUi1AEKUdMYgVUJoFlRZEQKRJUSCIkFBMAtl5/9iThSWFtC3ZfD/XtReZZ56Zve9ndzLD3JmZii4NC/B4R44cUYcOHfTHH3+ocuXKMgxDv/32myIiIvTZZ5+pQoUKrg4RAADkc5wbAQAAWZHp4szAgQPv2MdkMmnRokU5CggA3FVystSnj/TZZ9bpQoWkL7+UatRwbVxAfjBs2DBVqFBBP/zwg4oVKyZJunDhgnr37q1hw4bps5QNEwAAwIE4NwIAAHJLposzUVFRKlOmjOrWrSvDMBwZEwC4HYtFevppafVq67S/v/Tpp1LDhq6NC8gvtm7daleYkaTixYtr2rRpatasmQsjAwAA+QnnRgAAQG7JdHFm8ODBWrlypY4dO6aBAweqd+/edidIAMBTGYY0cqS0eLF12sdH+ugjqUUL18YF5Cd+fn66fPlyqvYrV67I19fXBREBAID8iHMjAAAgt5gz23H+/Pk6c+aMXn75ZX3yySeKiIhQjx49tH79ev5aBIBHGz9emj3b+rPZLH3wgdS+vUtDAvKdhx56SE8//bR+/PFHGYYhwzD0ww8/aPDgwercubOrwwMAAPkE50YAAEBuyXRxRrL+1erjjz+ujRs36sCBA6pevbqGDBmiMmXK6MqVK46KEQBc5vXXpYkTb06/+67Uvbvr4gHyqzfffFMVKlRQkyZN5O/vL39/fzVr1kwVK1bU7JTqKQAAgBNwbgQAAOSGTN/W7HYmk0kmk0mGYchiseRmTADgFt5+W3rxxZvTs2dLAwa4Lh4gvzIMQ3FxcVqxYoX+/PNPHTx4UIZhqFq1aqpYsaKrwwMAAPkY50YAAEB2ZenKmcTERK1YsUIPPPCAKleurH379mnu3Lk6efKkChUq5KgYAcDpli+XBg++OT1pkjRsmOviAfIzwzBUqVIl/fHHH6pYsaI6deqkzp07U5gBAAAuwbkRAACQGzJ95cyQIUO0cuVK3XXXXRowYIBWrlyp4sWLOzI2AHCJjz+W+vaVUm4Z/dJL0ujRro0JyM/MZrMqVaqkCxcuqFKlSq4OBwAA5GOcGwEAALkl08WZhQsX6q677lK5cuW0detWbd26Nc1+H330Ua4FBwDO9tVXUo8eUnKydXrwYGnaNMlkcm1cQH43Y8YMvfjii1qwYIFq1Kjh6nAAAEA+xbkRAACQWzJdnOnbt69MnJ0E4MG+/156+GEpKck63bu3NG8ehRnAHfTu3VvXrl1T7dq15evrq4CAALv5f//9t4siAwAA+QnnRgAAQG7JdHEmKirKgWEAgGvFxEgdOkjXrlmnu3SRliyRzFl6MhcAR5k1a5arQwAAAODcCAAAyDWZLs4AgKf69VepbVspLs46/cAD0sqVkje/IQG30a9fP1eHAAAAAAAAkGs49QggX/v9d2sx5vx563TTplJ0tOTn59KwAKQhOTlZ0dHROnjwoEwmk6pWraqHH35Y3lRSAQAAAABAHsPZDAD51pkzUps20unT1uk6daTPPpMKFnRpWADS8Msvv+jhhx/W2bNnVblyZUnSb7/9puDgYK1bt041a9Z0cYQAAAAAAACZx9MUAORLFy5Yr5g5etQ6XaWKtGGDVKSIS8MCkI4nn3xS1atX1+nTp7V7927t3r1bp06dUq1atfT000+7OjwAAAAAAIAs4coZAPlOfLz04IPS/v3W6bJlpY0bpeBgl4YFIAN79+7Vzp07VbRoUVtb0aJFNXnyZDVs2NCFkQEAAAAAAGQdV84AyFeuXZM6dZJ27rROh4dLX30llS7t2rgAZKxy5co6d+5cqvbY2FhVrFjRBREBAAAAAABkH8UZAPlGUpL06KPStm3W6eLFrVfMVKjg2rgA3NmUKVM0bNgwffjhhzp9+rROnz6tDz/8UCNGjND06dMVHx9vewEAAAAAALg7bmsGIF+4cUPq1Uv68kvrdOHC0vr1UvXqro0LQOY89NBDkqQePXrIZDJJkgzDkCR16tTJNm0ymZScnOyaIAEAAAAAADKJ4gwAj2exSE89Ja1ZY50OCJA++0yqX9+1cQHIvM2bN7s6BAAAAAAAgFxDcQaARzMMacQIKSrKOu3jI0VHS82buzIqAFnVokULV4cAAAAAAACQayjOAPBoY8ZIc+ZYfzabpZUrpXbtXBsTgOxJSEjQzz//rNjYWFksFrt5nTt3dlFUAAAAAAAAWUdxBoDHmj5dmjz55vSSJVLXrq6LB0D2ffnll+rbt6/++uuvVPN4zgwAAEAeZxjSoUPShQtSUpJ06ZJUubL0v2cNAgDgicyufPNt27apU6dOKlmypEwmk9auXWs33zAMjR8/XiVLllRAQIBatmyp/fv333G9a9asUbVq1eTn56dq1aopOjo6VZ/58+erXLly8vf3V/369fXNN9/kVloA3MD8+dKoUTen586V+vZ1XTwAcmbo0KHq3r27zpw5I4vFYveiMAMAAPKqfH9e5No1ae1aqV8/qVcvafBg63/eeveWBgyQPv5Y+ucf58cFAIATuLQ4c/XqVdWuXVtz585Nc/6MGTM0c+ZMzZ07Vzt27FBYWJgeeOABXb58Od11bt++XT179lSfPn20d+9e9enTRz169NCPP/5o67Nq1SqNGDFCr7zyivbs2aPmzZurffv2OnnyZK7nCMBxEhKkZcukbt1M6tq1qLp1M2nZMmnRIumZZ272mzrVfhpA3hMbG6uRI0cqNDTU1aEAAADkmnx9XuTcOWnIEGn0aGnXLqlwYSkiQgoOlgoVknbskCIjrf+Zi411XlwAADiJS4sz7du316RJk9Q1jfsMGYahWbNm6ZVXXlHXrl1Vo0YNLV26VNeuXdPy5cvTXeesWbP0wAMPKDIyUlWqVFFkZKRat26tWbNm2frMnDlTgwYN0pNPPqmqVatq1qxZioiI0IIFCxyRJgAHWLdOKlnSejXMxx9L27f76eOPrdNPPnmzX2Sk/RU0APKmbt26acuWLa4OAwAAIFfl2/Mily5JI0dK27dLpUpJ5ctLgYGSt7fk5WX9uXx563/6vvtOeuEFKS7OObEBAOAkbvvMmePHj+vs2bNq27atrc3Pz08tWrTQ999/r3/9619pLrd9+3Y999xzdm3t2rWzHYQkJSVp165dGnXb2dq2bdvq+++/TzeexMREJSYm2qbj4+MlyXZLldxgsVhkGEaurc/VPCkfT8pFyvv5rFsnde2acu9hkywW688p/6Zo397Qa68Zymtp5vXP53bk474ckYujxmXu3Lnq3r27vvnmG9WsWVM+Pj5284cNG+aQ9wUAAHAVjz4vsnSptHu3VLas5Odna7aYTDJMJllSnjVToIC1z44d0vvvS//+d9beJ5/xpP+rOBtjlzOMX84wftnnjmOXlVjctjhz9uxZSUp1+5LQ0FCdOHEiw+XSWiZlfX/99ZeSk5Mz7JOWqVOnasKECanaz58/r4SEhIyTySSLxaK4uDgZhiGz2aUXNeUKT8rHk3KR8nY+CQlS//4hkiTDyOjhkIa+/97QqVOx8vd3Tmy5JS9/PmkhH/fliFwyusVGTixfvlzr169XQECAtmzZItMtD4c1mUwUZwAAgMfx2PMi//wj7dsn1akjFStmN8siKa5ECevx6a0zihaVYmKkkyeV5/6D50Se9H8VZ2PscobxyxnGL/vcceyycl7EbYszKW49+SJZL+u9vS07y2R1vZGRkRo5cqRtOj4+XhEREQoODlZgYGCG8WSWxWKRyWRScHCw23yZcsKT8vGkXKS8nc+yZVJcXGZiNikuzqRt20LUu7fDw8pVefnzSQv5uC9H5OLvoP8sv/rqq5o4caJGjRrl1HGfPHmyPvvsM8XExMjX11eXLl3KsP/169f16quv6vPPP9exY8cUFBSkNm3aaNq0aSpZsqStX8uWLbV161a7ZXv27KmVK1c6Ig0AAJCHedx5kU8+kX74wfp8matX7WZZTCbr8enp0zIbxs0ZSUnS/v3SL79IHTpk/r3yGU/6v4qzMXY5w/jlDOOXfe44dlk5L+K2xZmwsDBJ1r/4CA8Pt7XHxsZm+DDgsLCwVH/pcesyJUqUkJeXV4Z90uLn5ye/Wy61TWE2m3P1gzeZTLm+TlfypHw8KRcp7+azbp1kNitTtyozm6WPPzarb1/Hx5Xb8urnkx7ycV+5nYujxiQpKUk9e/Z0+pgnJSWpe/fuatKkiRYtWnTH/teuXdPu3bs1ZswY1a5dWxcvXtSIESPUuXNn7dy5067vU089pYkTJ9qmAwICcj1+AACQd3nseZFTp6TkZOvzZW4twPyPyTBk/t/LxsfHusypU9b/6CFdnvR/FWdj7HKG8csZxi/73G3sshKHe0SchnLlyiksLEwbN260tSUlJWnr1q1q2rRpuss1adLEbhlJ2rBhg20ZX19f1a9fP1WfjRs3ZrheAO7hwoXMFWYka7+//3ZsPACco1+/flq1apXT33fChAl67rnnVLNmzUz1DwoK0saNG9WjRw9VrlxZjRs31pw5c7Rr1y6dPHnSrm+BAgUUFhZmewUFBTkiBQAAkEd57HmR69ddsywAAG7GpVfOXLlyRUeOHLFNHz9+XDExMSpWrJjuuusujRgxQlOmTFGlSpVUqVIlTZkyRQUKFFCvXr1sy/Tt21elSpXS1KlTJUnDhw/Xfffdp+nTp+vhhx/Wxx9/rK+++krffvutbZmRI0eqT58+atCggZo0aaK3335bJ0+e1ODBg52XPIAsMwzrM2cyy2xOdQtjAHlUcnKyZsyYofXr16tWrVry8fGxmz9z5kwXRXZncXFxMplMKlKkiF37Bx98oPfff1+hoaFq3769xo0bp8KFC6e7nlx9CK+bc8eHOjoCeXoOh+foJn8FaDGbrQ/qdpN4HCE/5Ci5WZ65vN3ktd81+fK8SKFC1n8NQ7rD7dlsDMP6XUlZFgAAD+DS4szOnTvVqlUr23TKvUv79eunqKgovfTSS/rnn380ZMgQXbx4UY0aNdKGDRvsTlycPHnS7lKhpk2bauXKlXr11Vc1ZswYVahQQatWrVKjRo1sfXr27KkLFy5o4sSJOnPmjGrUqKHPP/9cZcqUcULWALJj82Zp1Cjpp58yv4zFIj3yiONiAuA8+/btU926dSVJv/zyi928O91z3ZUSEhI0atQo9erVy+5e7E888YTtr2F/+eUXRUZGau/evan+gvVWufYQ3jzAHR/q6Ajk6TkcnmP9+rm/zmywmEyKq1hRhmR/uyEPkh9ylNwsz9jYXF1dVh7C6w7y5XmRhg0lf3/pyhUpgz9MsXP5slSwoHTPPY6NDQAAJzIZhquPxPKm+Ph4BQUFKS4uLmsPvsuAxWJRbGysQkJCPOI/rp6UjyflIuWtfHbtkkaPljZsyNpyJpNUpIj055/W4/68JC99PplBPu7LEbk4Yv+Y28aPH59mkeNWO3bsUIMGDWzTUVFRGjFihC5dupTp97l+/bq6d++ukydPasuWLRmOx65du9SgQQPt2rVL9erVS7NPWlfORERE6OLFi2471tllsVh0/vx5t3qooyOQp+dweI63XS3oKhazWefr1VPw7t0y57GrEzIrP+QouVmeuXybqvj4eBUtWtStj0U8RbaP+wxDGjDA+pd3FSrYzbKYTIqNiFDIqVP2hcOjR6XGjaVFizJ/tU0+5En/V3E2xi5nGL+cYfyyzx3HLiv7R5deOQMA6fntN2nMGGn1avv2GjWsV8NMmmSdTqu8nHKsvnRp3ivMAHC8oUOH6rHHHsuwT9myZXP0HtevX1ePHj10/Phxbdq06Y4HZPXq1ZOPj48OHz6cbnEm1x7Cm0e420MdHYU8PYdDc3T1yfNbmAxDZovF9Sf0HSg/5Ci5UZ65vM148u8Zj2EySU88Ie3dK507J4WGZtz/3Dnrf+x696YwAwDwKBRnALiVP/6QJk60/kFUcvLN9rJlpddekx5/XPLykho0kPr3ly5elMxmQxaLyfZvkSLWwkynTi5KAkCu6dq1a6b6ffTRR5leZ4kSJVSiRInshnRHKYWZw4cPa/PmzSpevPgdl9m/f7+uX7+u8PBwh8UFAADgNtq0kf79b2nePOnkSSksTPL1te+TlCSdOWMt4A0bJt1/v2tiBQDAQSjOAHALFy9K06dLs2dLtz46ITjYegXN009Lt/7BeOfO1luWffih9NFH0tmziQoL81XXrlK3blwxA3iKoKAgl77/yZMn9ffff+vkyZNKTk5WTEyMJKlixYoq9L8H0lapUkVTp07VI488ohs3bqhbt27avXu3Pv30UyUnJ+vs2bOSpGLFisnX11dHjx7VBx98oA4dOqhEiRI6cOCAnn/+edWtW1fNmjVzVaoAAADOYzJJTz0lFSsmvf22dOqUtT0gwPo6dsx61WDp0tYiTpcuLg0XAABHoDgDwKWuXZPefNNamLn1UQ6FC0svviiNGJH+MyJTrmzv1ctQbOzF/91fksvcAU+yZMkSl77/2LFjtXTpUtt03bp1JUmbN29Wy5YtJUmHDh1SXFycJOn06dNat26dJKlOnTp260pZxtfXV19//bVmz56tK1euKCIiQh07dtS4cePk5eXl+KQAAADcgclk/cu69u2lzZul9eutV8qEhVlf7dpJLVtKBQq4OlIAAByC4gwAl7h+3XrrsokTrcffKXx9paFDpchIyYF3HQKATImKilJUVFSGfYxbHn5VtmxZu+m0REREaOvWrbkRHgAAQN5XsKD00EPWl8UixcZKISG5/jwiAADcDcUZAE5lsUirV0uvviodPXqz3Wy2PkNm3DjprrtcFh4AAAAAAAAAOBzFGQBOYRjWq9QjI6X/PbLB5pFHpMmTpapVXRIaAAAAAAAAADgVxRkADvfDD9KoUdLtd/Fp2VKaNk1q1MglYQEAAAAAAACAS3ADTwAOs3+/9aqYJk3sCzN161qvotm0icIMAAAAAAAAgPyH4gyAXHfihDRggFSrlrR27c32SpWkVauknTultm0lk8llIQIAAAAAAACAy3BbMwC55vx5acoUaf58KSnpZnt4uDR+vLVg4+PjsvAAAAAAAAAAwC1QnAGQY5cvSzNnSq+/Ll25crO9SBEpMlIaOlQqUMBl4QEAAAAAAACAW6E4AyDbEhOlt96SJk2yXjWTIiBAGj5ceuklqWhR18UHAAAAAAAAAO6I4gyALEtOlj74QBo71vp8mRReXtJTT0ljxkglS7ouPgAAAAAAAABwZxRnAGSaYUiffCKNHi3t328/77HHpIkTpUqVXBMbAAAAAAAAAOQVFGcAZMq2bdKoUdL27fbtDz4oTZki1a3rmrgAAAAAAAAAIK+hOAMgQzEx1itlvvjCvr1RI2naNKllS1dEBQAAAAAAAAB5l9nVAQBwT0ePSr16Wa+IubUwU7WqFB1tvYKGwgwAAAAAAAAAZB1XzgCwc+aMNGmS9Pbb0o0bN9sjIqzPlOnTR/Lycl18AAAAAAAAAJDXUZwBIEm6dEn6v/+TZs2Srl272V6ihPTKK9LgwZK/v6uiAwAAAAAAAADPQXEGyOf++UeaO1eaOlW6ePFme6FC0vPPSyNHSoGBrosPAAAAAAAAADwNxRkgn7pxQ3rnHem116Q//rjZ7uMjDRkijR4thYS4Lj4AAAAAAAAA8FQUZ4B8xjCkDz+URo8uoaNHzbZ2k0nq21caP14qW9Zl4QEAAAAAAACAx6M4A+QjX30ljRol7dpllnSzMNO5szR5slSjhutiAwAAAAAAAID8guIMkA/s2CFFRkpff23f3ry5oWnTTGra1DVxAQAAAAAAAEB+ZL5zFwB51a+/St26SffcY1+YqV3b0Pvv/63Nmw0KMwAAAAAAAADgZBRnAA906pT05JNS9erSmjU328uXl5Yvl3buNNS6dZJMJtfFCAAAAAAAAAD5Fbc1AzzIhQvS1KnS3LlSYuLN9tBQaexYa8HG11eyWFwXIwAAAAAAAADkdxRnAA9w5Yo0a5b0f/8nxcffbA8MlF5+WRo+XCpY0GXhAQAAAAAAAABuQXEGyMOSkqR33pFee006d+5mu7+/9Oyz1sJM8eKuiw8AAAAAAAAAkBrFGSAPslikFSukMWOk48dvtnt5SQMHWm9hVrq06+IDAAAAAAAAAKSP4gyQhxiG9Pnn0ujR0s8/28/r3t16BU3lyq6JDQAAAAAAAACQORRngDziu++kUaOkb7+1b3/gAWnKFKlBA9fEBQAAAAAAAADIGoozgJvbt0965RXpk0/s2xs0kKZNk1q3dk1cAAAAAAAAAIDsMbs6gDu5fPmyRowYoTJlyiggIEBNmzbVjh070u3fv39/mUymVK/q1avb+kRFRaXZJyEhwRkpAZly/LjUt69Uu7Z9YaZyZenDD6WffqIwAwAAAACejvMiAAB4Jrcvzjz55JPauHGjli1bpn379qlt27Zq06aN/vjjjzT7z549W2fOnLG9Tp06pWLFiql79+52/QIDA+36nTlzRv7+/s5ICcjQuXPSsGHWIsyyZdbnzEhSqVLSu+9Kv/wiPfqoZDK5Nk4AAAAAgONxXgQAAM/k1rc1++eff7RmzRp9/PHHuu+++yRJ48eP19q1a7VgwQJNmjQp1TJBQUEKCgqyTa9du1YXL17UgAED7PqZTCaFhYU5NgEgC+Ljpddfl2bOlK5evdlerJg0erQ0ZIgUEOC6+AAAAAAAzsV5EQAAPJdbF2du3Lih5OTkVH+5ERAQoG9vfyp6OhYtWqQ2bdqoTJkydu1XrlxRmTJllJycrDp16ui1115T3bp1011PYmKiEhMTbdPx8fGSJIvFIovFktmUMmSxWGQYRq6tz9U8KR9H5pKQIC1YIE2datKFCzcvhylQwNCIEdILLxhKOa7Orbf3pM9GIh93Rz7uyxG5eMK4AAAAuAvOiyArGL/sY+xyhvHLGcYv+9xx7LISi1sXZwoXLqwmTZrotddeU9WqVRUaGqoVK1boxx9/VKVKle64/JkzZ/TFF19o+fLldu1VqlRRVFSUatasqfj4eM2ePVvNmjXT3r17013v1KlTNWHChFTt58+fz7V7slosFsXFxckwDJnNbn/HuTvypHwckcuNG9KHHwbo//6vkP7808vW7u1tqE+faxox4qpCQixKTJRiY3PlLW086bORyMfdkY/7ckQuly9fzpX1AAAAgPMiyBrGL/sYu5xh/HKG8cs+dxy7rJwXcevijCQtW7ZMAwcOVKlSpeTl5aV69eqpV69e2r179x2XjYqKUpEiRdSlSxe79saNG6tx48a26WbNmqlevXqaM2eO3nzzzTTXFRkZqZEjR9qm4+PjFRERoeDgYAUGBmYvudtYLBaZTCYFBwe7zZcpJzwpn9zMxTCktWulMWNMOnjw5pUyJpOhxx+XJkwwVL58gCTH3cPMkz4biXzcHfm4L0fkwn3KAQAAchfnRZBZjF/2MXY5w/jlDOOXfe44dlk5L+L2xZkKFSpo69atunr1quLj4xUeHq6ePXuqXLlyGS5nGIYWL16sPn36yNfXN8O+ZrNZDRs21OHDh9Pt4+fnJz8/vzSXzc0P3mQy5fo6XcmT8smNXDZvlkaNkn76yb69Y0dp8mSTateWJFNai+Y6T/psJPJxd+TjvnI7F08YEwAAAHfCeRFkBeOXfYxdzjB+OcP4ZZ+7jV1W4nCPiDOhYMGCCg8P18WLF7V+/Xo9/PDDGfbfunWrjhw5okGDBt1x3YZhKCYmRuHh4bkVLmBn1y6pXTvp/vvtCzNNm0rbtkmffqr/FWYAAO5k8uTJatq0qQoUKKAiRYpkapn+/fvLZDLZvW79y1TJes/2Z599ViVKlFDBggXVuXNnnT592gEZAAAAT8F5EQAAPIvbF2fWr1+vL7/8UsePH9fGjRvVqlUrVa5cWQMGDJBkvay2b9++qZZbtGiRGjVqpBo1aqSaN2HCBK1fv17Hjh1TTEyMBg0apJiYGA0ePNjh+SB/+e03qWdPqUEDacOGm+01akjr1knffis1b+66+AAAGUtKSlL37t3173//O0vLPfjggzpz5ozt9fnnn9vNHzFihKKjo7Vy5Up9++23unLlih566CElJyfnZvgAAMADcF4EAADP5Pa3NYuLi1NkZKROnz6tYsWK6dFHH9XkyZPl4+Mjyfpwu5MnT6ZaZs2aNZo9e3aa67x06ZKefvppnT17VkFBQapbt662bdume+65x+H5IH/4809p4kTp3XelW8+zlS1rbe/VS/Lycll4AIBMSnnobVRUVJaW8/PzU1hYWJrz4uLitGjRIi1btkxt2rSRJL3//vuKiIjQV199pXbt2uUoZgAA4Fk4LwIAgGdy++JMjx491KNHj3Tnp3WyJCgoSNeuXUt3mTfeeENvvPFGboQH2Ll4UZo+XZo9W0pIuNkeHCyNGSM9/bSUxi16AQAeZsuWLQoJCVGRIkXUokULTZ48WSEhIZKkXbt26fr162rbtq2tf8mSJVWjRg19//336RZnEhMTlZiYaJuOj4+XZH0AosVicWA2zmexWGQYhsfldTvy9BwOz9FN7p9tMZtlmEyyuEk8jpAfcpTcLM9c3m488XcN50UAAPBMbl+cAfKCa9ekN9+0FmYuXbrZXriw9OKL0ogR1p8BAJ6vffv26t69u8qUKaPjx49rzJgxuv/++7Vr1y75+fnp7Nmz8vX1VdGiRe2WCw0N1dmzZ9Nd79SpU21X8tzq/PnzSrj1LwI8gMViUVxcnAzDcJuHOjoCeXoOh+dYv37urzMbLCaT4ipWlCHJbBiuDsch8kOOkpvlGRubq6u7fPlyrq4PAADAUSjOADlw/bq0aJH1VmVnztxs9/WVhg6VIiOlEiVcFx8AILXx48enWeS41Y4dO9SgQYNsrb9nz562n2vUqKEGDRqoTJky+uyzz9S1a9d0lzMMQyaTKd35kZGRGjlypG06Pj5eERERCg4OVmBgYLZidVcWi0Umk0nBwcEeezJfIk9P4vAcd+3K/XVmg8VslklS8O7dMnvg1QlS/shRcrM8/3dlaW7x9/fP1fUBAAA4CsUZIBssFmn1auutyo4cudluNkv9+0vjxkl33eWy8AAAGRg6dKgee+yxDPuULVs2194vPDxcZcqU0eHDhyVJYWFhSkpK0sWLF+2unomNjVXTpk3TXY+fn5/80rg3ptls9sgT3iaTyWNzuxV5eg6H5ujqk+e3MBmGzBaL60/oO1B+yFFyozxzeZvx5N8zAADAs1CcAbLAMKT1661XxOzZYz/vkUekyZOlqlVdExsAIHNKlCihEk68rPHChQs6deqUwsPDJUn169eXj4+PNm7caLt//JkzZ/TLL79oxowZTosLAAAAAAC4Dn9SAmTSrl0+atPGpAcftC/MtGwp/fCD9NFHFGYAwNOcPHlSMTExOnnypJKTkxUTE6OYmBhduXLF1qdKlSqKjo6WJF25ckUvvPCCtm/frt9//11btmxRp06dVKJECT3yyCOSrA/oHTRokJ5//nl9/fXX2rNnj3r37q2aNWuqTZs2LskTAAAAAAA4F1fOAHdw4IA0erRJH39c3K69bl1p2jTpgQekDB4RAADIw8aOHaulS5fapuvWrStJ2rx5s1q2bClJOnTokOLi4iRJXl5e2rdvn9577z1dunRJ4eHhatWqlVatWqXChQvb1vPGG2/I29tbPXr00D///KPWrVsrKipKXl5ezksOAAAAAAC4DMUZIB0nTkjjx0vvvSdZLDerL5UqSZMmSd265frtkQEAbiYqKkpRUVEZ9jEMw/ZzQECA1q9ff8f1+vv7a86cOZozZ05OQwQAAAAAAHkQxRngNufPS1OmSPPnS0lJN9tDQ5M1frxJgwaZ5ePjuvgAAAAAAAAAAHkbxRngfy5flt54Q3r9devPKYoUkUaNsqh79/MqWzaEq2UAAAAAAAAAADlCcQb5XmKi9NZb1luVnT9/sz0gQBo+XHrpJSkoSIqNdV2MAAAAAAAAAADPQXEG+VZysvTBB9LYsdbny6Tw8pKeekoaM0YqWdLaZrG4JkYAAAAAAAAAgOehOIN8xzCkTz6RRo+W9u+3n/fYY9LEiVKlSq6JDQAAAAAAAADg+SjOIF/Ztk0aNUravt2+/cEHpSlTpLp1XRMXAAAAAAAAACD/oDiDfCEmxnqlzBdf2Lc3aiRNmya1bOmKqAAAAAAAAAAA+ZHZ1QEAjnT0qNSrl/WKmFsLM1WrStHR1itoKMwAAAAAAAAAAJyJK2fgkc6ckSZNkt5+W7px42Z7RIT1mTJ9+kheXq6LDwAAAAAAAACQf1GcgUe5dEn6v/+TZs2Srl272V6ihPTKK9LgwZK/v6uiAwAAAAAAAACA4gw8xD//SHPnSlOnShcv3mwvVEh6/nlp5EgpMNB18QEAAAAAAAAAkILiDPK0GzekJUukCROkP/642e7jI/3739arZUJCXBcfAAAAAAAAAAC3oziDPMkwpDVrrMWX33672W4yWZ8nM2GCVLasy8IDAAAAAAAAACBdFGeQ53z1lTRqlLRrl317587S5MlSjRquiQsAAAAAAAAAgMygOIM8Y8cOKTJS+vpr+/bmzaVp06SmTV0TFwAAAAAAAAAAWWF2dQDAnfz6q9Stm3TPPfaFmdq1pc8/l7ZupTADAAAAAAAAAMg7KM7AbZ06JT35pFS9uvX5MinKl5c++EDavVtq3976nBkAAAAAAAAAAPIKbmsGt3PhgjR1qjR3rpSYeLM9NFQaO9ZasPH1dV18AAAAAAAAAADkBMUZuI0rV6TZs6UZM6T4+JvtgYHSyy9Lw4dLBQu6Lj4AAAAAAAAAAHIDxRm4XFKS9M470muvSefO3Wz395eefdZamCle3HXxAQAAAAAAAACQmyjOwGUsFmnFCmnMGOn48ZvtZrM0cKA0bpxUurTr4gMAAAAAAAAAwBEozsDpDEP6/HNp9Gjp55/t53XrZr2CpkoV18QGAAAAAAAAAICjUZyBU333nRQZKX3zjX37Aw9IU6ZIDRq4Ji4AAAAAAAAAAJyF4gycYt8+6ZVXpE8+sW9v0ECaNk1q3do1cQEAAAAAAAAA4GwUZ+BQJ0966cUXTfrgA+vtzFJUrixNnix17SqZTK6LDwAAAAAAAAAAZ6M4A4c4d06aNMmkt94qoevXb1ZfSpWSJkyQ+vWTvPn2AQAAAAAAAADyIU6PI1fFx0uvvy7NnCldvXqzKFOsmDR6tDRkiBQQ4MIAAQAAAAAAAABwMbOrA7iTy5cva8SIESpTpowCAgLUtGlT7dixI93+W7ZskclkSvX69ddf7fqtWbNG1apVk5+fn6pVq6bo6GhHp+LREhKkN96QypeXXntNunrV2h4QYNHo0YaOHZOef57CDAAAAAAAWcF5EQAAPJPbF2eefPJJbdy4UcuWLdO+ffvUtm1btWnTRn/88UeGyx06dEhnzpyxvSpVqmSbt337dvXs2VN9+vTR3r171adPH/Xo0UM//vijo9PxODduSEuWSHffLY0cKV24YG339paGDDH0ww9/6bXXDAUFuTZOAAAAAADyIs6LAADgmdy6OPPPP/9ozZo1mjFjhu677z5VrFhR48ePV7ly5bRgwYIMlw0JCVFYWJjt5eXlZZs3a9YsPfDAA4qMjFSVKlUUGRmp1q1ba9asWQ7OyHMYhhQdLdWqJQ0cKJ06ZW03maQnnpAOHZLmzDEUEmJxbaAAAAAAAORRnBcBAMBzufUzZ27cuKHk5GT5+/vbtQcEBOjbb7/NcNm6desqISFB1apV06uvvqpWrVrZ5m3fvl3PPfecXf927dpleBCSmJioxMRE23R8fLwkyWKxyGLJnQKExWKRYRi5tj5H2bxZGj3apJ9+Mtm1d+hgaNIkQ7VrW6fzSj6Z4Um5SOTj7sjHvXlSPo7IxRPGBQAAwF1wXgRZwfhlH2OXM4xfzjB+2eeOY5eVWNy6OFO4cGE1adJEr732mqpWrarQ0FCtWLFCP/74o93luLcKDw/X22+/rfr16ysxMVHLli1T69attWXLFt13332SpLNnzyo0NNRuudDQUJ09ezbdWKZOnaoJEyakaj9//rwSEhJykOVNFotFcXFxMgxDZrP7XdT088/emjKlsLZu9bNrb9gwSaNHX1bjxtclSbGx1nZ3zycrPCkXiXzcHfm4N0/KxxG5XL58OVfWAwAAAM6LIGsYv+xj7HKG8csZxi/73HHssnJexK2LM5K0bNkyDRw4UKVKlZKXl5fq1aunXr16affu3Wn2r1y5sipXrmybbtKkiU6dOqXXX3/ddhAiSSaT/VUfhmGkartVZGSkRo4caZuOj49XRESEgoODFRgYmN307FgsFplMJgUHB7vNl0mSDh+Wxo41afVq+/GpUcN6pcxDD3nLZCqaajl3zSc7PCkXiXzcHfm4N0/KxxG53P5XnQAAAMgZzosgsxi/7GPscobxyxnGL/vcceyycl7E7YszFSpU0NatW3X16lXFx8crPDxcPXv2VLly5TK9jsaNG+v999+3TYeFhaX6a5DY2NhUfzVyKz8/P/n5+aVqN5vNufrBm0ymXF9ndv35pzRxovTuu1Jy8s32smWt7b16meTllf6Bm+Re+eSUJ+UikY+7Ix/35kn55HYunjAmAAAA7oTzIsgKxi/7GLucYfxyhvHLPncbu6zE4R4RZ0LBggUVHh6uixcvav369Xr44YczveyePXsUHh5um27SpIk2btxo12fDhg1q2rRprsWbl128KI0aJVWsKL311s3CTHCw9Oab0q+/Sn36SLc8SxAAAAAAADgQ50UAAPAsbn/lzPr162UYhipXrqwjR47oxRdfVOXKlTVgwABJ1stq//jjD7333nuSpFmzZqls2bKqXr26kpKS9P7772vNmjVas2aNbZ3Dhw/Xfffdp+nTp+vhhx/Wxx9/rK+++uqOD9PzdNeuWYsv06dLly7dbC9cWHrxRWnECOvPAAAAAADAOTgvAgCAZ3L74kxcXJwiIyN1+vRpFStWTI8++qgmT54sHx8fSdKZM2d08uRJW/+kpCS98MIL+uOPPxQQEKDq1avrs88+U4cOHWx9mjZtqpUrV+rVV1/VmDFjVKFCBa1atUqNGjVyen7u4Pp1adEi663Kzpy52e7rKw0dKkVGSiVKuC4+AAAAAADyK86LAADgmdy+ONOjRw/16NEj3flRUVF20y+99JJeeumlO663W7du6tatW07Dy9MsFmn1amnMGOnIkZvtZrPUr580frx0110uCw8AAJebPHmyPvvsM8XExMjX11eXbr20NB3pPUh3xowZevHFFyVJLVu21NatW+3m9+zZUytXrsxxzAAAwLNwXgQAAM/k9sUZ5D7DkDZssF4Rs2eP/bxHHpEmTZKqVXNNbAAAuJOkpCR1795dTZo00aJFizK1zJlbL0OV9MUXX2jQoEF69NFH7dqfeuopTZw40TYdEBCQ84ABAAAAAECeQHEmn/nhB2tRZssW+/aWLaVp0ySuYAYA4KYJEyZISv0XqRkJCwuzm/7444/VqlUrlS9f3q69QIECqfoCAAAAAID8geJMPnHggPTKK9LatfbtdetaizIPPCClcxcWAACQTefOndNnn32mpUuXppr3wQcf6P3331doaKjat2+vcePGqXDhwumuKzExUYmJibbp+Ph4SZLFYpHFYsn94F3IYrHIMAyPy+t25Ok5HJ6j2eyY9WaRxWyWYTLJ4ibxOEJ+yFFyszxzebvx5N81AADAs1Cc8XAnTlifHfPee/bHvBUrSpMnS926uc3/9QAA8DhLly5V4cKF1bVrV7v2J554QuXKlVNYWJh++eUXRUZGau/evdq4cWO665o6dartSp5bnT9/XgkJCbkeuytZLBbFxcXJMAyZPfhAhTw9h8NzrF8/99eZDRaTSXEVK8qQZDYMV4fjEPkhR8nN8oyNzdXVXb58OVfXBwAA4CgUZzzU+fPSlCnS/PlSUtLN9vBwadw4aeBAycfHdfEBAOAq48ePT7PIcasdO3aoQYMGOX6vxYsX64knnpC/v79d+1NPPWX7uUaNGqpUqZIaNGig3bt3q169emmuKzIyUiNHjrRNx8fHKyIiQsHBwQoMDMxxrO7EYrHIZDIpODjYY0/mS+TpSRye465dub/ObLCYzTJJCt69W2YPvTohP+QouVmeISG5urrb97kAAADuiuKMh7l8WXrjDen1160/pyhSRBo1Snr2WalAAZeFBwCAyw0dOlSPPfZYhn3Kli2b4/f55ptvdOjQIa1ateqOfevVqycfHx8dPnw43eKMn5+f/Pz8UrWbzWaPPOFtMpk8NrdbkafncGiOrj55fguTYchssbj+hL4D5YccJTfKM5e3GU/+PQMAADwLxRkPkZgovfWWNGmS9aqZFAEB0vDh0ksvSUWLui4+AADcRYkSJVSiRAmHv8+iRYtUv3591a5d+4599+/fr+vXrys8PNzhcQEAAAAAANfjT0ryuORk6/NkKle2FmFSCjNeXtLgwdKRI9LUqRRmAADIjpMnTyomJkYnT55UcnKyYmJiFBMToytXrtj6VKlSRdHR0XbLxcfH67///a+efPLJVOs8evSoJk6cqJ07d+r333/X559/ru7du6tu3bpq1qyZw3MCAAAAAACux5UzeZRhSJ98Io0eLe3fbz/vscekiROlSpVcExsAAJ5i7NixWrp0qW26bt26kqTNmzerZcuWkqRDhw4pLi7ObrmVK1fKMAw9/vjjqdbp6+urr7/+WrNnz9aVK1cUERGhjh07aty4cfLy8nJcMgAAAAAAQJJ044Z04YKUkGB9DEiJEpLJ5NwYKM7kQdu2WZ8fs327fXu7dtKUKVI6t6oHAABZFBUVpaioqAz7GIaRqu3pp5/W008/nWb/iIgIbd26NTfCAwAAAAAAWfDXX9L69dJHH0mnTlnvTOXtbb0z1SOPSG3aSIULOycWijNuICFB+u9/pehok86eLaqwMJMeeUTq3l3y97/Zb+9eKTJS+uIL++UbNbLeuqxVK+fGDQAAAAAAAABAXvD119Zntp85I/n4WB8F4uVlvYpm1y5p507pnXesF0DUqeP4eCjOuNi6dVL//tLFi5LZLFksfjKbDUVHW58hs3SpVK2aNHastHy5/bJVq1q/KA8/7PxLrgAAAAAAAAAAyAu+/tr6iJCrV6Xy5a1FmVsVKSJdvy4dPy6NGCG9+aZUq5ZjY6I440Lr1kldutyctlhMdv9euiR17pxStLnZLyLC+kyZPn1Sf4kAAAAAAAAAAIBVbKz1iplr16SyZdO/0MHHx1q4OXrUerHEqlWSn5/j4jI7btXISEKC9YoZSUrjVvV27SmFmRIlpDfekH77zboshRkAAAAAAAAAANK3fr31VmYREXe+A5XZbO135Ij0zTeOjYsrZ3IqIUHy9U3dbjbbtyck2M1e84F07aLkK8kis67rZl8/2feVpIc7W+93F1jktvUmJqZf3TGZ7Et7WemblGR/uc7tbn0YTnp9LZZUeefKelP4+d3cmq5ftz69Kbf73rhhfaXkkpBg/Wwz6pseX9+by+ZmXx+fm5W6rPRNTk6dz628va2vlL7Xr6e/3lv7WizWzy63+xqG9TucFovFPu+M+krWMfDxyf2+d9juM9339u9bTtbrLr8j0tp+0uvr7r8jUr4P0p23OXf/HXH7d+323xGZ3e5v7ZvR9xMAAAAAAMCJbtyQ1qyxnkrJ7MUO/v7WUx1r10pt2jguNoozOdW3r/2JuhQNGkjjxt2c7t3b7qRu5Z3Sh5IMSb+ohkZrqm3eIg1SoOJt0yZJYT9JgYMkVaokzZx5c71Dhlivy0pLRIQ0f/7N6eeek06dSrtvSIi0aNHN6VGjpMOH0+4bGCh98MHN6XHjpF9+SdXNZBgqIlnv35Zi6lTrk5XS88knN3+eOVP67rv0+/73vzdP1M6bZ71xYHref18KCrL+/O670uefp9930SLreEjSe+9J0dHWXJKSZPL1tS+vzpsn3XWX9efVq6UVK9Jf78yZ1s9Pso7JkiXp950yRapZ0/rz+vXSwoXp9x07VmrY0Prz1q3SrFnp9335ZeneeyVJPjt3yvTOO+mXi0eMkFq3tv68e7f1XnrpGTxY6tjR+vP+/dYbOKZnwACpa1frz0ePSiNHpt/38celXr2sP586JT3zTJrdTIahgNatrQ9qkqTz56VBg9Jfb4cO0r//bf05Pt66faandWvrWEjWbbh79/T7Nmtm3XZSZNQ3g98Rqb5vNWpYt50UgwZZ406LG/6OMI0fryK7d6fefiRr8eLDD29O54XfEe+8c/Pn//2OSJeb/45I9V275XeEtm+Xpk9Pf73p/Y7IqKADAAAAAADgROfOSX/8IRUtmrXlAgOlmBhrkcZRd7CiOOMiSUnWwkxmGJKSONcFAAAA5E/pXdnqbBaL9Y8+QkLSv/o6r8sPOUr5J08AAJDvJSRYD32yesjj5WVdLjFRKlDAMbGZDMNdjvTzlvj4eAUFBSnu3DkFBgam7nCH2xA99pj1D6Mtxp1va2Y2SZ07SytXprFed7llURp9LRaLYmNjFXLXXTKnfPvzwi2L0rgNkS2XkJCbuaTTN11udFszi8Wi2DNnFFK0qH0+t8pDtzWzWCyK/ftvhZQsac0nj9/WLNX3LY/f1sySkKDYs2dTbz9p9M0LvyMsPj6KPX/ems/tt9TLaL1u+Dsi1XctF25rFh8fr6DQUMXFxaW9f0SusR2LeOBYp7vf9TDk6TnyQ45S/sgzP+QoeXaenrx/dDeOGGtP/m46A+OXfYxdzjB+OcP4ZV9mxu7MGeu59YCAmzdNyYxz56ynobZuvfNzam6Vlf0jV87klL+//cnCjPrdouOj0qqP0+6aqNvWZ0gPdZNub5Zkf7L0TrLSN63n6GS1r8WSemxyY71p8fFJ+/ZyOe2bcvIxJRd//8w9oyWz63VlXy+vjPO5vW9mr98zmzO3TWS1r8mUfl+LxT7vjPpmZb056Stlv++dvm9ZWa+7/I640/aT3fVmVm7+jri1IOQO23JO+mb0XcvKdn9r34wKrgAAAAAAAE4UGiqVLy8dOJC14kx8vHTffVkrzGQVpTgX6d7dep+7O324JpO1X7duzokLAAAAAAAAAABPYDZLjz565xuP3Oqff6x/t/vwww6OzbGrR3r8/aWlS60/p1egSWlfujRrfygPAAAAAAAAAACkBx6QIiKkEyfu/DjH5GTp9GmpenWpSRPHxkVxxoU6dZLWrpWKFLFOm82G3b9Fikgff2ztBwAAAAAAAAAAsqZoUWnSJKl4cenYsfTvyP7PP9b5ZcpIU6Zk/i7y2cUzZ1ysc2fpzz+lDz+UPvpIOns2UWFhvura1XorM66YAQAAAAAAAAAg++65R3rjDWncOOn4cWtbUJD1EbrXr1ufMePtLdWuLU2ebH1OjaNRnHED/v5S795Sr16GYmMvKiQkRGazA580BAAAAAAAAABAPtKggfUiic2bpeho6cAB623MfHykdu2kLl2kZs2s085AcQYAAAAAAAAAAHi8gACpQwfrKylJSkiQChRw/C3M0kJxBgAAAAAAAAAA5Cu+vtaXq5hd99YAAAAAAAAAAAD5D8UZAAAAAAAAAAAAJ6I4AwAAAAAAAAAA4EQUZwAAAAAAAAAAAJyI4gwAAAAAAAAAAIATUZwBAAAAAAAAAABwIm9XB5BXGYYhSYqPj8+1dVosFl2+fFn+/v4ym/N+3cyT8vGkXCTycXfk4948KR9H5JKyX0zZT8JxHHEs4i48aTvLCHl6jvyQo5Q/8swPOUqenSfHIs7DeRH3w/hlH2OXM4xfzjB+2eeOY5eVYxGKM9l0+fJlSVJERISLIwEAwP1cvnxZQUFBrg7Do3EsAgBA+jgWcTyORQAASF9mjkVMBn9Oki0Wi0V//vmnChcuLJPJlCvrjI+PV0REhE6dOqXAwMBcWacreVI+npSLRD7ujnzcmyfl44hcDMPQ5cuXVbJkSbf5qxVP5YhjEXfhSdtZRsjTc+SHHKX8kWd+yFHy7Dw5FnEezou4H8Yv+xi7nGH8cobxyz53HLusHItw5Uw2mc1mlS5d2iHrDgwMdJsvU27wpHw8KReJfNwd+bg3T8ont3Phr1Sdw5HHIu7Ck7azjJCn58gPOUr5I8/8kKPkuXlyLOIcnBdxX4xf9jF2OcP45Qzjl33uNnaZPRbhz0gAAAAAAAAAAACciOIMAAAAAAAAAACAE1GccSN+fn4aN26c/Pz8XB1KrvCkfDwpF4l83B35uDdPyseTcoFnyS/fTfL0HPkhRyl/5JkfcpTyT57Ie/hu5gzjl32MXc4wfjnD+GVfXh87k2EYhquDAAAAAAAAAAAAyC+4cgYAAAAAAAAAAMCJKM4AAAAAAAAAAAA4EcUZAAAAAAAAAAAAJ6I4AwAAAAAAAAAA4EQUZxxo/vz5KleunPz9/VW/fn198803GfbfunWr6tevL39/f5UvX14LFy5M1WfNmjWqVq2a/Pz8VK1aNUVHRzsq/FSyks9HH32kBx54QMHBwQoMDFSTJk20fv16uz5RUVEymUypXgkJCY5ORVLW8tmyZUuasf766692/fLK59O/f/8086levbqtj6s+n23btqlTp04qWbKkTCaT1q5de8dl3HnbyWo+7r7tZDUfd992spqPO287U6dOVcOGDVW4cGGFhISoS5cuOnTo0B2Xc+ftB57FU/ZT6fG0/Vd6PG2/lhZP29elx5P2genJD/vG7OSYF7dLeJ47/Q4yDEPjx49XyZIlFRAQoJYtW2r//v2uCdbNZGa7Z/zSt2DBAtWqVUuBgYG234FffPGFbT5jl3lTp06VyWTSiBEjbG2MX/rGjx+far8aFhZmm8/Y3dkff/yh3r17q3jx4ipQoIDq1KmjXbt22ebnxTGkOOMgq1at0ogRI/TKK69oz549at68udq3b6+TJ0+m2f/48ePq0KGDmjdvrj179mj06NEaNmyY1qxZY+uzfft29ezZU3369NHevXvVp08f9ejRQz/++KPb5bNt2zY98MAD+vzzz7Vr1y61atVKnTp10p49e+z6BQYG6syZM3Yvf39/t8snxaFDh+xirVSpkm1eXvp8Zs+ebZfHqVOnVKxYMXXv3t2unys+n6tXr6p27dqaO3dupvq7+7aT1XzcfdvJaj4p3HXbyWo+7rztbN26Vc8884x++OEHbdy4UTdu3FDbtm119erVdJdx9+0HnsOT9lPp8bT9V3o8bb+WFk/b16XHk/aB6ckP+8bs5JgXt0t4njv9DpoxY4ZmzpypuXPnaseOHQoLC9MDDzygy5cvOzlS95OZ7Z7xS1/p0qU1bdo07dy5Uzt37tT999+vhx9+2HYCl7HLnB07dujtt99WrVq17NoZv4xVr17dbr+6b98+2zzGLmMXL15Us2bN5OPjoy+++EIHDhzQf/7zHxUpUsTWJ0+OoQGHuOeee4zBgwfbtVWpUsUYNWpUmv1feuklo0qVKnZt//rXv4zGjRvbpnv06GE8+OCDdn3atWtnPPbYY7kUdfqymk9aqlWrZkyYMME2vWTJEiMoKCi3QsySrOazefNmQ5Jx8eLFdNeZlz+f6Ohow2QyGb///rutzZWfTwpJRnR0dIZ93H3buVVm8kmLO207t8pMPu6+7dwqO5+Pu247hmEYsbGxhiRj69at6fbJS9sP8jZP3U+lx9P2X+nxtP1aWjxtX5ceT9sHpic/7Bszk2Na8tJ2Cc9z++8gi8VihIWFGdOmTbO1JSQkGEFBQcbChQtdEKF7u327Z/yyrmjRosa7777L2GXS5cuXjUqVKhkbN240WrRoYQwfPtwwDL57dzJu3Dijdu3aac5j7O7s5ZdfNu6999505+fVMeTKGQdISkrSrl271LZtW7v2tm3b6vvvv09zme3bt6fq365dO+3cuVPXr1/PsE9668wt2cnndhaLRZcvX1axYsXs2q9cuaIyZcqodOnSeuihh1L9tZYj5CSfunXrKjw8XK1bt9bmzZvt5uXlz2fRokVq06aNypQpY9fuis8nq9x528kN7rTt5IQ7bju5wZ23nbi4OElK9d25ladvP3AP+X0/lZ78uv15yn4tLZ66r0tPXtwu88O+MTM53s6Tt0vkTcePH9fZs2fttjM/Pz+1aNHCLbYzd3P7ds/4ZV5ycrJWrlypq1evqkmTJoxdJj3zzDPq2LGj2rRpY9fO+N3Z4cOHVbJkSZUrV06PPfaYjh07Jomxy4x169apQYMG6t69u0JCQlS3bl298847tvl5dQwpzjjAX3/9peTkZIWGhtq1h4aG6uzZs2kuc/bs2TT737hxQ3/99VeGfdJbZ27JTj63+89//qOrV6+qR48etrYqVaooKipK69at04oVK+Tv769mzZrp8OHDuRr/7bKTT3h4uN5++22tWbNGH330kSpXrqzWrVtr27Zttj559fM5c+aMvvjiCz355JN27a76fLLKnbed3OBO2052uPO2k1PuvO0YhqGRI0fq3nvvVY0aNdLt5+nbD9xDft9PpSe/bn95fb+WFk/e16UnL26X+WHfmNkcb+eJ2yXytpRtyR23M3eT1nbP+N3Zvn37VKhQIfn5+Wnw4MGKjo5WtWrVGLtMWLlypXbv3q2pU6emmsf4ZaxRo0Z67733tH79er3zzjs6e/asmjZtqgsXLjB2mXDs2DEtWLBAlSpV0vr16zV48GANGzZM7733nqS8+/3zdnUAnsxkMtlNG4aRqu1O/W9vz+o6c1N233vFihUaP368Pv74Y4WEhNjaGzdurMaNG9ummzVrpnr16mnOnDl68803cy/wdGQln8qVK6ty5cq26SZNmujUqVN6/fXXdd9992Vrnbktu+8dFRWlIkWKqEuXLnbtrv58ssLdt53sctdtJyvywraTXe687QwdOlQ///yzvv322zv29dTtB+4nP++n0pPftj9P2K+lxZP3denJi9tlftg3ZiXHFJ66XcIzuON25m4y2u4Zv/RVrlxZMTExunTpktasWaN+/fpp69attvmMXdpOnTql4cOHa8OGDRk+g4zxS1v79u1tP9esWVNNmjRRhQoVtHTpUts+l7FLn8ViUYMGDTRlyhRJ1qvW9+/frwULFqhv3762fnltDLlyxgFKlCghLy+vVFW52NjYVNW7FGFhYWn29/b2VvHixTPsk946c0t28kmxatUqDRo0SKtXr051uePtzGazGjZs6PC/xspJPrdq3LixXax58fMxDEOLFy9Wnz595Ovrm2FfZ30+WeXO205OuOO2k1vcZdvJCXfedp599lmtW7dOmzdvVunSpTPs66nbD9xLft9PpSe/bX+evF9Liyfs69KTF7fL/LBvzEqOKfLbdom8IywsTJLcbjtzN+lt94zfnfn6+qpixYpq0KCBpk6dqtq1a2v27NmM3R3s2rVLsbGxql+/vry9veXt7a2tW7fqzTfflLe3t22MGL/MKViwoGrWrKnDhw/z3cuE8PBwVatWza6tatWqOnnypKS8+7uP4owD+Pr6qn79+tq4caNd+8aNG9W0adM0l2nSpEmq/hs2bFCDBg3k4+OTYZ/01plbspOPZP0rrP79+2v58uXq2LHjHd/HMAzFxMQoPDw8xzFnJLv53G7Pnj12sea1z0eStm7dqiNHjmjQoEF3fB9nfT5Z5c7bTna567aTW9xl28kJd9x2DMPQ0KFD9dFHH2nTpk0qV67cHZfxxO0H7ie/76fSk5+2P0/fr6XFE/Z16clL22V+2DdmJ0cpf26XyDvKlSunsLAwu+0sKSlJW7duzZO/N3PbnbZ7xi/rDMNQYmIiY3cHrVu31r59+xQTE2N7NWjQQE888YRiYmJUvnx5xi8LEhMTdfDgQYWHh/Pdy4RmzZrp0KFDdm2//fab7fmHeXYMDTjEypUrDR8fH2PRokXGgQMHjBEjRhgFCxY0fv/9d8MwDGPUqFFGnz59bP2PHTtmFChQwHjuueeMAwcOGIsWLTJ8fHyMDz/80Nbnu+++M7y8vIxp06YZBw8eNKZNm2Z4e3sbP/zwg9vls3z5csPb29uYN2+ecebMGdvr0qVLtj7jx483vvzyS+Po0aPGnj17jAEDBhje3t7Gjz/+6Hb5vPHGG0Z0dLTx22+/Gb/88osxatQoQ5KxZs0aW5+89Pmk6N27t9GoUaM01+mqz+fy5cvGnj17jD179hiSjJkzZxp79uwxTpw4kWYu7r7tZDUfd992spqPu287Wc0nhTtuO//+97+NoKAgY8uWLXbfnWvXrtn65LXtB57Dk/ZT6fG0/Vd6PG2/lhZP29elx5P2genJD/vG7OSYF7dLeJ47/Q6aNm2aERQUZHz00UfGvn37jMcff9wIDw834uPjXRy562Vmu2f80hcZGWls27bNOH78uPHzzz8bo0ePNsxms7FhwwbDMBi7rGrRooUxfPhw2zTjl77nn3/e2LJli3Hs2DHjhx9+MB566CGjcOHCtv8TMXYZ++mnnwxvb29j8uTJxuHDh40PPvjAKFCggPH+++/b+uTFMaQ440Dz5s0zypQpY/j6+hr16tUztm7dapvXr18/o0WLFnb9t2zZYtStW9fw9fU1ypYtayxYsCDVOv/73/8alStXNnx8fIwqVarY/afP0bKST4sWLQxJqV79+vWz9RkxYoRx1113Gb6+vkZwcLDRtm1b4/vvv3fLfKZPn25UqFDB8Pf3N4oWLWrce++9xmeffZZqnXnl8zEMw7h06ZIREBBgvP3222muz1Wfz+bNmzP87uS1bSer+bj7tpPVfNx928nO981dt5208pBkLFmyxNYnr20/8Cyesp9Kj6ftv9Ljafu1tHjavi49nrQPTE9+2DdmJ8e8uF3C89zpd5DFYjHGjRtnhIWFGX5+fsZ9991n7Nu3z7VBu4nMbPeMX/oGDhxoOyYNDg42WrdubSvMGAZjl1W3F2cYv/T17NnTCA8PN3x8fIySJUsaXbt2Nfbv32+bz9jd2SeffGLUqFHD8PPzM6pUqZLqmDQvjqHJMP73dEMAAAAAAAAAAAA4HM+cAQAAAAAAAAAAcCKKMwAAAAAAAAAAAE5EcQYAAAAAAAAAAMCJKM4AAAAAAAAAAAA4EcUZAAAAAAAAAAAAJ6I4AwAAAAAAAAAA4EQUZwAAAAAAAAAAAJyI4gwAAAAAAAAAAIATUZwBkG+ULVtWs2bNcnUYAAAgn+JYBAAAz/H777/LZDIpJibG1aHY/Prrr2rcuLH8/f1Vp04dV4cD4A4ozgBwiP79+6tLly6SpJYtW2rEiBFOe++oqCgVKVIkVfuOHTv09NNPOy0OAADgOhyLAADg2fr37y+TyaRp06bZta9du1Ymk8lFUbnWuHHjVLBgQR06dEhff/11mn1Sxu3215EjR3IlhvSOgwCkRnEGQJ6RlJSUo+WDg4NVoECBXIoGAADkNxyLAADgXvz9/TV9+nRdvHjR1aHkmpwcbxw9elT33nuvypQpo+LFi6fb78EHH9SZM2fsXuXKlcv2+zrK9evXXR0C4FAUZwA4VP/+/bV161bNnj3b9tcYv//+uyTpwIED6tChgwoVKqTQ0FD16dNHf/31l23Zli1baujQoRo5cqRKlCihBx54QJI0c+ZM1axZUwULFlRERISGDBmiK1euSJK2bNmiAQMGKC4uzvZ+48ePl5T6ViInT57Uww8/rEKFCikwMFA9evTQuXPnbPPHjx+vOnXqaNmyZSpbtqyCgoL02GOP6fLly44dNAAAkGs4FgEAwHO1adNGYWFhmjp1arp9Uvant5o1a5bKli1rm0654nbKlCkKDQ1VkSJFNGHCBN24cUMvvviiihUrptKlS2vx4sWp1v/rr7+qadOm8vf3V/Xq1bVlyxa7+dk93ridxWLRxIkTVbp0afn5+alOnTr68ssvbfNNJpN27dqliRMn2h1/pMXPz09hYWF2Ly8vL0nSJ598ovr168vf31/ly5e3jUOK7B4HmUwmrV271i6OIkWKKCoqStLN28StXr1aLVu2lL+/v95//31J0pIlS1S1alX5+/urSpUqmj9/vm0dSUlJGjp0qMLDw+Xv76+yZctm+H0A3AnFGQAONXv2bDVp0kRPPfWU7a8xIiIidObMGbVo0UJ16tTRzp079eWXX+rcuXPq0aOH3fJLly6Vt7e3vvvuO7311luSJLPZrDfffFO//PKLli5dqk2bNumll16SJDVt2lSzZs1SYGCg7f1eeOGFVHEZhqEuXbro77//1tatW7Vx40YdPXpUPXv2tOt39OhRrV27Vp9++qk+/fRTbd26NdUl0wAAwH1xLAIAgOfy8vLSlClTNGfOHJ0+fTpH69q0aZP+/PNPbdu2TTNnztT48eP10EMPqWjRovrxxx81ePBgDR48WKdOnbJb7sUXX9Tzzz+vPXv2qGnTpurcubMuXLggSTk63rjd7Nmz9Z///Eevv/66fv75Z7Vr106dO3fW4cOHbe9VvXp1Pf/88+kef9zJ+vXr1bt3bw0bNkwHDhzQW2+9paioKE2ePNnWJzeOgzLy8ssva9iwYTp48KDatWund955R6+88oomT56sgwcPasqUKRozZoyWLl0qSXrzzTe1bt06rV69WocOHdL7779vV3gD3JoBAA7Qr18/4+GHHzYMwzBatGhhDB8+3G7+mDFjjLZt29q1nTp1ypBkHDp0yLZcnTp17vheq1evNooXL26bXrJkiREUFJSqX5kyZYw33njDMAzD2LBhg+Hl5WWcPHnSNn///v2GJOOnn34yDMMwxo0bZxQoUMCIj4+39XnxxReNRo0a3TEmAADgWhyLAADg2W7d1zdu3NgYOHCgYRiGER0dbdx6ynPcuHFG7dq17ZZ94403jDJlytitq0yZMkZycrKtrXLlykbz5s1t0zdu3DAKFixorFixwjAMwzh+/LghyZg2bZqtz/Xr143SpUsb06dPNwwjd483SpYsaUyePNmurWHDhsaQIUNs07Vr1zbGjRuX4Xr69etneHl5GQULFrS9unXrZhiGYTRv3tyYMmWKXf9ly5YZ4eHh6a4vs8dBkozo6Gi7tqCgIGPJkiWGYdwcz1mzZtn1iYiIMJYvX27X9tprrxlNmjQxDMMwnn32WeP+++83LBZLhnkD7sjbZVUhAPnarl27tHnzZhUqVCjVvKNHj+ruu++WJDVo0CDV/M2bN2vKlCk6cOCA4uPjdePGDSUkJOjq1asqWLBgpt7/4MGDioiIUEREhK2tWrVqKlKkiA4ePKiGDRtKst5+pHDhwrY+4eHhio2NzVKuAADA/XAsAgCA55g+fbruv/9+Pf/889leR/Xq1WU237zJUGhoqGrUqGGb9vLyUvHixVPth5s0aWL72dvbWw0aNNDBgwcl5ex441bx8fH6888/1axZM7v2Zs2aae/evZnM8KZWrVppwYIFtumU45ddu3Zpx44ddlfKJCcnKyEhQdeuXVOBAgVy5TgoI7eOxfnz53Xq1CkNGjRITz31lK39xo0bCgoKkmS9Jd0DDzygypUr68EHH9RDDz2ktm3b5jgOwBkozgBwCYvFok6dOmn69Omp5oWHh9t+vn3HfuLECXXo0EGDBw/Wa6+9pmLFiunbb7/VoEGDsvSgOMMwZDKZ7tju4+NjN99kMslisWT6fQAAgHviWAQAAM9x3333qV27dho9erT69+9vN89sNsswDLu2tPbZae1zs7sfTtmXZ/d4407rTZHe8cSdFCxYUBUrVkzVbrFYNGHCBHXt2jXVPH9//xwdB5lMpkx9DreORcpYv/POO2rUqJFdv5Rn5NSrV0/Hjx/XF198oa+++ko9evRQmzZt9OGHH2YYD+AOKM4AcDhfX18lJyfbtdWrV09r1qxR2bJl5e2d+V9FO3fu1I0bN/Sf//zH9hctq1evvuP73a5atWo6efKkTp06ZfuL1QMHDiguLk5Vq1bNdDwAAMD9cSwCAIDnmzZtmurUqWO7GiVFcHCwzp49a1fIiImJybX3/eGHH3TfffdJsl7RsWvXLg0dOlRS9o83bhcYGKiSJUvq22+/tb2XJH3//fe65557cpbALerVq6dDhw6lWbiRcnYcFBwcrDNnztimDx8+rGvXrmUYT2hoqEqVKqVjx47piSeeSLdfYGCgevbsqZ49e6pbt2568MEH9ffff6tYsWIZrh9wNfOduwBAzpQtW1Y//vijfv/9d/3111+yWCx65pln9Pfff+vxxx/XTz/9pGPHjmnDhg0aOHBghiczKlSooBs3bmjOnDk6duyYli1bpoULF6Z6vytXrujrr7/WX3/9lebOvk2bNqpVq5aeeOIJ7d69Wz/99JP69u2rFi1a3PFyYgAAkLdwLAIAgOerWbOmnnjiCc2ZM8euvWXLljp//rxmzJiho0ePat68efriiy9y7X3nzZun6Oho/frrr3rmmWd08eJFDRw4UJKyfbyRlhdffFHTp0/XqlWrdOjQIY0aNUoxMTEaPnx4ruUyduxYvffeexo/frz279+vgwcPatWqVXr11Vcl5ew46P7779fcuXO1e/du7dy5U4MHD051ZVJaxo8fr6lTp2r27Nn67bfftG/fPi1ZskQzZ86UJL3xxhtauXKlfv31V/3222/673//q7CwMBUpUiTXxgVwFIozABzuhRdekJeXl6pVq6bg4GCdPHlSJUuW1Hfffafk5GS1a9dONWrU0PDhwxUUFGR3j9fb1alTRzNnztT06dNVo0YNffDBB5o6dapdn6ZNm2rw4MHq2bOngoODNWPGjFTrMZlMWrt2rYoWLar77rtPbdq0Ufny5bVq1apczx8AALgWxyIAAOQPr732WqpbZ1WtWlXz58/XvHnzVLt2bf3000964YUXcu09p02bpunTp6t27dr65ptv9PHHH6tEiRKSlO3jjbQMGzZMzz//vJ5//nnVrFlTX375pdatW6dKlSrlWi7t2rXTp59+qo0bN6phw4Zq3LixZs6cqTJlykjK2XHQf/7zH0VEROi+++5Tr1699MILL6hAgQJ3jOnJJ5/Uu+++q6ioKNWsWVMtWrRQVFSUypUrJ0kqVKiQpk+frgYNGqhhw4b6/fff9fnnn2d5fAFXMBm3/8YCAAAAAAAAAACAw1BCBAAAAAAAAAAAcCKKMwAAAAAAAAAAAE5EcQYAAAAAAAAAAMCJKM4AAAAAAAAAAAA4EcUZAAAAAAAAAAAAJ6I4AwAAAAAAAAAA4EQUZwAAAAAAAAAAAJyI4gwAAAAAAAAAAIATUZwBAAAAAAAAAABwIoozAAAAAAAAAAAATkRxBgAAAAAAAAAAwIkoziDPioqKkslkkslk0pYtW1LNNwxDFStWlMlkUsuWLXP1vU0mk8aPH5/l5X7//XeZTCZFRUVlql/Ky2w2q3jx4urQoYO2b9+evaAzMGfOHFWsWFG+vr4ymUy6dOlSrr9HfnPs2DENHTpUd999twICAlSgQAFVr15dr776qv744w9Xh+dw48ePl8lkcnUYAAAAAAAAgFuiOIM8r3Dhwlq0aFGq9q1bt+ro0aMqXLiwC6LKHc8++6y2b9+ub775RlOnTtXevXvVqlUr7dmzJ9feIyYmRsOGDVOrVq20adMmbd++PU+PmTv49NNPVatWLX366ad6+umn9emnn9p+/uSTT/TQQw+5OkSHe/LJJx1SSAQAAAAAAAA8gberAwByqmfPnvrggw80b948BQYG2toXLVqkJk2aKD4+3oXR5cxdd92lxo0bS5KaNWumihUrqnXr1po/f77eeeedHK372rVrKlCggPbv3y9Jeuqpp3TPPffkOOZb150fHT9+XI899pjuvvtubd68WUFBQbZ5999/v4YNG6bo6GgXRuhYKZ996dKlVbp0aVeHAwAAAAAAALglrpxBnvf4449LklasWGFri4uL05o1azRw4MA0l/n77781ZMgQlSpVSr6+vipfvrxeeeUVJSYm2vWLj4/XU089peLFi6tQoUJ68MEH9dtvv6W5zsOHD6tXr14KCQmRn5+fqlatqnnz5uVSllYphZoTJ07Y2r766iu1bt1agYGBKlCggJo1a6avv/7abrmUW0zt3r1b3bp1U9GiRVWhQgW1bNlSvXv3liQ1atRIJpNJ/fv3ty23ePFi1a5dW/7+/ipWrJgeeeQRHTx40G7d/fv3V6FChbRv3z61bdtWhQsXVuvWrSVZb/82dOhQLVmyRJUrV1ZAQIAaNGigH374QYZh6P/+7/9Urlw5FSpUSPfff7+OHDlit+6NGzfq4YcfVunSpeXv76+KFSvqX//6l/76668089u/f78ef/xxBQUFKTQ0VAMHDlRcXJxdX4vFojlz5qhOnToKCAhQkSJF1LhxY61bt86u36pVq9SkSRMVLFhQhQoVUrt27TJ1xdLMmTN19epVzZ8/364wk8JkMqlr1652bVkZ519//VXt2rVTwYIFFR4ermnTpkmSfvjhB917770qWLCg7r77bi1dutRu+ZTbAG7cuFEDBgxQsWLFVLBgQXXq1EnHjh3L0bjf/r26dd6tNm3apJYtW6p48eIKCAjQXXfdpUcffVTXrl2z9cnstpny3Vq2bJmqVq2qAgUKqHbt2vr000/T/WwAAAAAAAAAd0FxBnleYGCgunXrpsWLF9vaVqxYIbPZrJ49e6bqn5CQoFatWum9997TyJEj9dlnn6l3796aMWOG3UlzwzDUpUsXLVu2TM8//7yio6PVuHFjtW/fPtU6Dxw4oIYNG+qXX37Rf/7zH3366afq2LGjhg0bpgkTJuRarinFi+DgYEnS+++/r7Zt2yowMFBLly7V6tWrVaxYMbVr1y5VgUaSunbtqooVK+q///2vFi5cqPnz5+vVV1+VJC1ZskTbt2/XmDFjJElTp07VoEGDVL16dX300UeaPXu2fv75ZzVp0kSHDx+2W29SUpI6d+6s+++/Xx9//LFdzp9++qneffddTZs2TStWrNDly5fVsWNHPf/88/ruu+80d+5cvf322zpw4IAeffRRGYZhW/bo0aNq0qSJFixYoA0bNmjs2LH68ccfde+99+r69eup8nv00Ud19913a82aNRo1apSWL1+u5557zq5P//79NXz4cDVs2FCrVq3SypUr1blzZ/3++++2PlOmTNHjjz+uatWqafXq1Vq2bJkuX76s5s2b68CBAxl+Rhs2bFBoaKitkHYnWRnn69evq2vXrurYsaM+/vhjtW/fXpGRkRo9erT69eungQMHKjo6WpUrV1b//v21a9euVO83aNAgmc1mLV++XLNmzdJPP/2kli1b2j1nKKvjfvv3Ki2///67OnbsKF9fXy1evFhffvmlpk2bpoIFCyopKUlS5rfNFJ999pnmzp2riRMnas2aNbbC1u3FJgAAAAAAAMDtGEAetWTJEkOSsWPHDmPz5s2GJOOXX34xDMMwGjZsaPTv398wDMOoXr260aJFC9tyCxcuNCQZq1evtlvf9OnTDUnGhg0bDMMwjC+++MKQZMyePduu3+TJkw1Jxrhx42xt7dq1M0qXLm3ExcXZ9R06dKjh7+9v/P3334ZhGMbx48cNScaSJUsyzC2l3/Tp043r168bCQkJxq5du4yGDRsakozPPvvMuHr1qlGsWDGjU6dOdssmJycbtWvXNu655x5b27hx4wxJxtixYzMcxxQXL140AgICjA4dOtj1PXnypOHn52f06tXL1tavXz9DkrF48eJU65ZkhIWFGVeuXLG1rV271pBk1KlTx7BYLLb2WbNmGZKMn3/+Oc0xsVgsxvXr140TJ04YkoyPP/44VX4zZsywW2bIkCGGv7+/7X22bdtmSDJeeeWVNN8jJUdvb2/j2WeftWu/fPmyERYWZvTo0SPdZQ3DMPz9/Y3GjRtn2CdFdsZ5zZo1trbr168bwcHBhiRj9+7dtvYLFy4YXl5exsiRI21tKZ/zI488Yvde3333nSHJmDRpUpoxZmbc0/pepcxL8eGHHxqSjJiYmHTHI7PbpmFYv1uhoaFGfHy8re3s2bOG2Ww2pk6dmu57AAAAAAAAAO6AK2fgEVq0aKEKFSpo8eLF2rdvn3bs2JHuLc02bdqkggULqlu3bnbtKbfzSrniZPPmzZKkJ554wq5fr1697KYTEhL09ddf65FHHlGBAgV048YN26tDhw5KSEjQDz/8kK28Xn75Zfn4+Mjf31/169fXyZMn9dZbb6lDhw76/vvv9ffff6tfv35272mxWPTggw9qx44dunr1qt36Hn300Uy97/bt2/XPP//Y3eJMkiIiInT//feneVVOeutu1aqVChYsaJuuWrWqJKl9+/Z2t71Kab/1lm2xsbEaPHiwIiIi5O3tLR8fH5UpU0aSUt32S5I6d+5sN12rVi0lJCQoNjZWkvTFF19Ikp555pm0E5e0fv163bhxQ3379rUbV39/f7Vo0UJbtmxJd9msyuo4m0wmdejQwTbt7e2tihUrKjw8XHXr1rW1FytWTCEhIXZjmeL273PTpk1VpkwZ2/ddyvq4Z+Z7VadOHfn6+urpp5/W0qVL07y6JbPbZopWrVqpcOHCtunQ0NB08wYAAAAAAADciberAwByg8lk0oABA/Tmm28qISFBd999t5o3b55m3wsXLigsLCzV8zBCQkLk7e2tCxcu2Pp5e3urePHidv3CwsJSre/GjRuaM2eO5syZk+Z73v6sjswaPny4evfuLbPZrCJFiqhcuXK2uM+dOydJqU5k3+rvv/+2K4yEh4dn6n1TxiCt/iVLltTGjRvt2goUKKDAwMA011WsWDG7aV9f3wzbExISJFmfDdO2bVv9+eefGjNmjGrWrKmCBQvKYrGocePG+ueff1K91+2flZ+fnyTZ+p4/f15eXl6pPsNbpYxrw4YN05xvNmdc077rrrt0/PjxDPukyM44+/v727X5+vqmGsuU9pSxvFVauYeFhdliyc64Z+Z7VaFCBX311VeaMWOGnnnmGV29elXly5fXsGHDNHz4cEmZ3zZT3P55S9bPPK0YAQAAAAAAAHdCcQYeo3///ho7dqwWLlyoyZMnp9uvePHi+vHHH2UYht1J4NjYWN24cUMlSpSw9btx44YuXLhgdxL47NmzdusrWrSovLy81KdPn3SvyChXrly2cipdurQaNGiQ5ryUOOfMmZPu801CQ0Ptpm8/6Z2elHzPnDmTat6ff/5pe++srjcrfvnlF+3du1dRUVHq16+frT3luTvZERwcrOTkZJ09ezbdgkJKbh9++KHtapGsaNeunebMmaMffvjhjs+dyeo454bbv78pbRUrVpSUvXHP7OffvHlzNW/eXMnJydq5c6fmzJmjESNGKDQ0VI899limt00AAAAAAAAgr+O2ZvAYpUqV0osvvqhOnTrZnVS+XevWrXXlyhWtXbvWrv29996zzZest0ySpA8++MCu3/Lly+2mCxQooFatWmnPnj2qVauWGjRokOqV1l/451SzZs1UpEgRHThwIM33bNCgge1qlKxq0qSJAgIC9P7779u1nz59Wps2bbKNkSOlnJxPufolxVtvvZXtdbZv316StGDBgnT7tGvXTt7e3jp69Gi645qR5557TgULFtSQIUMUFxeXar5hGIqOjpbkmnG+/fv8/fff68SJE2rZsqUkx4z77by8vNSoUSPNmzdPkrR7925Jmd82AQAAAAAAgLyOK2fgUaZNm3bHPn379tW8efPUr18//f7776pZs6a+/fZbTZkyRR06dFCbNm0kSW3bttV9992nl156SVevXlWDBg303XffadmyZanWOXv2bN17771q3ry5/v3vf6ts2bK6fPmyjhw5ok8++USbNm3K9VwLFSqkOXPmqF+/fvr777/VrVs3hYSE6Pz589q7d6/Onz+fYREiI0WKFNGYMWM0evRo9e3bV48//rguXLigCRMmyN/fX+PGjcvlbFKrUqWKKlSooFGjRskwDBUrVkyffPJJqlt9ZUXz5s3Vp08fTZo0SefOndNDDz0kPz8/7dmzRwUKFNCzzz6rsmXLauLEiXrllVd07NgxPfjggypatKjOnTunn376SQULFtSECRPSfY9y5cpp5cqV6tmzp+rUqaOhQ4fangdz4MABLV68WIZh6JFHHnHJOO/cuVNPPvmkunfvrlOnTumVV15RqVKlNGTIEEmOGXdJWrhwoTZt2qSOHTvqrrvuUkJCghYvXixJtm0us9smAAAAAAAAkNdRnEG+4+/vr82bN+uVV17R//3f/+n8+fMqVaqUXnjhBbuT4WazWevWrdPIkSM1Y8YMJSUlqVmzZvr8889VpUoVu3VWq1ZNu3fv1muvvaZXX31VsbGxKlKkiCpVqmT3APfc1rt3b911112aMWOG/vWvf+ny5csKCQlRnTp1Uj1kPqsiIyMVEhKiN998U6tWrVJAQIBatmypKVOmqFKlSrmTQAZ8fHz0ySefaPjw4frXv/4lb29vtWnTRl999ZXuuuuubK83KipK9erV06JFixQVFaWAgABVq1ZNo0ePtvWJjIxUtWrVNHv2bK1YsUKJiYkKCwtTw4YNNXjw4Du+x0MPPaR9+/bpP//5jxYuXKhTp07JbDarXLlyevDBB/Xss8/avZczx3nRokVatmyZHnvsMSUmJqpVq1aaPXu27bk1jhr3OnXqaMOGDRo3bpzOnj2rQoUKqUaNGlq3bp3atm0rKfPbJgAAAAAAAJDXmQzDMFwdBADAsaKiojRgwADt2LHjjrdmAwAAAAAAAOBYPHMGAAAAAAAAAADAiSjOAAAAAAAAAAAAOBG3NQMAAAAAAAAAAHAirpwBAADIoW3btqlTp04qWbKkTCaT1q5de8dltm7dqvr168vf31/ly5fXwoULHR8oAAAAAABwCxRnAAAAcujq1auqXbu25s6dm6n+x48fV4cOHdS8eXPt2bNHo0eP1rBhw7RmzRoHRwoAAAAAANwBtzXLJovFoj///FOFCxeWyWRydTgAALgFwzB0+fJllSxZUmZz/vwbEJPJpOjoaHXp0iXdPi+//LLWrVungwcP2toGDx6svXv3avv27Wkuk5iYqMTERNu0xWLR33//reLFi3MsAgDA/3AsAgAA8gpvVweQV/3555+KiIhwdRgAALilU6dOqXTp0q4Ow21t375dbdu2tWtr166dFi1apOvXr8vHxyfVMlOnTtWECROcFSIAAHkaxyIAAMDdUZzJpsKFC0uyHvAFBga6OJq8x2Kx6Pz58woODuavmZBjfJ+Qm/g+5Ux8fLwiIiJs+0mk7ezZswoNDbVrCw0N1Y0bN/TXX38pPDw81TKRkZEaOXKkbTouLk533XUXxyIAANyCYxEAAJBXUJzJppTbhwQGBnJCJBssFosSEhIUGBjIyU/kGN8n5Ca+T7mD22zd2e1jlHKn2fTGzs/PT35+fqnaORYBACA1jkUAAIC746wTACBPmjt3rho0aCA/P79Uz/bIaN6d1vXII4+kmn/06FG1b99eRYsWValSpTRjxgy7+bNmzVJISIgqVqyobdu22dovXbqk6tWr6/z589nKEZ4rLCxMZ8+etWuLjY2Vt7e3ihcv7qKoAAAAAACAs1CcAQDkSSVLltSrr76qp556Kkvzsrqu5ORkde7cWfXq1VNsbKw2bdqkuXPnavny5ZKst6eaNGmS9u7dq1mzZumZZ56xLfvyyy/rhRdeUHBwcDazhKdq0qSJNm7caNe2YcMGNWjQIM3nzQAAAAAAAM9CcQYAkCd17dpVXbp0UYkSJbI0L6vrOnTokA4dOqRx48bJx8dHlStX1qBBg/T2229Lkk6cOKFKlSopPDxcbdq00dGjRyVJ3333nY4cOaIBAwbkIEvkFVeuXFFMTIxiYmIkScePH1dMTIxOnjwpyfq8mL59+9r6Dx48WCdOnNDIkSN18OBBLV68WIsWLdILL7zgivABAAAAAICT8cwZAAAyYLFYJN18HkhK288//yxJqlSpko4fP67Tp09rz549qlmzpq5fv65hw4ZpxYoVLokZzrdz5061atXKNj1y5EhJUr9+/RQVFaUzZ87YCjWSVK5cOX3++ed67rnnNG/ePJUsWVJvvvmmHn30UafHDgAAAAAAnI/iDAAAGahcubLKlSunsWPHauLEiTpy5IgWL16s+Ph4SVKxYsU0Z84cdenSRYGBgXr33Xc1ffp0denSRdevX1f79u31zz//aPjw4Wk+zwaeoWXLlnYFvNtFRUWlamvRooV2797twKgAAAAAAIC7ojgDAEAGfHx8tG7dOo0YMUKlS5dWqVKlNGDAAL311lu2Pt27d1f37t0lSYcPH1Z0dLS2b9+u++67TzNmzFDNmjVVq1YttWzZUkWLFnVVKgAAAAAAAHATPHMGAIA7qFq1qtavX6/z588rJiZGiYmJatGiRZp9hwwZotmzZ8vX11d79+5Vo0aNVLRoUZUuXVqHDx92cuQAAAAAAABwR1w5AwDIk27cuGF7WSwWJSQkyGw2y9fXN8N5mV1XUlKS/P39JUk///yzKlSoIB8fH3366adavHixvv7661TrWbp0qcqXL697771XklS+fHlt3LhR9erV02+//aYyZco4bkAAAAAAAACQZ1CcAQDkSZMmTdKECRNs0wEBAWrRooW2bNmS4TxJGjx4sCRp4cKFaa7r008/teu/evVqzZ8/X4mJiapdu7bWrl2rWrVq2cVz4cIFvf766/rmm29sbfPmzdPAgQN15coVjR8/XqGhobk6BgAAAAAAAMibTEZGT69FuuLj4xUUFKS4uDgFBga6Opw8x2KxKDY2ViEhITKbubsecobvE3IT36ecYf/oPIw1AACpsX8EAAB5BWedAAAAAAAAAAAAnIjiDAAAAAAAAAAAgBNRnAEAAAAAAAAAAHAiijMAAAAAAAAAAABORHEGAAAAAAAAAADAibxdHQAAII8wmVwdgXOYzVL9+tKuXZLF4upoHM8wXB0BAAAAAABAvsOVMwAAAAAAAAAAAE5EcQYAAAAAAAAAAMCJKM4AAAAAAAAAAAA4EcUZAAAAAAAAAAAAJ6I4AwAAAAAAAAAA4EQUZwAAAAAAAAAAAJyI4gwAAAAAAAAAAIATUZwBAAAAAAAAAABwIoozAAAAAAAAAAAATkRxBgAAAAAAAAAAwIkozgAAAAAAAAAAADgRxRkAAAAAAAAAAAAnojgDAAAAAAAAAADgRBRnAAAAAAAAAAAAnIjiDAAAAAAAAAAAgBNRnAEAAAAAAAAAAHAiijMAAAAAAAAAAABORHEGAAAAAAAAAADAiSjOAAAAAAAAAAAAOBHFGQAAAAAAAAAAACeiOAMAAAAAAAAAAOBEFGcAAAAAAAAAAACciOIMAJc6evSo2rdvr6JFi6pUqVKaMWNGtvv+8ccf6tKli4oXL64SJUqoe/fuOnfunG3+rFmzFBISoooVK2rbtm229kuXLql69eo6f/587icIAAAAAAAAALehOAPAZZKTk9W5c2fVq1dPsbGx2rRpk+bOnavly5dnq+8zzzwjSTpx4oSOHz+uxMREDR8+XJJ09uxZTZo0SXv37tWsWbNsfSXp5Zdf1gsvvKDg4GAHZwwAAAAAAAAAFGcAuNChQ4d06NAhjRs3Tj4+PqpcubIGDRqkt99+O1t9f//9d/Xo0UOFChVS4cKF1bNnT/3yyy+SrAWbSpUqKTw8XG3atNHRo0clSd99952OHDmiAQMGOCdpAAAAAAAAAPkexRkALmOxWCRJhmHYtf3888/Z6jtixAj997//VVxcnC5duqQVK1aoY8eOkqRKlSrp+PHjOn36tDZu3KiaNWvq+vXrGjZsmBYsWOCQ/AAAAAAAAAAgLRRnALhM5cqVVa5cOY0dO1aJiYnav3+/Fi9erPj4+Gz1bdasmWJjY1W0aFEVK1ZMf//9t1599VVJUrFixTRnzhx16dJFb7zxht59911Nnz5dXbp00fXr19W+fXu1bNlS0dHRTssfAAAAAAAAQP5EcQaAy/j4+GjdunWKiYlR6dKl9cQTT2jAgAEqXrx4lvtaLBa1a9dOzZo105UrV3TlyhXde++9ateunW0d3bt3186dO7Vp0yb5+/srOjpaL7/8sgYNGqTIyEhFR0dr2LBhunjxotPGAAAAAAAAAED+Q3EGgEtVrVpV69ev1/nz5xUTE6PExES1aNEiy30vXryoEydOaNiwYSpQoIAKFCigZ599Vtu3b9dff/2Val1DhgzR7Nmz5evrq71796pRo0YqWrSoSpcurcOHDzs0ZwAAAAAAAAD5G8UZAC71888/6+rVq0pKStJHH32kxYsX225FlpW+xYsXV8WKFTVv3jwlJCQoISFB8+bNU+nSpVWiRAm79SxdulTly5fXvffeK0kqX768Nm7cqD///FO//fabypQp49ikAQAAAAAAAORr3q4OAED+tnr1as2fP1+JiYmqXbu21q5dq1q1akmSBg8eLElauHBhhn0tFoskKTo6Ws8//7xKlSoli8WiunXrat26dXbvd+HCBb3++uv65ptvbG3z5s3TwIEDdeXKFY0fP16hoaHOSB0AAAAAAABAPmUyDMNwdRB5UXx8vIKCghQXF6fAwEBXh5PnWCwWxcbGKiQkRGYzF3AhZ/g+OYnJ5OoInMJiNiu2fn2F7Nol8/8Kfx4tlw8D2D86D2MNAEBq7B8BAEBe4ZFnMbdt26ZOnTqpZMmSMplMWrt2rd18wzA0fvx4lSxZUgEBAWrZsqX279/vmmABAAAAAAAAAEC+4pHFmatXr6p27dqaO3dumvNnzJihmTNnau7cudqxY4fCwsL0wAMP6PLly06OFAAAAAAAAAAA5Dce+cyZ9u3bq3379mnOMwxDs2bN0iuvvKKuXbtKsj4cPDQ0VMuXL9e//vWvNJdLTExUYmKibTo+Pl6S9XZKlvxw25tcZrFYZBgGY4dcwffJSfLJLeMsZrMMk0mWfJKvcnm7YTsEAAAAAAC4M48szmTk+PHjOnv2rNq2bWtr8/PzU4sWLfT999+nW5yZOnWqJkyYkKr9/PnzSkhIcFi8nspisSguLk6GYfCMEOQY3ycnqV/f1RE4hcVkUlzFijIkmfPDY9liY3N1dVyFCgAAAAAAcGf5rjhz9uxZSVJoaKhde2hoqE6cOJHucpGRkRo5cqRtOj4+XhEREQoODuYhg9lgsVhkMpkUHBzMyXRH8vFxdQROYTGbZapXT8G7d+ePB7hfv+6a9921yzXv62QWs1kmKf98n0JCcnV1/v7+ubo+AAAAAAAAT5TvijMpTCaT3bRhGKnabuXn5yc/P79U7WazmeJCNplMJsbP0fLDieX/MRmGzBZL/jiZ7qptJj+M7f/wfcrJ6vidDgAAAAAAcCf57gxKWFiYpJtX0KSIjY1NdTUNAAAAAAAAAABAbst3xZly5copLCxMGzdutLUlJSVp69atatq0qQsjAwAAAAAAAAAA+YFHFmeuXLmimJgYxcTESJKOHz+umJgYnTx5UiaTSSNGjNCUKVMUHR2tX375Rf3791eBAgXUq1cv1waeRxw9elTt27dX0aJFVapUKc2YMSPdvs8++6wiIiIUGBioUqVKacSIEUpKSrLNDwwMVKFChWwvHx8f1apVyzZ/1qxZCgkJUcWKFbVt2zZb+6VLl1S9enWdP3/eMUkCAAAAAAAAAOAgHlmc2blzp+rWrau6detKkkaOHKm6detq7NixkqSXXnpJI0aM0JAhQ9SgQQP98ccf2rBhgwoXLuzKsPOE5ORkde7cWfXq1VNsbKw2bdqkuXPnavny5Wn2HzJkiH799VfFx8crJiZGe/futSvmxMfH68qVK7ZX1apV9dhjj0my3npu0qRJ2rt3r2bNmqVnnnnGttzLL7+sF154QcHBwY5NGAAAAAAAAACAXOaRxZmWLVvKMIxUr6ioKEnWB9GPHz9eZ86cUUJCgrZu3aoaNWq4Nug84tChQzp06JDGjRsnHx8fVa5cWYMGDdLbb7+dZv+qVauqYMGCtmmz2azDhw+n2fenn37SgQMH1L9/f0nSiRMnVKlSJYWHh6tNmzY6evSoJOm7777TkSNHNGDAgNxNDgAAAAAAAAAAJ/DI4gwcx2KxSJIMw7Br+/nnn9NdZtq0aSpcuLBCQkK0d+9ePfvss2n2W7Rokdq3b6+SJUtKkipVqqTjx4/r9OnT2rhxo2rWrKnr169r2LBhWrBgQS5mBQAAAAAAAACA81CcQZZUrlxZ5cqV09ixY5WYmKj9+/dr8eLFio+PT3eZUaNG6fLlyzpw4IAGDx6ssLCwVH2uXbumlStX6sknn7S1FStWTHPmzFGXLl30xhtv6N1339X06dPVpUsXXb9+Xe3bt1fLli0VHR3tkFwBAAAAAAAAAHAEijPIEh8fH61bt04xMTEqXbq0nnjiCQ0YMEDFixe/47JVq1ZV7dq1bbctu9Xq1atVoEABdezY0a69e/fu2rlzpzZt2iR/f39FR0fr5Zdf1qBBgxQZGano6GgNGzZMFy9ezK0UAQAAAAAAAABwKIozyLKqVatq/fr1On/+vGJiYpSYmKgWLVpkatnr16+n+cyZd999V/369ZO3t3e6yw4ZMkSzZ8+Wr6+v9u7dq0aNGqlo0aIqXbp0us+xAQAAAAAAAADA3VCcQZb9/PPPunr1qpKSkvTRRx9p8eLFevXVV1P1u3LlipYsWaJLly7JMAzt27dPkyZNUrt27ez6HTp0SN9//70GDhyY7nsuXbpU5cuX17333itJKl++vDZu3Kg///xTv/32m8qUKZO7SQIAAAAAAAAA4CDpX6YApGP16tWaP3++EhMTVbt2ba1du1a1atWSJA0ePFiStHDhQplMJi1fvlwvvPCCEhMTFRISokcffVQTJkywW9+iRYvUvHlz3X333Wm+34ULF/T666/rm2++sbXNmzdPAwcO1JUrVzR+/HiFhoY6KFsAAAAAAAAAAHKXyTAMw9VB5EXx8fEKCgpSXFycAgMDXR1OnmOxWBQbG6uQkBCZzVzA5TAmk6sjcAqL2azY+vUVsmuXzBaLq8NxPFf92ub75Jly+fvE/tF5GGsAAFJj/wgAAPIKzooDAADkgvnz56tcuXLy9/dX/fr17a74TMsHH3yg2rVrq0CBAgoPD9eAAQN04cIFJ0ULAAAAAABcieIMAABADq1atUojRozQK6+8oj179qh58+Zq3769Tp48mWb/b7/9Vn379tWgQYO0f/9+/fe//9WOHTv05JNPOjlyAAAAAADgChRnAAAAcmjmzJkaNGiQnnzySVWtWlWzZs1SRESEFixYkGb/H374QWXLltWwYcNUrlw53XvvvfrXv/6lnTt3OjlyAAAAAADgChRnAAAAciApKUm7du1S27Zt7drbtm2r77//Ps1lmjZtqtOnT+vzzz+XYRg6d+6cPvzwQ3Xs2DHd90lMTFR8fLzdCwAAAAAA5E0UZwAAAHLgr7/+UnJyskJDQ+3aQ0NDdfbs2TSXadq0qT744AP17NlTvr6+CgsLU5EiRTRnzpx032fq1KkKCgqyvSIiInI1DwAAAAAA4DwUZ9yMyZQ/Xj4+UufO1n9dHYszXgAAz2e67Re+YRip2lIcOHBAw4YN09ixY7Vr1y59+eWXOn78uAYPHpzu+iMjIxUXF2d7nTp1KlfjBwAAAAAAzuPt6gAAAADyshIlSsjLyyvVVTKxsbGprqZJMXXqVDVr1kwvvviiJKlWrVoqWLCgmjdvrkmTJik8PDzVMn5+fvLz88v9BAAAAAAAgNNx5QwAAEAO+Pr6qn79+tq4caNd+8aNG9W0adM0l7l27ZrMZvvDMC8vL0nWK24AAAAAAIBnozgDAACQQyNHjtS7776rxYsX6+DBg3ruued08uRJNBVL/gAAP6pJREFU223KIiMj1bdvX1v/Tp066aOPPtKCBQt07Ngxfffddxo2bJjuuecelSxZ0lVpAAAAAAAAJ+G2ZgAAADnUs2dPXbhwQRMnTtSZM2dUo0YNff755ypTpowk6cyZMzp58qStf//+/XX58mXNnTtXzz//vIoUKaL7779f06dPd1UKAAAAAADAiUwG987Ilvj4eAUFBSkuLk6BgYG5tt788vB4s9mi+vVjtWtXiCwWz7+Ay2VbWT75QlnMZsXWr6+QXbtktlhcHY7jueoLxffJM+Xy98lR+0ekxlgDAJAa+0cAAJBXeP5ZcQAAAAAAAAAAADdCcQYAAAAAAAAAAMCJKM4AAAAAAAAAAAA4EcUZAAAAAAAAAAAAJ6I4AwAAAAAAAAAA4EQUZwAAAAAAAAAAAJyI4gwAAAAAAAAAAIATUZwBAAAAAAAAAABwIoozAAAAAAAAAAAATkRxBgAAAAAAAAAAwIkozgAAAAAAAAAAADgRxRkAAAAAAAAAAAAnojgDAAAAAAAAAADgRBRnAAAAAAAAAAAAnIjiDAAAAAAAAAAAgBNRnAEAAAAAAAAAAHAiijMAAAAAAAAAAABORHEGAAAAAAAAAADAiSjOAAAAAAAAAAAAOBHFGQAAAAAAAAAAACeiOAMAAAAAAAAAAOBEFGcAAAAAAAAAAACciOIMAAAAAAAAAACAE1GcAQAAAAAAAAAAcCKKMwAAAAAAAAAAAE5EcQYAAAAAAAAAAMCJKM4AAAAAAAAAAAA4EcUZAAAAAAAAAAAAJ6I4AwAAAAAAAAAA4EQUZwAAAAAAAAAAAJyI4gwAAAAAAAAAAIATUZwBAAAAAAAAAABwonxbnLlx44ZeffVVlStXTgEBASpfvrwmTpwoi8Xi6tAAAAAAAAAAAIAH83Z1AK4yffp0LVy4UEuXLlX16tW1c+dODRgwQEFBQRo+fLirwwMAAAAAAAAAAB4q3xZntm/frocfflgdO3aUJJUtW1YrVqzQzp07XRwZAAAAAAAAAADwZPm2OHPvvfdq4cKF+u2333T33Xdr7969+vbbbzVr1qw0+ycmJioxMdE2HR8fL0myWCy5eis0cz650ZzZbJHJZMhszh+3kXPZ3fLyyRfKYjbLMJlkySf5uuwLlU/Gl+9TTleXP36vAwAAAAAA5ES+Lc68/PLLiouLU5UqVeTl5aXk5GRNnjxZjz/+eJr9p06dqgkTJqRqP3/+vBISEnItrvr1c21Vbs1ksuj/27vzcCvLQm/837UZNmqBooCgiJRDKuWwKQMPlRMkDtnRxIHIqSRJBXICz8mkFDUjSgVnrY4iZg5YhPLmK+LQCRnKRM0hQxRESQFRt8Bavz962b8ILIHNWnv4fK5r/7EenvWs77qv272Wz3ffz7PTTkuSlFIqNf0ToIsWVeiFm8mEKhYKWbLTTiklqSqVKh1n06vUhDKfmqZ6nk/Lli2r1+MBAAAANEXNtpyZOHFi/ud//ie33XZb9thjj8yZMydDhw5Nly5d8rWvfW2t/UeMGJHhw4fXPV66dGm6du2aDh06pG3btvWWa+bMejtUg/b3FTOFzJrVIcVi0y9nOnas0As3kwlVrKpKIUmHWbNS1Rz+ar9SE8p8aprqeT61adOmXo8HAAAA0BQ123LmnHPOyfnnn59jjz02SfLJT34yf/3rXzN69Oh1ljPV1dWprq5ea3tVVVWq6vHSN83hPOBqpVIhxWJVsyhnKnZ1pGY0oQqlUqqKxeZxMr1SE6o5jO3/Yz5tzOGa/u90AAAAgI3VbM+gvPPOO2udQGrRooVr5QMAAAAAAJtUs105c/jhh+fiiy/ODjvskD322COzZ8/OmDFjcvLJJ1c6GgAAAAAA0IQ123LmyiuvzH//93/n9NNPz6JFi9KlS5ecdtpp+c53vlPpaAAAAAAAQBPWbMuZj370oxk7dmzGjh1b6SgAAAAAAEAz0mzvOQMAAAAAAFAJyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAKAejBs3Lt27d0+bNm1SU1OT6dOn/8v9a2trc8EFF6Rbt26prq7Oxz/+8dx0001lSgsAAABUUstKBwAAaOwmTpyYoUOHZty4cdlvv/1y7bXX5pBDDsncuXOzww47rPM5xxxzTF577bXceOON2WmnnbJo0aKsXLmyzMkBAACASlDOAABspDFjxuSUU07JqaeemiQZO3Zs7r///owfPz6jR49ea/8pU6Zk2rRpefHFF9O+ffskyY477vgvX6O2tja1tbV1j5cuXVp/bwAAAAAoK5c1AwDYCO+//35mzpyZvn37rrG9b9++eeyxx9b5nEmTJqVnz565/PLLs91222WXXXbJ2WefnXffffcDX2f06NFp165d3U/Xrl3r9X0AAAAA5WPlDADARnjjjTeyatWqdOrUaY3tnTp1ysKFC9f5nBdffDGPPPJI2rRpk7vvvjtvvPFGTj/99Pztb3/7wPvOjBgxIsOHD697vHTpUgUNAAAANFLKGQCAelAoFNZ4XCqV1tq2WrFYTKFQyK233pp27dol+ful0Y4++uhcffXV2WyzzdZ6TnV1daqrq+s/OAAAAFB2LmsGALARttlmm7Ro0WKtVTKLFi1aazXNap07d852221XV8wkyW677ZZSqZT58+dv0rwAAABA5SlnAAA2QuvWrVNTU5OpU6eusX3q1Knp3bv3Op+z33775dVXX83bb79dt+3Pf/5zqqqqsv3222/SvAAAAEDlKWcAADbS8OHDc8MNN+Smm27K008/nWHDhmXevHkZPHhwkr/fL2bQoEF1+x9//PHZeuutc9JJJ2Xu3Ll5+OGHc8455+Tkk09e5yXNAAAAgKalwdxz5tlnn82ECRMyffr0vPTSS3nnnXfSoUOH7L333unXr1+OOuoo11kHABqkAQMGZPHixRk1alQWLFiQHj16ZPLkyenWrVuSZMGCBZk3b17d/h/5yEcyderUnHHGGenZs2e23nrrHHPMMfn+979fqbcAAAAAlFGhVCqVKhlg9uzZOffcczN9+vT07t07n/nMZ7Lddttls802y9/+9rf86U9/yvTp07N06dKce+65GTp0aIMoaZYuXZp27dplyZIladu2bb0d9wPuG9zkVFUVU1OzKDNndkyx2PQXcFXsv7JmMqGKVVVZVFOTjjNnpqpYrHScTa9SE8p8aprqeT5tqs9H1masAWBtPh8BgMai4itnjjzyyJxzzjmZOHFi2rdv/4H7Pf744/nRj36UH/7whxk5cmQZEwIAAAAAANSfipczzz33XFq3bv1v9+vVq1d69eqV999/vwypAAAAAAAANo2KX0/qwxQzG7M/AAAAAABAQ1LxcmZdFixYkKOPPjodOnRI+/btc/jhh+fFF1+sdCwAAAAAAICN1iDLmZNPPjk9evTItGnT8uCDD6ZTp045/vjjKx0LAAAAAABgozWIcuass87K8uXL6x4///zzOe+887L77rtnr732yllnnZVnn322ggkBAAAAAADqR8tKB0iS7bbbLjU1Nbn88stzxBFHZMCAAdl3333Tv3//rFixInfddVdOOOGESscEAAAAAADYaA2inDn33HPzla98JaeffnpuueWW/OQnP8m+++6bhx56KKtWrcrll1+eo48+utIxAQAAAAAANlqDKGeSpHv37vnNb36T//mf/8kXvvCFnHXWWbniiitSKBQqHQ0AAAAAAKDeNIh7zqy2ePHiDBw4MDNmzMisWbPSq1ev/PGPf6x0LAAAAAAAgHrTIMqZ//t//2+23XbbdOjQIdtvv32eeeaZ3Hzzzbnkkkty7LHH5txzz827775b6ZgAAAAAAAAbrUGUM6effnrOOeecvPPOO7nqqqsydOjQJMkBBxyQ2bNnp2XLltlrr70qmhEAAAAAAKA+NIhy5tVXX82hhx6aNm3a5Itf/GJef/31un+rrq7OJZdckrvuuquCCQEAAAAAAOpHy0oHSJIjjjgiRx99dI444og88sgj6d+//1r77LHHHhVIBgAAAAAAUL8axMqZG2+8MaeddlqWLFmSgQMHZuzYsZWOBAAAAAAAsEk0iJUzrVu3zhlnnFHpGAAAAAAAAJtcxVfOPP744x963+XLl+epp57ahGkAAAAAAAA2rYqXM4MGDcrBBx+cO+64I2+//fY695k7d25GjhyZnXbaKbNmzSpzQgAAAAAAgPpT8cuazZ07N9dee22+853v5IQTTsguu+ySLl26pE2bNnnzzTfzzDPPZPny5fnP//zPTJ06NT169Kh0ZAAAAAAAgA1W8XKmVatW+da3vpVvfetbmTVrVqZPn56XXnop7777bvbcc88MGzYs+++/f9q3b1/pqAAAAAAAABut4uXMP9pnn32yzz77VDoGAAAAAADAJlPxe85U0iuvvJKBAwdm6623zuabb5699torM2fOrHQsAAAAAACgCWtQK2fK6c0338x+++2X/fffP7/5zW/SsWPHvPDCC9lyyy0rHQ0AAAAAAGjCmm05c9lll6Vr1665+eab67btuOOOlQsEAAAAAAA0C822nJk0aVL69euXr3zlK5k2bVq22267nH766fn617++zv1ra2tTW1tb93jp0qVJkmKxmGKxWG+5qprJheaqqoopFEqpqqq/sWvI6nGKrJ9mMqGKVVUpFQopNpP3W7EJ1UzG13za2MM1j9/rAAAAABuj2ZYzL774YsaPH5/hw4dn5MiR+f3vf58zzzwz1dXVGTRo0Fr7jx49OhdddNFa219//fW899579ZarpqbeDtWgFQrF7LTTkiSllEpN/wTookUVeuFmMqGKhUKW7LRTSkmqSqVKx9n0KjWhzKemqZ7n07Jly+r1eAAAAABNUaFUqvyZp/79+2fChAlp165dkuTiiy/OkCFD6u7/snjx4vTp0ydz586tt9ds3bp1evbsmccee6xu25lnnpkZM2bk8ccfX2v/da2c6dq1a9588820bdu23nK1alVvh2rQqqqK2Wef1zNrVocUi02/nFmxokIv3EwmVLGqKq/vs086zJqVqubwV/uVmlDmU9NUz/Np6dKl2WqrrbJkyZJ6/XxkbUuXLk27du2MNQD8A5+PAEBj0SBWztx///1rFB+XXXZZjjvuuLpyZuXKlXn22Wfr9TU7d+6c3XfffY1tu+22W375y1+uc//q6upUV1evtb2qqipV9Xjpm+ZwHnC1UqmQYrGqWZQzFbs6UjOaUIVSKVXFYvM4mV6pCdUcxvb/MZ825nBN/3c6AAAAwMZqEGdQ/nnxTjkW8+y3335rFT5//vOf061bt03+2gAAAAAAQPPVIMqZShg2bFh+97vf5ZJLLsnzzz+f2267Ldddd12GDBlS6WgAAAAAAEAT1iDKmUKhkEKhsNa2TenTn/507r777kyYMCE9evTI9773vYwdOzYnnHDCJn1dAAAAAACgeWsQ95wplUo58cQT6+7p8t5772Xw4MHZYostkmSN+9HUp8MOOyyHHXbYJjk2AAAAAADAujSIcuZrX/vaGo8HDhy41j6DBg0qVxwAAAAAAIBNpkGUMzfffHOlIwAAAAAAAJRFgyhnkuSvf/1rHnjggaxYsSJf+MIXsvvuu1c6EgAAAAAAQL1rEOXMww8/nP79++edd95JkrRs2TI//elPc9xxx1U4GQAAAAAAQP2qqnSAJPnv//7v7L///pk/f34WL16ck08+Oeeee26lYwEAAAAAANS7BlHOPPnkkxk9enS6dOmSrbbaKj/84Q/z6quv5s0336x0NAAAAAAAgHrVIMqZt956Kx07dqx7vMUWW2TzzTfPW2+9VblQAAAAAAAAm0CDuOdMksydOzcLFy6se1wqlfL0009n2bJldds+9alPVSIaAAAAAABAvWkw5cyBBx6YUqm0xrbDDjsshUIhpVIphUIhq1atqlA6AAAAAACA+tEgypm//OUvlY4AAAAAAABQFg2inOnWrdu/3WfOnDkfaj8AAAAAAICGrKrSAf6VJUuWZNy4cdlnn31SU1NT6TgAAAAAAAAbrUGWMw8++GAGDhyYzp0758orr0z//v3zxBNPVDoWAAAAAADARmsQlzVLkvnz5+eWW27JTTfdlOXLl+eYY47JihUr8stf/jK77757peMBAAAAAADUiwaxcqZ///7ZfffdM3fu3Fx55ZV59dVXc+WVV1Y6FgAAAAAAQL1rECtnHnjggZx55pn55je/mZ133rnScQAAAAAAADaZBrFyZvr06Vm2bFl69uyZfffdN1dddVVef/31SscCAAAAAACodw2inOnVq1euv/76LFiwIKeddlpuv/32bLfddikWi5k6dWqWLVtW6YgAAAAAAAD1okGUM6ttvvnmOfnkk/PII4/kySefzLe//e1ceuml6dixY4444ohKxwMAAAAAANhoDaqc+Ue77rprLr/88syfPz8TJkyodBwAAAAAAIB60WDLmdVatGiRI488MpMmTap0FAAAAAAAgI3WstIBkuTkk0/+t/sUCoXceOONZUgDAAAAAACw6TSIcuaWW25Jt27dsvfee6dUKlU6DgAAAAAAwCbTIMqZwYMH5/bbb8+LL76Yk08+OQMHDkz79u0rHQsAAAAAAKDeNYh7zowbNy4LFizIeeedl/vuuy9du3bNMccck/vvv99KGgAAAAAAoElpEOVMklRXV+e4447L1KlTM3fu3Oyxxx45/fTT061bt7z99tuVjgcAAAAAAFAvGkw5848KhUIKhUJKpVKKxWKl4wAAAAAAANSbBlPO1NbWZsKECTn44IOz66675sknn8xVV12VefPm5SMf+Uil4wEAAAAAANSLlpUOkCSnn356br/99uywww456aSTcvvtt2frrbeudCwAAAAAAIB61yDKmWuuuSY77LBDunfvnmnTpmXatGnr3O+uu+4qczIAgA9n3Lhx+cEPfpAFCxZkjz32yNixY9OnT59/+7xHH300n//859OjR4/MmTNn0wcFAAAAKq5BlDODBg1KoVCodAwAgA0yceLEDB06NOPGjct+++2Xa6+9Noccckjmzp2bHXbY4QOft2TJkgwaNCgHHnhgXnvttTImBgAAACqpQZQzt9xyS6UjAABssDFjxuSUU07JqaeemiQZO3Zs7r///owfPz6jR4/+wOeddtppOf7449OiRYvcc889ZUoLAAAAVFpVpQMAADRm77//fmbOnJm+ffuusb1v37557LHHPvB5N998c1544YVceOGFH+p1amtrs3Tp0jV+AAAAgMZJOQMAsBHeeOONrFq1Kp06dVpje6dOnbJw4cJ1Pue5557L+eefn1tvvTUtW364hcyjR49Ou3bt6n66du260dkBAACAylDOAADUg3++f16pVFrnPfVWrVqV448/PhdddFF22WWXD338ESNGZMmSJXU/L7/88kZnBgAAACqjQdxzBgCgsdpmm23SokWLtVbJLFq0aK3VNEmybNmyPPHEE5k9e3a+9a1vJUmKxWJKpVJatmyZBx54IAcccMBaz6uurk51dfWmeRMAAABAWVk5AwCwEVq3bp2amppMnTp1je1Tp05N796919q/bdu2efLJJzNnzpy6n8GDB2fXXXfNnDlzsu+++5YrOgAAAFAhVs4AAGyk4cOH56tf/Wp69uyZXr165brrrsu8efMyePDgJH+/JNkrr7ySn/3sZ6mqqkqPHj3WeH7Hjh3Tpk2btbYDAAAATZNyBgBgIw0YMCCLFy/OqFGjsmDBgvTo0SOTJ09Ot27dkiQLFizIvHnzKpwSAAAAaCgKpVKpVOkQjdHSpUvTrl27LFmyJG3btq23467jvsFNUlVVMTU1izJzZscUi03/6noV+6+smUyoYlVVFtXUpOPMmakqFisdZ9Or1IQyn5qmep5Pm+rzkbUZawBYm89HAKCxaPpnxQEAAAAAABoQ5QwAAAAAAEAZKWcAAAAAAADKSDkDAAAAAABQRsoZAAAAAACAMlLOAAAAAAAAlJFyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAAAAAAEAZKWcAAAAAAADKSDmTZPTo0SkUChk6dGilowAAAAAAAE1csy9nZsyYkeuuuy6f+tSnKh0FAAAAAABoBlpWOkAlvf322znhhBNy/fXX5/vf//6/3Le2tja1tbV1j5cuXZokKRaLKRaL9ZapqpnUZVVVxRQKpVRV1d/YNWT1OEXWTzOZUMWqqpQKhRSbyfut2IRqJuNrPm3s4ZrH73UAAACAjdGsy5khQ4bk0EMPzUEHHfRvy5nRo0fnoosuWmv766+/nvfee6/eMtXU1NuhGrRCoZiddlqSpJRSqemfAF20qEIv3EwmVLFQyJKddkopSVWpVOk4m16lJpT51DTV83xatmxZvR4PAAAAoClqtuXM7bffnlmzZmXGjBkfav8RI0Zk+PDhdY+XLl2arl27pkOHDmnbtm295Zo5s94O1aD9fcVMIbNmdUix2PTLmY4dK/TCzWRCFauqUkjSYdasVDWHv9qv1IQyn5qmep5Pbdq0qdfjAQAAADRFzbKcefnll3PWWWflgQce+NAnkaqrq1NdXb3W9qqqqlTV46VvmsN5wNVKpUKKxapmUc5U7OpIzWhCFUqlVBWLzeNkeqUmVHMY2//HfNqYwzX93+kAAAAAG6tZljMzZ87MokWLUvMPl+hZtWpVHn744Vx11VWpra1NixYtKpgQAAAAAABoqpplOXPggQfmySefXGPbSSedlE984hM577zzFDMAAAAAAMAm0yzLmY9+9KPp0aPHGtu22GKLbL311mttBwAAAAAAqE8uDA8AAAAAAFBGzXLlzLo89NBDlY4AAAAAAAA0A1bOAAAAAAAAlJFyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAAAAAAEAZKWcAAAAAAADKSDkDAAAAAABQRsoZAAAAAACAMlLOAAAAAAAAlJFyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAAAAAAEAZKWcAAAAAAADKSDkDAAAAAABQRsoZAAAAAACAMlLOAAAAAAAAlJFyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAAAAAAEAZKWcAAAAAAADKSDkDAAAAAABQRsoZAAAAAACAMlLOAAAAAAAAlJFyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAAAAAAEAZKWcAAAAAAADKSDkDAAAAAABQRsoZAAAAAACAMlLOAAAAAAAAlJFyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAAAAAAEAZKWcAAAAAAADKSDkDAAAAAABQRsoZAAAAAACAMlLOAADUg3HjxqV79+5p06ZNampqMn369A/c96677srBBx+cDh06pG3btunVq1fuv//+MqYFAAAAKkk5AwCwkSZOnJihQ4fmggsuyOzZs9OnT58ccsghmTdv3jr3f/jhh3PwwQdn8uTJmTlzZvbff/8cfvjhmT17dpmTAwAAAJXQstIBAAAauzFjxuSUU07JqaeemiQZO3Zs7r///owfPz6jR49ea/+xY8eu8fiSSy7Jvffem/vuuy977733Ol+jtrY2tbW1dY+XLl1af28AAAAAKCsrZwAANsL777+fmTNnpm/fvmts79u3bx577LEPdYxisZhly5alffv2H7jP6NGj065du7qfrl27blRuAAAAoHKUMwAAG+GNN97IqlWr0qlTpzW2d+rUKQsXLvxQx/jhD3+Y5cuX55hjjvnAfUaMGJElS5bU/bz88ssblRsAAACoHJc1AwCoB4VCYY3HpVJprW3rMmHChHz3u9/Nvffem44dO37gftXV1amurt7onAAAAEDlKWcAADbCNttskxYtWqy1SmbRokVrrab5ZxMnTswpp5ySX/ziFznooIM2ZUwAAACgAXFZMwCAjdC6devU1NRk6tSpa2yfOnVqevfu/YHPmzBhQk488cTcdtttOfTQQzd1TAAAAKABsXIGAGAjDR8+PF/96lfTs2fP9OrVK9ddd13mzZuXwYMHJ/n7/WJeeeWV/OxnP0vy92Jm0KBB+fGPf5zPfvazdatuNttss7Rr165i7wMAAAAoD+UMAMBGGjBgQBYvXpxRo0ZlwYIF6dGjRyZPnpxu3bolSRYsWJB58+bV7X/ttddm5cqVGTJkSIYMGVK3/Wtf+1puueWWcscHAAAAyqzZljOjR4/OXXfdlWeeeSabbbZZevfuncsuuyy77rprpaMBAI3Q6aefntNPP32d//bPhctDDz206QMBAAAADVazvefMtGnTMmTIkPzud7/L1KlTs3LlyvTt2zfLly+vdDQAAAAAAKAJa7YrZ6ZMmbLG45tvvjkdO3bMzJkz87nPfa5CqQAAAAAAgKau2ZYz/2zJkiVJkvbt26/z32tra1NbW1v3eOnSpUmSYrGYYrFYbzmqmslapqqqYgqFUqqq6m/sGrJ6nCLrp5lMqGJVVUqFQorN5P1WbEI1k/E1nzb2cM3j9zoAAADAxlDOJCmVShk+fHj+4z/+Iz169FjnPqNHj85FF1201vbXX3897733Xr1lqampt0M1aIVCMTvttCRJKaVS0z8BumhRhV64mUyoYqGQJTvtlFKSqlKp0nE2vUpNKPOpaarn+bRs2bJ6PR4AAABAU1QolZrDmad/bciQIfn1r3+dRx55JNtvv/0691nXypmuXbvmzTffTNu2bestS6tW9XaoBq2qqph99nk9s2Z1SLHY9MuZFSsq9MLNZEIVq6ry+j77pMOsWalqDn+1X6kJZT41TfU8n5YuXZqtttoqS5YsqdfPR9a2dOnStGvXzlgDwD/w+QgANBbNfuXMGWeckUmTJuXhhx/+wGImSaqrq1NdXb3W9qqqqlTV46VvmsN5wNVKpUKKxapmUc5U7OpIzWhCFUqlVBWLzeNkeqUmVHMY2//HfNqYwzX93+kAAAAAG6vZljOlUilnnHFG7r777jz00EPp3r17pSMBAAAAAADNQLMtZ4YMGZLbbrst9957bz760Y9m4cKFSZJ27dpls802q3A6AAAAAACgqWq21x4ZP358lixZki984Qvp3Llz3c/EiRMrHQ0AAAAAAGjCmu3KmVKpVOkIAAAAAABAM9RsV84AAAAAAABUgnIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZaScAQAAAAAAKCPlDAAAAAAAQBkpZwAAAAAAAMpIOQMAAAAAAFBGyhkAAAAAAIAyUs4AAAAAAACUkXIGAAAAAACgjJQzAAAAAAAAZdSsy5lx48ale/fuadOmTWpqajJ9+vRKRwIAGqn1/V4xbdq01NTUpE2bNvnYxz6Wa665pkxJAQAAgEprtuXMxIkTM3To0FxwwQWZPXt2+vTpk0MOOSTz5s2rdDQAoJFZ3+8Vf/nLX9K/f//06dMns2fPzsiRI3PmmWfml7/8ZZmTAwAAAJXQbMuZMWPG5JRTTsmpp56a3XbbLWPHjk3Xrl0zfvz4SkcDABqZ9f1ecc0112SHHXbI2LFjs9tuu+XUU0/NySefnCuuuKLMyQEAAIBKaFnpAJXw/vvvZ+bMmTn//PPX2N63b9889thj63xObW1tamtr6x4vWbIkSfLWW2+lWCzWW7ZCod4O1aAVCsUUi0tTKLROodD0O8K33qrQCzeTCVUsFLK0WEzrQiFVzeE9V2pCNYexjfm0sZYuXZokKZVK9XrchmxDvlc8/vjj6du37xrb+vXrlxtvvDErVqxIq1at1nrOB30XWT3mAEDz/C4CADROzbKceeONN7Jq1ap06tRpje2dOnXKwoUL1/mc0aNH56KLLlpre7du3TZJxqZu1apk5sxKpyifrbaqdIImzoSiPplP9WLZsmVp167dJjl2Q7Mh3ysWLly4zv1XrlyZN954I507d17rOR/0XaRr164bkR4AmqbFixc3m+8iAEDj1CzLmdUK//QX0aVSaa1tq40YMSLDhw+ve1wsFvO3v/0tW2+99Qc+hw+2dOnSdO3aNS+//HLatm1b6Tg0cuYT9cl82jilUinLli1Lly5dKh2l7Nbne8UH7b+u7av983eRt956K926dcu8efOcfNrE/F4oL+NdPsa6fIx1+SxZsiQ77LBD2rdvX+koAAD/UrMsZ7bZZpu0aNFirb9mXbRo0Vp/xbpadXV1qqur19i25ZZbbqqIzUbbtm39zwn1xnyiPplPG665FQUb8r1i2223Xef+LVu2zNZbb73O56zru0jy9/E2V8vD74XyMt7lY6zLx1iXT1VV0798NgDQuDXLbyutW7dOTU1Npk6dusb2qVOnpnfv3hVKBQA0RhvyvaJXr15r7f/AAw+kZ8+e67zfDAAAANC0NMtyJkmGDx+eG264ITfddFOefvrpDBs2LPPmzcvgwYMrHQ0AaGT+3feKESNGZNCgQXX7Dx48OH/9618zfPjwPP3007npppty44035uyzz67UWwAAAADKqFle1ixJBgwYkMWLF2fUqFFZsGBBevTokcmTJ6dbt26VjtYsVFdX58ILL1zn5VlgfZlP1CfziQ3x775XLFiwIPPmzavbv3v37pk8eXKGDRuWq6++Ol26dMlPfvKTHHXUUR/6Nc3V8jHW5WW8y8dYl4+xLh9jDQA0FoXS6rvPAgAAAAAAsMk128uaAQAAAAAAVIJyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAQAM1bty4dO/ePW3atElNTU2mT5/+L/efNm1aampq0qZNm3zsYx/LNddcU6akjd/6jPVdd92Vgw8+OB06dEjbtm3Tq1ev3H///WVM27it77xe7dFHH03Lli2z1157bdqATcz6jndtbW0uuOCCdOvWLdXV1fn4xz+em266qUxpG7f1Hetbb701e+65ZzbffPN07tw5J510UhYvXlymtI3Xww8/nMMPPzxdunRJoVDIPffc82+f4/MRAGiIlDNAs1AqlSodAWC9TJw4MUOHDs0FF1yQ2bNnp0+fPjnkkEMyb968de7/l7/8Jf3790+fPn0ye/bsjBw5MmeeeWZ++ctfljl547O+Y/3www/n4IMPzuTJkzNz5szsv//+OfzwwzN79uwyJ2981nesV1uyZEkGDRqUAw88sExJm4YNGe9jjjkmv/3tb3PjjTfm2WefzYQJE/KJT3yijKkbp/Ud60ceeSSDBg3KKaeckqeeeiq/+MUvMmPGjJx66qllTt74LF++PHvuuWeuuuqqD7W/z0cAoKEqlJyxBJqo1157LW+88Ub22GOPJH8vaAqFQoVT0Vi9+OKLmTRpUp599tn0798/n/3sZ9OhQ4dKx6IJ23fffbPPPvtk/Pjxddt22223HHnkkRk9evRa+5933nmZNGlSnn766bptgwcPzh/+8Ic8/vjjZcncWK3vWK/LHnvskQEDBuQ73/nOporZJGzoWB977LHZeeed06JFi9xzzz2ZM2dOGdI2fus73lOmTMmxxx6bF198Me3bty9n1EZvfcf6iiuuyPjx4/PCCy/Ubbvyyitz+eWX5+WXXy5L5qagUCjk7rvvzpFHHvmB+/h8BAAaKitnaJT+sVPUL7IuTz/9dD75yU9m1KhRefLJJ5P8/X/ezBc2xJNPPpk+ffrkN7/5TWbNmpXjjz++7hIvxWKxwuloit5///3MnDkzffv2XWN7375989hjj63zOY8//vha+/fr1y9PPPFEVqxYscmyNnYbMtb/rFgsZtmyZU5m/xsbOtY333xzXnjhhVx44YWbOmKTsiHjPWnSpPTs2TOXX355tttuu+yyyy45++yz8+6775YjcqO1IWPdu3fvzJ8/P5MnT06pVMprr72WO++8M4ceemg5IjcrPh8BgIZKOUOjsvrE+j+eDHXCnX+2cOHCnHrqqdlpp53yxBNPZMyYMQoaNti8efNy9NFHZ9CgQZk8eXL+93//NxdffHEuu+yyvPbaa6mq8lFK/XvjjTeyatWqdOrUaY3tnTp1ysKFC9f5nIULF65z/5UrV+aNN97YZFkbuw0Z63/2wx/+MMuXL88xxxyzKSI2GRsy1s8991zOP//83HrrrWnZsmU5YjYZGzLeL774Yh555JH86U9/yt13352xY8fmzjvvzJAhQ8oRudHakLHu3bt3br311gwYMCCtW7fOtttumy233DJXXnllOSI3Kz4fAYCGyhklGo3Vl6R68MEH881vfjMnnHBChg0bliQuVcUaXnjhhXTq1CnXX399xo0blwcffHCtggY+jFWrVuXee+/NXnvtlbPOOqtu7gwYMCDbbLNNFi1aVOGENHX//Pvq312ecV37r2s7a1vfsV5twoQJ+e53v5uJEyemY8eOmypek/Jhx3rVqlU5/vjjc9FFF2WXXXYpV7wmZ33mdrFYTKFQyK233prPfOYz6d+/f8aMGZNbbrnF6pkPYX3Geu7cuTnzzDPzne98JzNnzsyUKVPyl7/8JYMHDy5H1GbH5yMA0BApZ2g0Vl9P+Etf+lKqq6uz55575vbbb0/v3r3zt7/9rdLxaEB69OiRESNGZI899ki/fv1y7bXX1hU0f/zjH+v2czkq/p0WLVpk++23zyc/+clsu+22datkPvrRj2b58uV55ZVXKpyQpmqbbbZJixYt1vqL60WLFq3117+rbbvttuvcv2XLltl66603WdbGbkPGerWJEyfmlFNOyR133JGDDjpoU8ZsEtZ3rJctW5Ynnngi3/rWt9KyZcu0bNkyo0aNyh/+8Ie0bNkyDz74YLmiN0obMrc7d+6c7bbbLu3atavbtttuu6VUKmX+/PmbNG9jtiFjPXr06Oy3334555xz8qlPfSr9+vXLuHHjctNNN2XBggXliN1s+HwEABoq5QyNxqJFi/K9730vo0aNypVXXpmBAwemRYsW2XPPPde4xrtLVtGuXbt8+tOfTvL3v7r94he/mOuuuy4PPvhgfvSjH9WtoLnssssyZcqUSkalEfjyl7+c//qv/0ry//9+qaqqykc+8pG0bt26br9f/epXeeaZZyqSkaandevWqampydSpU9fYPnXq1PTu3Xudz+nVq9da+z/wwAPp2bNnWrVqtcmyNnYbMtbJ31fMnHjiibntttvcI+JDWt+xbtu2bZ588snMmTOn7mfw4MHZddddM2fOnOy7777lit4obcjc3m+//fLqq6/m7bffrtv25z//OVVVVdl+++03ad7GbEPG+p133lnr0qgtWrRI4v9n6pvPRwCgwSpBI/HSSy+Vdt9999J7771XeuWVV0rbbbdd6bTTTqv798mTJ1cwHQ1ZsVgslUql0pQpU0o77LBD6cQTTywdddRRpc0337w0d+7cCqejsSkWi6Xa2trS3nvvXfrd735XKpVKpfPPP7/Uvn370rx58yqcjqbk9ttvL7Vq1ap04403lubOnVsaOnRoaYsttii99NJLpVLp7/Puq1/9at3+L774YmnzzTcvDRs2rDR37tzSjTfeWGrVqlXpzjvvrNRbaDTWd6xvu+22UsuWLUtXX311acGCBXU/b731VqXeQqOxvmP9zy688MLSnnvuWaa0jd/6jveyZctK22+/fenoo48uPfXUU6Vp06aVdt5559Kpp55aqbfQaKzvWN98882lli1blsaNG1d64YUXSo888kipZ8+epc985jOVeguNxrJly0qzZ88uzZ49u5SkNGbMmNLs2bNLf/3rX0ulks9HAKDxcFdNGo3NNtssm222WW699daMGjUqhx12WN0NM1966aVcc8012XzzzfP5z3++wkmppNK/uLZ3v379Mn78+Bx22GFp165dHnnkkey2225lTkhjsq75VCgUsnLlyixZsiS1tbX57ne/m5/85Cd56KGH0rVr1wolpSkaMGBAFi9enFGjRmXBggXp0aNHJk+enG7duiVJFixYkHnz5tXt371790yePDnDhg3L1VdfnS5duuQnP/lJjjrqqEq9hUZjfcf62muvzcqVKzNkyJA1bpT+ta99Lbfccku54zcq6zvWbJz1He+PfOQjmTp1as4444z07NkzW2+9dY455ph8//vfr9RbaDTWd6xPPPHELFu2LFdddVW+/e1vZ8stt8wBBxyQyy67rFJvodF44oknsv/++9c9Hj58eJL//3ewz0cAoLEolErWTNPwrOuE6JtvvplTTz01kydPziGHHJK77rqr7t/OP//8PPjgg7n33nvTuXPncselglbPlfnz5//by23U1tbmvPPOy09/+tM8+uij2X333cuUksbiw86nd999N/vtt19atWqVP/zhD3n00UdTU1NTxqQAAAAANGbuOUODs/rk6NSpU/Ptb3873/jGN/LUU09lq622yn/913+la9eueeedd3L11Vfnvvvuy5AhQ3LNNdfk+uuvV8w0Q4VCIXfffXcOPvjgPPvss/9y3xdeeCG333577r//fsUM6/Rh5lOpVEptbW3efPPNPP/88/n973+vmAEAAABgvVg5Q4M0efLkHH300dl///0zf/78vPDCC7nhhhty7LHHZsaMGRkzZkweffTRbLXVVunUqVOuuOKKfOpTn6p0bMpodYk3b968fPOb38yRRx6Zr3/96//2ecuWLctHP/rRMiSkMdmQ+XTddddlv/32yx577FGmlAAAAAA0Fe45Q4Ox+uTosmXL8vjjj+fHP/5x3cnRYcOG5Wtf+1pWrlyZgQMH5mc/+1mWL1+eJGndunU233zzSkanAgqFQmbMmJFbbrklpVIpRxxxRIrFYqqq/vWCQMUM67I+82n176pvfOMbFUgKAAAAQFOgnKGi7rjjjnz+859Pp06dUigUMnv27BxwwAHp3r17Ro0aVbffj370oyTJKaeckhYtWuToo4/OlltuWaHUNBRTp07NL37xi6xatSpvvfVWOnXqtM77FcGH8WHnk/kFAAAAwMZyzxkqolgs5plnnsk3vvGNvP/++3Xb99xzz/Tv3z9z5szJokWLkvz9r9STvxc0Z5xxRk444YRMmjSpIrlpWEaOHJkLL7wwW2yxRS677LK89NJLTpyzwcwnAAAAAMrFPWeoiJUrV6Zly5ZZsmRJ2rVrlz/96U9p3759unTpkpUrV2bQoEGZMmVK7rnnnnzuc59b47kXXHBBvvrVr+YTn/hEhdJTCatXMPz5z3/OO++8k9dffz0HH3xwkr8Xdz/72c9ywAEH5KyzzsoOO+xQ4bQ0dOYTAAAAAJWknKHsbrzxxrRs2TLHHntsqqur8/rrr6dTp0454YQTcvnll6dz584pFosZMGBAHnzwwdx9991rFTQ0L6tPpN911105//zz06ZNm/ztb3/LLrvskmuuuSa77LJLfvCDH2TChAk58MADM2TIkOy4446Vjk0DZT4BAAAAUGkua0ZZlUql3HLLLbniiity3333pba2Nh06dMh9992XO++8MxdeeGFeffXVVFVVZeLEiTnggAMyYMCA/Pa3v610dCqoUCjk4Ycfzoknnpjzzz8/s2bNyp133pmHHnoojz76aJLknHPOyXHHHZc777wzN9xwQ1auXFnh1DRU5hMAAAAAlWblDGWz+q/VV65cmaOOOirz5s3L+eefn8MPPzybb7557r///hx66KE5+eST893vfjddunRJsVhM//7989xzz+VPf/pTNttss0q/DSrkiiuuyDPPPJMbbrghzz//fPr165eDDjoo11577Rr7jR07Nl/60pfSvXv3CiWlMTCfAAAAAKgk5QxltWrVqrRo0SIrV67MkUcemVdeeeUDC5qLLrqo7hJnCxYsyHbbbVfp+JTR6jJvtQEDBmSbbbbJD3/4w+y8887p379/rrnmmhQKhYwfPz6FQiGDBw+uYGIaMvMJAAAAgIbEZc0oqxYtWiRJWrZsmXvuuSedO3fOpZdemvvuuy/vvPNO+vXrl1//+tf5+c9/nm9/+9tZuHBhqqqqFDPNyIIFCzJnzpwUCoXccccdueWWW5IkRx11VGbNmpXtt98+hx122BorHJ588snMnDkz7777boVS01CZTwAAAAA0RC0rHYDmYfVfrS9cuDCtWrXKW2+9lY9//OOZNGlSjjzyyIwePTpJcvjhh6dfv3654447ctJJJ8XCruZl6dKl+epXv5ptt902e+65Z84777zcdNNNSZJdd901bdq0yTbbbJMvfelLSZIlS5bkiiuuyN13352HHnrIZe9Yg/kEAAAAQEPlsmZscquLmUmTJuXSSy/N0qVLs2rVqgwcODAXXHDBGpc4GzFiRA499NBsscUWWb58ebbYYotKx6fM7rnnnpx77rl5/vnnc9FFF+W///u/6/7t//yf/5NLL700L7zwQtq1a5d27drlhRdeyH333Ze99967gqlpqMwnAAAAABoi5QxlMWXKlHz5y1/OFVdckc997nP59a9/nZEjR2bKlCnp27dvVq5cmaOOOip/+MMfMmbMmPznf/7nWveIoOmaN29e7rrrrgwdOjRvvfVWampqsmrVqhx00EH55je/mZqamrp9n3766Tz//POZPn169txzz/Tu3dvN2lmD+QQAAABAQ6ecoSwGDx6cDh065Hvf+17mzZuXAw44IAcddFCuueaaFIvFVFVVZcWKFRk4cGBGjx6dj33sY5WOTJmsWrUqF1xwQe655558/etfz7e//e28/vrreeSRR3LJJZdkt912y1lnnbXGCXX4IOYTAAAAAI1BVaUD0PTV1tbmf//3f7PTTjtl6dKl6d27dw488MCMHz8+SXLdddfloYceSqtWrTJx4kTFTDPTokWLnHHGGfniF7+YCRMm5Ac/+EE6dOiQL3/5yxk2bFiefvrpXHXVVXniiSeSJBdddFF+/vOfVzg1DZX5BAAAAEBjYOUM9W715cjee++9VFdXp1Ao5Nxzz81rr72W3/72tzn88MNz9dVXp6qqKu+++26++c1v5hOf+ETOPvvstGjRwqXMmqmFCxfm4osvzowZM3LEEUdk5MiRSZIJEybkyiuvTFVVVTp27Jh77rknM2bMsPKBf8l8AgAAAKAhs3KGerW6mJkyZUpGjhyZp556Kkmyxx575Ne//nW23377jBw5MlVVVVm5cmW+//3vZ9q0afnKV76Sli1bKmaasW233TYXXHBBPv3pT2fSpEm55JJLkiTHHXdcLrjggvTp0yebbbZZnnzySSfS+bfMJwAAAAAaMitnqHd33XVXTjrppAwZMiQnnnhidtlllyTJpZdemuuuuy477rhjunTpknfffTfTpk3L1KlTs/fee1c4NQ3FB614KBaLKRaLadmyZYUT0piYTwAAAAA0RMoZ6tWcOXPSr1+/XHrppTnppJPqtr/55pvZaqutMnXq1Pz2t7/NU089lZqamhx33HHZddddK5iYhmj1CfXZs2fngAMOyKhRoyodiUbMfAIAAACgoVHOUK/uv//+fO9738uUKVOSJHfeeWduvfXWvPrqq+nTp08uv/zytG3btsIpaQwWLlyYESNGZP78+bn99tuz9dZbVzoSjZj5BAAAAEBDopxho62+z0yS/OpXv8qRRx6Z888/P7/61a+yww47ZMcdd0znzp1z/fXX54YbbsgBBxxQ4cQ0Fq+99lqSpFOnThVOQlNgPgEAAADQUChn2GCrS5l/LGeSZPTo0fnd736XnXbaKSeddFJ69OiRFStW5DOf+Uwuu+yy9O3bt4KpAQAAAACgstwJmQ2yupB5+OGHc++992blypXZZZddMmTIkIwYMSJvvfVWttxyy7r9L7rooixbtiy777575UIDAAAAAEADYOUMG+zuu+/OSSedlMMPPzwrVqzIU089lX333Tc33HBDkqRYLOanP/1pHnvssdxzzz154IEHsvfee1c4NQAAAAAAVJaVM2yQJ554IsOHD89ll12W0047Lc8880w+97nP5ec//3mWLFmSX/ziF6mqqkqxWMzixYszbdo0q2YAAAAAACBWzvBvFIvFVFVVpVQqpVQqpaqqKkny85//PI888kiuvfbazJs3L1/4whfyhS98Ifvtt1++9a1vZeDAgbn++uuTJMuXL88WW2xRybcBAAAAAAANhnKGD7S6mPnzn/+cK6+8Mq+88kp69+6ds88+O0kyY8aM7LPPPjnssMPSsWPH/PSnP80bb7yR3r175/nnn8+xxx6b2267re7+NAAAAAAAQFJV6QA0TKuLmT/84Q/5j//4j8yfPz/V1dUZOXJkLrvssiTJpz/96bz66quZP39+Tj755CRJVVVV9t133/zsZz/LxRdfnCSKGQAAAAAA+AfuOcNaVhczf/zjH9OrV68MGzYsF198cVatWpVtttkmCxcuzHvvvZc2bdqkuro67733Xu68887stdde+cEPfpBnn302Y8aMSYcOHSr9VgAAAAAAoMFxWTPW6eWXX84+++yT/fffP3fccUfd9mOPPTbPPPNMamtrs+OOO+aoo47K22+/nR/84Adp0aJF3n///fzmN7/J3nvvXcH0AAAAAADQcLmsGeu0atWqdO/ePbW1tXn00UeTJJdeemnuu+++HHXUUTn77LPz0ksv5aqrrkpNTU2mTp2aq6++OjNmzFDMAAAAAADAv2DlDB/oueeey5lnnpnWrVunY8eOmTRpUn7+85+nb9++SZK//vWv6d69e6699tp8/etfr3BaAAAAAABoHKyc4QPtvPPO+fGPf5x33303t956a84999z07ds3pVIpK1asSMuWLfPJT34yW221VZJEzwcAAAAAAP+ecoZ/aZdddsn48ePTp0+f/Pa3v8306dNTKBTSqlWrXHvttVm2bFn23XffJEmhUKhwWgAAAAAAaPhc1owPZfUlzkqlUkaPHp2pU6fmwgsvzGOPPeYeMwAAAAAAsB6UM3xozz33XIYPH57f//73efPNN/P444+npqam0rEAAAAAAKBRcVkzPrSdd945V1xxRT772c9m9uzZihkAAAAAANgAVs6w3lasWJFWrVpVOgYAAAAAADRKyhkAAAAAAIAyclkzAAAAAACAMlLOAAAAAAAAlJFyBgAAAAAAoIyUMwAAAAAAAGWknAEAAAAAACgj5QwAAAAAAEAZKWcAAAAAAADKSDkDAAAAAABQRsoZAAAAAACAMvr/ALZyvIFmuIGFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x1600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comprehensive Visualization\n",
    "print(\"\\nüìä Creating comprehensive visualizations...\")\n",
    "\n",
    "# Create a large figure with multiple subplots\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# 1. Performance progression over iterations\n",
    "plt.subplot(3, 3, 1)\n",
    "iterations = [r['iteration'] for r in iteration_results]\n",
    "mape_values = [r['mape'] for r in iteration_results]\n",
    "improvements = [r['improvement'] for r in iteration_results]\n",
    "\n",
    "plt.plot(iterations, mape_values, 'bo-', linewidth=2, markersize=8, label='MAPE')\n",
    "plt.axhline(y=baseline_mape, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Performance Progression Over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Improvement per iteration\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.bar(iterations[1:], improvements[1:], color=['green' if imp > 0 else 'red' for imp in improvements[1:]])\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Improvement (%)')\n",
    "plt.title('Improvement per Iteration')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature count vs Performance\n",
    "plt.subplot(3, 3, 3)\n",
    "feature_counts = [r['feature_count'] for r in iteration_results]\n",
    "colors = ['blue' if r['iteration'] == 0 else 'green' if r['improvement'] > 0 else 'red' for r in iteration_results]\n",
    "plt.scatter(feature_counts, mape_values, c=colors, s=100, alpha=0.7)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Feature Count vs Performance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Model comparison (bar chart)\n",
    "plt.subplot(3, 3, 4)\n",
    "model_names = [f\"Iter {r['iteration']}\" if r['iteration'] > 0 else \"Baseline\" for r in iteration_results]\n",
    "bars = plt.bar(range(len(model_names)), mape_values, color=['blue'] + ['green' if imp > 0 else 'red' for imp in improvements[1:]])\n",
    "plt.xticks(range(len(model_names)), model_names, rotation=45)\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, mape_values)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "             f'{value:.2f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 5. True vs Predicted (Best Model)\n",
    "plt.subplot(3, 3, 5)\n",
    "best_predictions = best_result['predictions']\n",
    "best_true = best_result['true_values']\n",
    "plt.scatter(best_true, best_predictions, alpha=0.6, s=50)\n",
    "plt.plot([best_true.min(), best_true.max()], [best_true.min(), best_true.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title(f'True vs Predicted (Best Model: {best_result[\"model_name\"]})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Time series comparison (Best Model vs Baseline)\n",
    "plt.subplot(3, 3, 6)\n",
    "test_range = range(len(best_true))\n",
    "plt.plot(test_range, best_true, 'k-', linewidth=2, label='True', alpha=0.8)\n",
    "plt.plot(test_range, baseline_results['predictions'], 'r-', linewidth=1.5, label='Baseline', alpha=0.7)\n",
    "plt.plot(test_range, best_predictions, 'g-', linewidth=1.5, label='Best Model', alpha=0.7)\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Short Interest')\n",
    "plt.title('Time Series Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Performance metrics comparison\n",
    "plt.subplot(3, 3, 7)\n",
    "metrics = ['MAPE', 'MAE', 'RMSE']\n",
    "baseline_metrics = [baseline_results['mape'], baseline_results['mae']/1e6, baseline_results['rmse']/1e6]\n",
    "best_metrics = [best_result['mape'], best_result['mae']/1e6, best_result['rmse']/1e6]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, baseline_metrics, width, label='Baseline', alpha=0.7)\n",
    "plt.bar(x + width/2, best_metrics, width, label='Best Model', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Performance Metrics Comparison')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Feature reduction efficiency\n",
    "plt.subplot(3, 3, 8)\n",
    "efficiency_data = []\n",
    "for i, result in enumerate(iteration_results):\n",
    "    if i == 0:\n",
    "        efficiency_data.append(0)\n",
    "    else:\n",
    "        feature_red = ((baseline_features - result['feature_count']) / baseline_features) * 100\n",
    "        performance_imp = result['improvement']\n",
    "        efficiency_data.append(performance_imp / feature_red if feature_red > 0 else 0)\n",
    "\n",
    "plt.bar(iterations[1:], efficiency_data[1:], color=['green' if eff > 0 else 'red' for eff in efficiency_data[1:]])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Efficiency (Improvement/Feature Reduction)')\n",
    "plt.title('Feature Engineering Efficiency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Cumulative improvement\n",
    "plt.subplot(3, 3, 9)\n",
    "cumulative_improvement = [0]\n",
    "for i in range(1, len(improvements)):\n",
    "    cumulative_improvement.append(cumulative_improvement[-1] + improvements[i])\n",
    "\n",
    "plt.plot(iterations, cumulative_improvement, 'go-', linewidth=2, markersize=6)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cumulative Improvement (%)')\n",
    "plt.title('Cumulative Performance Improvement')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949f6bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': 0,\n",
       " 'model_name': 'Baseline',\n",
       " 'features_used': 'All 62 original features',\n",
       " 'feature_count': 62,\n",
       " 'mape': 9.37122452950319,\n",
       " 'mae': 7301369.571800289,\n",
       " 'rmse': 9576693.442747284,\n",
       " 'improvement': 0.0,\n",
       " 'predictions': array([5.98582978e+07, 6.25753859e+07, 6.32193637e+07, 6.88554744e+07,\n",
       "        7.44277183e+07, 6.76696088e+07, 7.09356428e+07, 6.51685841e+07,\n",
       "        7.29543987e+07, 7.86932655e+07, 6.44571159e+07, 6.23853097e+07,\n",
       "        5.81718256e+07, 6.80903418e+07, 6.44335470e+07, 6.81049717e+07,\n",
       "        7.77457832e+07, 7.03057867e+07, 7.35728083e+07, 6.43618944e+07,\n",
       "        9.73121123e+07, 9.28565211e+07, 8.79442305e+07, 7.82008106e+07,\n",
       "        9.41288908e+07, 7.61428032e+07, 9.19527696e+07, 9.72672996e+07,\n",
       "        1.00992702e+08, 9.89437720e+07, 1.09522500e+08, 1.16461063e+08,\n",
       "        1.09032448e+08, 1.06534699e+08, 1.08311814e+08, 1.12926942e+08])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3222f097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saving results and generating final report...\n",
      "‚úÖ Results saved to: cache/PFE_iterative_results.pkl\n",
      "‚úÖ Detailed report saved to: cache/PFE_iterative_report.txt\n",
      "\n",
      "======================================================================\n",
      "üéâ ITERATIVE AGENT-BASED FEATURE SELECTION COMPLETED!\n",
      "======================================================================\n",
      "üìä Final Results:\n",
      "   ‚Ä¢ Baseline MAPE: 9.37%\n",
      "   ‚Ä¢ Best MAPE: 9.37%\n",
      "   ‚Ä¢ Total Improvement: 0.00%\n",
      "   ‚Ä¢ Feature Reduction: 0.0%\n",
      "   ‚Ä¢ Iterations Completed: 2\n",
      "   ‚Ä¢ Success Rate: 0.0%\n",
      "\n",
      "üíæ Files Saved:\n",
      "   ‚Ä¢ Results: cache/PFE_iterative_results.pkl\n",
      "   ‚Ä¢ Report: cache/PFE_iterative_report.txt\n",
      "\n",
      "‚úÖ Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save results and generate final report\n",
    "print(\"\\nüíæ Saving results and generating final report...\")\n",
    "\n",
    "# Save iteration results to pickle\n",
    "results_filename = f'cache/{stock}_iterative_results.pkl'\n",
    "with open(results_filename, 'wb') as f:\n",
    "    pickle.dump(iteration_results, f)\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {results_filename}\")\n",
    "\n",
    "# Generate detailed report\n",
    "report_filename = f'cache/{stock}_iterative_report.txt'\n",
    "with open(report_filename, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"ITERATIVE AGENT-BASED FEATURE SELECTION REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(f\"Stock: {stock}\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Total Iterations: {len(iteration_results) - 1}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE SUMMARY:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"Baseline MAPE: {baseline_mape:.2f}%\\n\")\n",
    "    f.write(f\"Best MAPE: {best_result['mape']:.2f}%\\n\")\n",
    "    f.write(f\"Total Improvement: {total_improvement:.2f}% ({improvement_percentage:.1f}% relative)\\n\")\n",
    "    f.write(f\"Feature Reduction: {feature_reduction:.1f}%\\n\")\n",
    "    f.write(f\"Success Rate: {efficiency:.1f}%\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"DETAILED RESULTS:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    for result in iteration_results:\n",
    "        f.write(f\"Iteration {result['iteration']}: {result['model_name']}\\n\")\n",
    "        f.write(f\"  MAPE: {result['mape']:.2f}%\\n\")\n",
    "        f.write(f\"  Features: {result['feature_count']}\\n\")\n",
    "        f.write(f\"  Improvement: {result['improvement']:+.2f}%\\n\")\n",
    "        f.write(f\"  Source: {result.get('function_source', 'baseline')}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"BEST MODEL DETAILS:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"Model: {best_result['model_name']}\\n\")\n",
    "    f.write(f\"MAPE: {best_result['mape']:.2f}%\\n\")\n",
    "    f.write(f\"MAE: {best_result['mae']:.4f}\\n\")\n",
    "    f.write(f\"RMSE: {best_result['rmse']:.4f}\\n\")\n",
    "    f.write(f\"Features: {best_result['feature_count']}\\n\")\n",
    "    f.write(f\"Source: {best_result.get('function_source', 'baseline')}\\n\")\n",
    "    \n",
    "    if best_result.get('claude_code'):\n",
    "        f.write(\"\\nBEST MODEL FEATURE ENGINEERING CODE:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(best_result['claude_code'])\n",
    "\n",
    "print(f\"‚úÖ Detailed report saved to: {report_filename}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ ITERATIVE AGENT-BASED FEATURE SELECTION COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìä Final Results:\")\n",
    "print(f\"   ‚Ä¢ Baseline MAPE: {baseline_mape:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Best MAPE: {best_result['mape']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Total Improvement: {total_improvement:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Feature Reduction: {feature_reduction:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Iterations Completed: {len(iteration_results) - 1}\")\n",
    "print(f\"   ‚Ä¢ Success Rate: {efficiency:.1f}%\")\n",
    "print(f\"\\nüíæ Files Saved:\")\n",
    "print(f\"   ‚Ä¢ Results: {results_filename}\")\n",
    "print(f\"   ‚Ä¢ Report: {report_filename}\")\n",
    "print(\"\\n‚úÖ Process completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d64f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ff082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5332002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301eea73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d6d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca9d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49643465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_features(data):\n",
    "    \"\"\"\n",
    "    Constructs engineered features from raw financial data for short interest prediction.\n",
    "    Input shape: (lookback_window, 62) where 62 = [short_interest, volume, OHLC_15days]\n",
    "    Output shape: (lookback_window, constructed_features)\n",
    "    \"\"\"\n",
    "    lookback = data.shape[0]\n",
    "\n",
    "    # Initialize output array\n",
    "    engineered = np.zeros((lookback, 25))\n",
    "\n",
    "    for t in range(lookback):\n",
    "        # Extract core features for current timestamp\n",
    "        short_interest = data[t,0]\n",
    "        volume = data[t,1]\n",
    "        print(volume)\n",
    "\n",
    "        # Reshape OHLC data (60 features) into (15,4) array\n",
    "        ohlc = data[t,2:].reshape(15,4)\n",
    "        opens = ohlc[:,0]\n",
    "        highs = ohlc[:,1]\n",
    "        lows = ohlc[:,2]\n",
    "        closes = ohlc[:,3]\n",
    "\n",
    "        # 1. Price momentum features\n",
    "        returns = np.diff(closes) / closes[:-1]  # Daily returns\n",
    "        engineered[t,0] = np.mean(returns)  # Average return\n",
    "        engineered[t,1] = np.sum(returns > 0) / len(returns)  # Up day ratio\n",
    "\n",
    "        # 2. Volatility features\n",
    "        true_range = np.maximum(highs - lows,\n",
    "                              np.abs(highs - np.roll(closes, 1)),\n",
    "                              np.abs(lows - np.roll(closes, 1)))\n",
    "        atr = np.mean(true_range)  # Average True Range\n",
    "        engineered[t,2] = atr\n",
    "        engineered[t,3] = np.std(returns)  # Return volatility\n",
    "\n",
    "        # 3. Price level features\n",
    "        typical_price = (highs + lows + closes) / 3\n",
    "        engineered[t,4] = np.mean(typical_price)  # Average price\n",
    "        engineered[t,5] = np.max(highs) / np.min(lows) - 1  # Price range\n",
    "\n",
    "        # 4. Volume features\n",
    "        vol_ma = np.mean(volume)  # Volume moving average\n",
    "        engineered[t,6] = volume / vol_ma - 1  # Volume vs MA\n",
    "        print(volume.shape)\n",
    "        print(closes.shape)\n",
    "        print(np.corrcoef(volume, closes))\n",
    "        engineered[t,7] = np.corrcoef(volume, closes)[0,1]  # Volume-price correlation\n",
    "        print(np.corrcoef(volume, closes)[0,1].shape)\n",
    "\n",
    "        # 5. Short interest features\n",
    "        engineered[t,8] = short_interest / volume  # Days to cover\n",
    "        engineered[t,9] = short_interest / np.mean(closes)  # Short interest ratio\n",
    "\n",
    "        # 6. Technical indicators\n",
    "        # RSI\n",
    "        gains = np.maximum(returns, 0)\n",
    "        losses = np.abs(np.minimum(returns, 0))\n",
    "        avg_gain = np.mean(gains)\n",
    "        avg_loss = np.mean(losses)\n",
    "        rs = avg_gain / (avg_loss + 1e-10)\n",
    "        engineered[t,10] = 100 - (100 / (1 + rs))\n",
    "\n",
    "        # MACD\n",
    "        ema12 = np.mean(closes[-12:])\n",
    "        ema26 = np.mean(closes[-26:]) if len(closes) >= 26 else ema12\n",
    "        engineered[t,11] = ema12 - ema26\n",
    "\n",
    "        # 7. Price patterns\n",
    "        # Higher highs/lower lows\n",
    "        engineered[t,12] = np.sum(np.diff(highs) > 0) / (len(highs)-1)\n",
    "        engineered[t,13] = np.sum(np.diff(lows) < 0) / (len(lows)-1)\n",
    "\n",
    "        # 8. Gap analysis\n",
    "        gaps = opens - np.roll(closes, 1)\n",
    "        engineered[t,14] = np.sum(gaps > 0) / (len(gaps)-1)  # Gap up ratio\n",
    "\n",
    "        # 9. Candlestick patterns\n",
    "        body = closes - opens\n",
    "        upper_shadow = highs - np.maximum(opens, closes)\n",
    "        lower_shadow = np.minimum(opens, closes) - lows\n",
    "        engineered[t,15] = np.mean(body)  # Average body size\n",
    "        engineered[t,16] = np.mean(upper_shadow)  # Average upper shadow\n",
    "        engineered[t,17] = np.mean(lower_shadow)  # Average lower shadow\n",
    "\n",
    "        # 10. Trend strength indicators\n",
    "        sma20 = np.mean(closes[-20:]) if len(closes) >= 20 else np.mean(closes)\n",
    "        engineered[t,18] = closes[-1] / sma20 - 1  # Price vs SMA\n",
    "\n",
    "        # 11. Volatility regime\n",
    "        engineered[t,19] = np.percentile(true_range, 75) / np.percentile(true_range, 25)\n",
    "\n",
    "        # 12. Volume profile\n",
    "        engineered[t,20] = np.corrcoef(volume, true_range)[0,1]  # Volume-volatility correlation\n",
    "\n",
    "        # 13. Short interest momentum\n",
    "        if t > 0:\n",
    "            engineered[t,21] = short_interest / data[t-1,0] - 1\n",
    "\n",
    "        # 14. Combined indicators\n",
    "        engineered[t,22] = engineered[t,10] * engineered[t,6]  # RSI * Volume ratio\n",
    "        engineered[t,23] = engineered[t,3] * engineered[t,8]  # Volatility * Days to cover\n",
    "        engineered[t,24] = engineered[t,11] * engineered[t,9]  # MACD * Short ratio\n",
    "\n",
    "    # Handle any NaN values\n",
    "    return np.nan_to_num(engineered, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bee87a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 62)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.zeros((142, 4,62))\n",
    "x_test = x_test[:, -1, :]\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d8b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 A                                                      \\\n",
      "           1. open 2. high 3. low 4. close 5. adjusted close 6. volume   \n",
      "1999-11-01     NaN     NaN    NaN      NaN               NaN       NaN   \n",
      "1999-11-02     NaN     NaN    NaN      NaN               NaN       NaN   \n",
      "1999-11-03     NaN     NaN    NaN      NaN               NaN       NaN   \n",
      "1999-11-04     NaN     NaN    NaN      NaN               NaN       NaN   \n",
      "1999-11-05     NaN     NaN    NaN      NaN               NaN       NaN   \n",
      "\n",
      "                                                     KMTUF          ...  \\\n",
      "           7. dividend amount 8. split coefficient 1. open 2. high  ...   \n",
      "1999-11-01                NaN                  NaN     NaN     NaN  ...   \n",
      "1999-11-02                NaN                  NaN     NaN     NaN  ...   \n",
      "1999-11-03                NaN                  NaN     NaN     NaN  ...   \n",
      "1999-11-04                NaN                  NaN     NaN     NaN  ...   \n",
      "1999-11-05                NaN                  NaN     NaN     NaN  ...   \n",
      "\n",
      "                          BST                          EGP                 \\\n",
      "           7. dividend amount 8. split coefficient 1. open 2. high 3. low   \n",
      "1999-11-01                NaN                  NaN   18.38   18.38  18.13   \n",
      "1999-11-02                NaN                  NaN   18.25   18.38  18.25   \n",
      "1999-11-03                NaN                  NaN   18.38   18.50  18.19   \n",
      "1999-11-04                NaN                  NaN   18.50   18.56  18.31   \n",
      "1999-11-05                NaN                  NaN   18.38   18.44  18.31   \n",
      "\n",
      "                                                                    \\\n",
      "           4. close 5. adjusted close 6. volume 7. dividend amount   \n",
      "1999-11-01    18.13          5.769661   10400.0                0.0   \n",
      "1999-11-02    18.38          5.849221   15600.0                0.0   \n",
      "1999-11-03    18.50          5.887409   14000.0                0.0   \n",
      "1999-11-04    18.38          5.849221   20000.0                0.0   \n",
      "1999-11-05    18.31          5.826944   23400.0                0.0   \n",
      "\n",
      "                                 \n",
      "           8. split coefficient  \n",
      "1999-11-01                  1.0  \n",
      "1999-11-02                  1.0  \n",
      "1999-11-03                  1.0  \n",
      "1999-11-04                  1.0  \n",
      "1999-11-05                  1.0  \n",
      "\n",
      "[5 rows x 46544 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6499 entries, 1999-11-01 to 2025-09-03\n",
      "Columns: 46544 entries, ('A', '1. open') to ('EGP', '8. split coefficient')\n",
      "dtypes: float64(46544)\n",
      "memory usage: 2.3 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the parquet file\n",
    "df = pd.read_parquet('../data/price_data_multiindex_20250904_113138.parquet')\n",
    "\n",
    "# Display basic info about the dataframe\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a01885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5818"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tickers = set([x[0] for x in df.columns])\n",
    "len(all_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e29c5a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'KMTUF', 'KMTUF',\n",
      "       ...\n",
      "       'BST', 'BST', 'EGP', 'EGP', 'EGP', 'EGP', 'EGP', 'EGP', 'EGP', 'EGP'],\n",
      "      dtype='object', length=46544)\n",
      "Index(['A', 'KMTUF', 'KNYJF', 'KNX', 'KNSL', 'KNOP', 'KNNGF', 'KNKZF', 'KNDI',\n",
      "       'KNCRF',\n",
      "       ...\n",
      "       'BSRR', 'AWK', 'AXGN', 'BRID', 'ASND', 'EBAY', 'DOGZ', 'DXR', 'BST',\n",
      "       'EGP'],\n",
      "      dtype='object', length=5818)\n"
     ]
    }
   ],
   "source": [
    "# Get the first level of column names\n",
    "first_level = df.columns.get_level_values(0)\n",
    "print(first_level)\n",
    "\n",
    "# If you want unique values only\n",
    "unique_tickers = df.columns.get_level_values(0).unique()\n",
    "print(unique_tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
