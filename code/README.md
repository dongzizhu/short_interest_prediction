# Iterative Agent-Based Feature Selection System

## Overview

This system implements an advanced **iterative agent-based feature selection** approach for financial time series prediction, specifically designed for **Short Interest prediction**. The system combines **Deep Learning (LSTM)** and **Support Vector Machine (SVM)** models with **Large Language Model (LLM)**-driven feature engineering to automatically discover optimal feature combinations.


## ğŸ—ï¸ System Architecture

### Single Ticker Process:
```
1. Config â†’ 2. DataLoader â†’ 3. Baseline Training â†’ 4. Iteration Loopâ”€â”€â”€â”€â”
                                                                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
5. Prompt Generation â†’ 6. Claude API Call â†’ 7. Code Extraction â†’ 8. Validation
    â”‚
    â–¼
9. Feature Application â†’ 10. Model Training â†’ 11. Performance Eval
    â”‚
    â””â”€â”€â†’ Improvement? â”€â”€Yesâ”€â”€â†’ Continue to next iteration
            â”‚
           No
            â”‚
            â–¼
12. Final Test Evaluation â†’ 13. Save Results
```

### Multi-Ticker Process:
```
1. Run Single Ticker Process for each ticker (e.g., 5 tickers)
    â”‚
    â–¼
2. Collect best results from all tickers
    â”‚
    â–¼
3. Generate Universal Prompt (synthesize best practices)
    â”‚
    â–¼
4. Claude generates Universal Feature Engineering Code
    â”‚
    â–¼
5. Validate Universal Code on ALL tickers (e.g., 500+ tickers)
    â”‚
    â–¼
6. Generate Comprehensive Performance Report
```


## ğŸ“Š Data Structure

### Input Data Format
- **Shape**: `(samples, lookback_window=4, features=97)`
- **Features per timestamp** (total: 97 features):
  - **Short Interest** (1 feature): Current short interest value
  - **Volume** (1 feature): Average daily volume over past 15 days
  - **Days to Cover** (1 feature): Short interest / average volume
  - **OHLC Prices** (60 features): Open, High, Low, Close prices for past 15 days (15 days Ã— 4 = 60)
  - **Options Put/Call Ratio** (1 feature): Volume ratio of put options to call options
  - **Synthetic Short Cost** (1 feature): Cost of creating synthetic short via options
  - **Implied Volatility** (1 feature): Average implied volatility of options
  - **Shares Outstanding** (1 feature): Total shares issued
  - **Short Volume** (15 features): Daily short volume for past 15 days
  - **Total Volume** (15 features): Daily total trading volume for past 15 days

### Time Series Structure
```
Timestamp T: [SI, Vol, DTC, OHLC_1...60, PutCall, ShortCost, IV, Shares, ShortVol_1...15, TotalVol_1...15]
Timestamp T-1: [SI, Vol, DTC, OHLC_1...60, PutCall, ShortCost, IV, Shares, ShortVol_1...15, TotalVol_1...15]
...
```

## ğŸ¤– LLM-Driven Feature Engineering

### Iterative Process

The system uses **Claude (Anthropic)** to automatically generate feature engineering code through an iterative process:

#### 1. **Initial Feature Engineering**
```python
# LLM generates initial feature construction code
def construct_features(data):
    # Extract key components (data shape: lookback_window Ã— 97)
    short_interest = data[:, 0]           # Feature 0
    volume = data[:, 1]                   # Feature 1
    days_to_cover = data[:, 2]            # Feature 2
    ohlc_data = data[:, 3:63].reshape(-1, 15, 4)  # Features 3-62 (60 total)
    put_call_ratio = data[:, 63]         # Feature 63
    short_cost = data[:, 64]             # Feature 64
    implied_vol = data[:, 65]            # Feature 65
    shares_out = data[:, 66]             # Feature 66
    short_volume = data[:, 67:82]        # Features 67-81 (15 total)
    total_volume = data[:, 82:97]        # Features 82-96 (15 total)

    # Create engineered features
    features = []
    # ... feature engineering logic
    return np.array(features)  # Shape: (lookback_window, num_engineered_features)
```

#### 2. **Performance-Based Iteration**
- **Baseline Performance**: Train model with original 97 features
- **Feature Importance Analysis**: Use DL-based methods to identify important features
- **LLM Feedback**: Provide performance metrics and feature importance to LLM
- **Code Generation**: LLM generates improved feature engineering code
- **Validation**: Test new features and compare performance

#### 3. **Error Handling & Retry Logic**
- **Validation**: Test generated code with mock data
- **Error Feedback**: If code fails, provide error details to LLM
- **Retry Mechanism**: LLM generates corrected code based on error feedback
- **Success Criteria**: Code must pass validation and improve performance

### Feature Engineering Capabilities

The LLM can generate sophisticated financial features:

- **Momentum Indicators**: Price momentum, volume momentum, short interest momentum
- **Volatility Measures**: Rolling volatility, ATR, price range analysis
- **Technical Indicators**: Moving averages, RSI, MACD-like indicators
- **Volume Analysis**: Volume-price relationships, volume patterns
- **Statistical Features**: Correlation, regression slopes, statistical moments
- **Domain-Specific Features**: Short interest ratios, market microstructure indicators


## ğŸ”„ Iterative Process Flow

### Phase 1: Baseline Establishment
1. **Load Data**: Load financial time series data
2. **Split Data**: Train (60%), Validation (20%), Test (20%)
3. **Baseline Training**: Train LSTM or SVM with original 97 features
4. **Performance Metrics**: Calculate MAPE
5. **Feature Importance**: Analyze which features are most important

### Phase 2: LLM-Driven Iteration
1. **Prompt Generation**: Create detailed prompt with:
   - Performance history
   - Feature importance analysis
   - Error feedback from previous attempts
   - Domain knowledge about financial markets

2. **Code Generation**: LLM generates feature engineering code
3. **Code Validation**: Test generated code with mock data
4. **Feature Application**: Apply new features to training data
5. **Model Retraining**: Train models with new features
6. **Performance Comparison**: Compare with previous iteration

### Phase 3: Convergence & Selection
1. **Convergence Check**: Stop if no improvement for 5 iterations
2. **Best Code Selection**: Choose best performing feature engineering code
3. **Final Validation**: Train on train+val set, test on unseen test set

## ğŸ“ˆ Performance Evaluation
We also evaluate the generalizability of the feature engineering code by make one more call to the LLM to combine all the previous code to a unversal feature engineering code and test on a more general set of tickers.


## ğŸ“ File Structure

```
code/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ config.py                 # Configuration management
â”œâ”€â”€ data_loader.py            # Data loading and preprocessing
â”œâ”€â”€ models.py                 # LSTM and SVM model definitions
â”œâ”€â”€ feature_engineering.py    # LLM-driven feature engineering
â”œâ”€â”€ evaluation.py             # Performance evaluation and reporting
â”œâ”€â”€ main.py                   # Main orchestration pipeline
â”œâ”€â”€ utils.py                  # Utility functions
â”œâ”€â”€ prompt.py                 # LLM prompt templates
â”œâ”€â”€ example_usage.py          # Usage examples
â””â”€â”€ __init__.py              # Package initialization
```

## ğŸ¯ Key Innovations

### **LLM-Driven Feature Engineering**
- **Automatic Code Generation**: LLM generates production-ready Python code
- **Domain Knowledge Integration**: Incorporates financial market expertise
- **Iterative Improvement**: Learns from previous attempts and errors
- **Error Handling**: Robust retry mechanism with error feedback


## ğŸš€ Usage
Please check out example_usage.py. Our final production version is the function example_svm_multi_ticker(). You can customize the iterative_tickers and validation_tickers there. Remember to include your anthropic API key in .env file in the root folder.
