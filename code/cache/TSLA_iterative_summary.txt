============================================================
ITERATIVE AGENT-BASED FEATURE SELECTION SUMMARY
============================================================
Stock: TSLA
Date: 2025-10-04 02:06:45
Total Iterations: 3

PERFORMANCE TREND:
----------------------------------------
Iteration 0: Baseline - MAPE: 12.73% (Baseline)
Iteration 1: Iteration 1 - MAPE: 13.81% (-1.08%)
Iteration 2: Iteration 2 - MAPE: 11.06% (+1.67%)
Iteration 3: Iteration 3 - MAPE: 12.41% (-1.36%)

Best Model: Iteration 2 - MAPE: 11.06%
Final Test MAPE: 6.62%
Final Improvement: -1.22%

============================================================
FEATURE ENGINEERING CODES
============================================================

ITERATION 1:
Performance: MAPE = 13.81%
Improvement: -1.08%
Features: 20
----------------------------------------
def construct_features(data):
    RAW_DIM = 62
    MAX_TOTAL = 20
    
    lookback_window = data.shape[0]
    features_list = []
    
    for t in range(lookback_window):
        # Extract raw features
        short_interest = data[t, 0]
        avg_volume = data[t, 1]
        
        # Reshape OHLC data
        ohlc = data[t, 2:].reshape(15, 4)
        open_prices, high_prices, low_prices, close_prices = ohlc[:, 0], ohlc[:, 1], ohlc[:, 2], ohlc[:, 3]
        
        # Keep essential raw features
        raw_keep = [short_interest, avg_volume]
        
        # Add last day OHLC as raw features (these were among top important features)
        raw_keep.append(open_prices[-1])   # Last day open
        raw_keep.append(high_prices[-1])   # Last day high
        raw_keep.append(low_prices[-1])    # Last day low
        raw_keep.append(close_prices[-1])  # Last day close
        
        # Calculate MAX_NEW based on raw features kept
        MAX_NEW = MAX_TOTAL - len(raw_keep)
        eng = []
        
        # 1. Price volatility (standard deviation of close prices)
        close_std = np.std(close_prices) if len(close_prices) > 1 else 0
        eng.append(close_std)
        
        # 2. Price momentum (close price change over the period)
        if len(close_prices) > 1:
            price_momentum = (close_prices[-1] - close_prices[0]) / (max(abs(close_prices[0]), 1e-8))
        else:
            price_momentum = 0
        eng.append(price_momentum)
        
        # 3. Average true range (ATR) - volatility indicator
        atr = 0
        if len(close_prices) > 1:
            tr_sum = 0
            for i in range(1, len(close_prices)):
                high_low = high_prices[i] - low_prices[i]
                high_close_prev = abs(high_prices[i] - close_prices[i-1])
                low_close_prev = abs(low_prices[i] - close_prices[i-1])
                tr = max(high_low, high_close_prev, low_close_prev)
                tr_sum += tr
            atr = tr_sum / (len(close_prices) - 1)
        eng.append(atr)
        
        # 4. Volume-price correlation
        vol_price_corr = 0
        if len(close_prices) > 2:
            # Create synthetic daily volumes by dividing avg_volume
            daily_volumes = np.ones(len(close_prices)) * (avg_volume / len(close_prices))
            # Calculate correlation between price changes and volume
            price_changes = np.diff(close_prices)
            vol_sample = daily_volumes[1:]
            if len(price_changes) > 1 and np.std(price_changes) > 1e-8 and np.std(vol_sample) > 1e-8:
                vol_price_corr = np.corrcoef(price_changes, vol_sample)[0, 1]
        eng.append(vol_price_corr)
        
        # 5. Relative strength index (RSI)
        rsi = 50  # Default neutral value
        if len(close_prices) > 2:
            delta = np.diff(close_prices)
            gain = np.where(delta > 0, delta, 0)
            loss = np.where(delta < 0, -delta, 0)
            avg_gain = np.mean(gain) if len(gain) > 0 else 0
            avg_loss = np.mean(loss) if len(loss) > 0 else 0
            
            if avg_loss > 1e-8:
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
            elif avg_gain > 0:
                rsi = 100
        eng.append(rsi)
        
        # 6. Price range relative to average price
        if len(close_prices) > 0:
            avg_price = np.mean(close_prices)
            price_range = (np.max(high_prices) - np.min(low_prices)) / max(abs(avg_price), 1e-8)
        else:
            price_range = 0
        eng.append(price_range)
        
        # 7. Short interest to volume ratio
        si_volume_ratio = short_interest / max(abs(avg_volume), 1e-8)
        eng.append(si_volume_ratio)
        
        # 8. Bollinger Band width (volatility measure)
        bb_width = 0
        if len(close_prices) > 1:
            sma = np.mean(close_prices)
            std = np.std(close_prices)
            bb_width = (2 * std) / max(abs(sma), 1e-8)
        eng.append(bb_width)
        
        # 9. Price acceleration (second derivative of price)
        price_accel = 0
        if len(close_prices) > 2:
            first_diff = np.diff(close_prices)
            second_diff = np.diff(first_diff)
            price_accel = np.mean(second_diff) if len(second_diff) > 0 else 0
        eng.append(price_accel)
        
        # 10. Gap analysis (average of overnight gaps)
        gap_avg = 0
        if len(close_prices) > 1 and len(open_prices) > 1:
            gaps = []
            for i in range(1, min(len(close_prices), len(open_prices))):
                gap = (open_prices[i] - close_prices[i-1]) / max(abs(close_prices[i-1]), 1e-8)
                gaps.append(gap)
            gap_avg = np.mean(gaps) if len(gaps) > 0 else 0
        eng.append(gap_avg)
        
        # 11. High-Low range to Close ratio (volatility relative to price)
        hl_close_ratio = 0
        if len(close_prices) > 0:
            hl_ranges = high_prices - low_prices
            avg_hl_range = np.mean(hl_ranges)
            avg_close = np.mean(close_prices)
            hl_close_ratio = avg_hl_range / max(abs(avg_close), 1e-8)
        eng.append(hl_close_ratio)
        
        # 12. Short interest momentum (if we have previous data)
        si_momentum = 0
        if t > 0:
            prev_si = data[t-1, 0]
            si_momentum = (short_interest - prev_si) / max(abs(prev_si), 1e-8)
        eng.append(si_momentum)
        
        # 13. Volume trend
        vol_trend = 0
        if t > 0:
            prev_vol = data[t-1, 1]
            vol_trend = (avg_volume - prev_vol) / max(abs(prev_vol), 1e-8)
        eng.append(vol_trend)
        
        # 14. Price trend consistency (directional movement)
        price_consistency = 0
        if len(close_prices) > 1:
            price_changes = np.diff(close_prices)
            pos_changes = np.sum(price_changes > 0)
            neg_changes = np.sum(price_changes < 0)
            total_changes = len(price_changes)
            if total_changes > 0:
                price_consistency = abs(pos_changes - neg_changes) / total_changes
        eng.append(price_consistency)
        
        # Ensure we don't exceed MAX_NEW
        eng = eng[:MAX_NEW]
        
        # Combine raw and engineered features
        row = np.array(raw_keep + eng, dtype=np.float32)
        
        # Pad or truncate to ensure consistent size
        if row.size < MAX_TOTAL:
            row = np.pad(row, (0, MAX_TOTAL - row.size), 'constant')
        elif row.size > MAX_TOTAL:
            row = row[:MAX_TOTAL]
            
        features_list.append(row)
    
    # Stack all rows into a 2D array
    features_array = np.stack(features_list, axis=0)
    
    # Handle NaN and infinite values
    features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
    
    return features_array
============================================================

ITERATION 2:
Performance: MAPE = 11.06%
Improvement: +1.67%
Features: 20
----------------------------------------
def construct_features(data):
    RAW_DIM = 62
    MAX_TOTAL = 20
    
    lookback_window = data.shape[0]
    features_list = []
    
    for t in range(lookback_window):
        # Extract raw features
        short_interest = data[t, 0]
        avg_volume = data[t, 1]
        
        # Reshape OHLC data
        ohlc = data[t, 2:].reshape(15, 4)
        open_prices, high_prices, low_prices, close_prices = ohlc[:, 0], ohlc[:, 1], ohlc[:, 2], ohlc[:, 3]
        
        # Keep essential raw features based on importance analysis
        # Always include short interest and volume (critical for prediction)
        raw_keep = [short_interest, avg_volume]
        
        # Add last day OHLC as raw features (these were among top important features)
        raw_keep.append(open_prices[-1])   # Last day open
        raw_keep.append(close_prices[-1])  # Last day close
        
        # Calculate MAX_NEW based on raw features kept
        MAX_NEW = MAX_TOTAL - len(raw_keep)
        eng = []
        
        # 1. Short interest to volume ratio (high importance in previous iteration)
        si_volume_ratio = short_interest / max(abs(avg_volume), 1e-8)
        eng.append(si_volume_ratio)
        
        # 2. Short interest momentum (if we have previous data)
        # This captures the trend in short interest which is directly relevant to prediction
        si_momentum = 0
        if t > 0:
            prev_si = data[t-1, 0]
            si_momentum = (short_interest - prev_si) / max(abs(prev_si), 1e-8)
        eng.append(si_momentum)
        
        # 3. Price volatility (standard deviation of close prices)
        # Improved by using normalized volatility to make it scale-invariant
        if len(close_prices) > 1 and np.mean(close_prices) != 0:
            close_std = np.std(close_prices) / max(abs(np.mean(close_prices)), 1e-8)
        else:
            close_std = 0
        eng.append(close_std)
        
        # 4. Bollinger Band width (volatility measure)
        # Refined to use more standard 2-sigma bands
        bb_width = 0
        if len(close_prices) > 1:
            sma = np.mean(close_prices)
            std = np.std(close_prices)
            bb_width = (2 * std) / max(abs(sma), 1e-8)
        eng.append(bb_width)
        
        # 5. Price momentum over different timeframes
        # Short-term momentum (last 5 days)
        short_momentum = 0
        if len(close_prices) >= 5:
            short_momentum = (close_prices[-1] - close_prices[-5]) / max(abs(close_prices[-5]), 1e-8)
        eng.append(short_momentum)
        
        # 6. Medium-term momentum (full 15 days)
        med_momentum = 0
        if len(close_prices) > 1:
            med_momentum = (close_prices[-1] - close_prices[0]) / max(abs(close_prices[0]), 1e-8)
        eng.append(med_momentum)
        
        # 7. High-Low range to Close ratio (volatility relative to price)
        # This captures intraday volatility which may correlate with short interest
        hl_close_ratio = 0
        if len(close_prices) > 0:
            hl_ranges = high_prices - low_prices
            avg_hl_range = np.mean(hl_ranges)
            avg_close = np.mean(close_prices)
            hl_close_ratio = avg_hl_range / max(abs(avg_close), 1e-8)
        eng.append(hl_close_ratio)
        
        # 8. RSI (Relative Strength Index) - momentum oscillator
        # Improved calculation with proper smoothing
        rsi = 50  # Default neutral value
        if len(close_prices) > 2:
            delta = np.diff(close_prices)
            gain = np.where(delta > 0, delta, 0)
            loss = np.where(delta < 0, -delta, 0)
            avg_gain = np.mean(gain) if len(gain) > 0 else 0
            avg_loss = np.mean(loss) if len(loss) > 0 else 0
            
            if avg_loss > 1e-8:
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
            elif avg_gain > 0:
                rsi = 100
        eng.append(rsi)
        
        # 9. Volume trend (rate of change in volume)
        vol_trend = 0
        if t > 0:
            prev_vol = data[t-1, 1]
            vol_trend = (avg_volume - prev_vol) / max(abs(prev_vol), 1e-8)
        eng.append(vol_trend)
        
        # 10. Price gap analysis (average of overnight gaps)
        # Significant gaps often indicate important market sentiment shifts
        gap_avg = 0
        if len(close_prices) > 1 and len(open_prices) > 1:
            gaps = []
            for i in range(1, min(len(close_prices), len(open_prices))):
                gap = (open_prices[i] - close_prices[i-1]) / max(abs(close_prices[i-1]), 1e-8)
                gaps.append(gap)
            gap_avg = np.mean(gaps) if len(gaps) > 0 else 0
        eng.append(gap_avg)
        
        # 11. Price trend consistency (directional movement)
        # Measures how consistent the price movement has been
        price_consistency = 0
        if len(close_prices) > 1:
            price_changes = np.diff(close_prices)
            pos_changes = np.sum(price_changes > 0)
            neg_changes = np.sum(price_changes < 0)
            total_changes = len(price_changes)
            if total_changes > 0:
                price_consistency = abs(pos_changes - neg_changes) / total_changes
        eng.append(price_consistency)
        
        # 12. Average True Range (ATR) - volatility indicator
        # Improved by normalizing to the average price
        atr = 0
        if len(close_prices) > 1:
            tr_sum = 0
            for i in range(1, len(close_prices)):
                high_low = high_prices[i] - low_prices[i]
                high_close_prev = abs(high_prices[i] - close_prices[i-1])
                low_close_prev = abs(low_prices[i] - close_prices[i-1])
                tr = max(high_low, high_close_prev, low_close_prev)
                tr_sum += tr
            avg_price = np.mean(close_prices)
            atr = (tr_sum / (len(close_prices) - 1)) / max(abs(avg_price), 1e-8)
        eng.append(atr)
        
        # 13. MACD-like indicator (difference between short and long moving averages)
        # Simplified to avoid EMA calculation issues with small sample sizes
        macd = 0
        if len(close_prices) >= 12:
            short_ma = np.mean(close_prices[-5:])
            long_ma = np.mean(close_prices[-12:])
            macd = (short_ma - long_ma) / max(abs(long_ma), 1e-8)
        eng.append(macd)
        
        # 14. Price acceleration (second derivative of price)
        # Captures the change in momentum
        price_accel = 0
        if len(close_prices) > 2:
            first_diff = np.diff(close_prices)
            second_diff = np.diff(first_diff)
            price_accel = np.mean(second_diff) if len(second_diff) > 0 else 0
            # Normalize by average price
            avg_price = np.mean(close_prices)
            price_accel = price_accel / max(abs(avg_price), 1e-8)
        eng.append(price_accel)
        
        # 15. Short interest ratio to price volatility
        # New feature: relates short interest to price volatility
        si_vol_ratio = 0
        if len(close_prices) > 1:
            price_vol = np.std(close_prices)
            si_vol_ratio = short_interest / max(price_vol, 1e-8)
        eng.append(si_vol_ratio)
        
        # 16. Normalized price range (high-low range over the period)
        # Captures the total trading range relative to average price
        norm_range = 0
        if len(high_prices) > 0 and len(low_prices) > 0:
            price_range = np.max(high_prices) - np.min(low_prices)
            avg_price = np.mean(close_prices)
            norm_range = price_range / max(abs(avg_price), 1e-8)
        eng.append(norm_range)
        
        # Ensure we don't exceed MAX_NEW
        eng = eng[:MAX_NEW]
        
        # Combine raw and engineered features
        row = np.array(raw_keep + eng, dtype=np.float32)
        
        # Pad or truncate to ensure consistent size
        if row.size < MAX_TOTAL:
            row = np.pad(row, (0, MAX_TOTAL - row.size), 'constant')
        elif row.size > MAX_TOTAL:
            row = row[:MAX_TOTAL]
            
        features_list.append(row)
    
    # Stack all rows into a 2D array
    features_array = np.stack(features_list, axis=0)
    
    # Handle NaN and infinite values
    features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
    
    return features_array
============================================================

ITERATION 3:
Performance: MAPE = 12.41%
Improvement: -1.36%
Features: 20
----------------------------------------
def construct_features(data):
    RAW_DIM = 62
    MAX_TOTAL = 20
    
    lookback_window = data.shape[0]
    features_list = []
    
    for t in range(lookback_window):
        # Extract raw features
        short_interest = data[t, 0]
        avg_volume = data[t, 1]
        
        # Reshape OHLC data
        ohlc = data[t, 2:].reshape(15, 4)
        open_prices, high_prices, low_prices, close_prices = ohlc[:, 0], ohlc[:, 1], ohlc[:, 2], ohlc[:, 3]
        
        # Keep essential raw features based on importance analysis
        # Always include short interest and volume (critical for prediction)
        raw_keep = [short_interest, avg_volume]
        
        # Add last day OHLC as raw features (these were among top important features)
        raw_keep.append(open_prices[-1])   # Last day open
        raw_keep.append(close_prices[-1])  # Last day close
        
        # Calculate MAX_NEW based on raw features kept
        MAX_NEW = MAX_TOTAL - len(raw_keep)
        eng = []
        
        # 1. Short interest to volume ratio (consistently high importance)
        si_volume_ratio = short_interest / max(abs(avg_volume), 1e-8)
        eng.append(si_volume_ratio)
        
        # 2. Short interest momentum (refined with exponential weighting)
        si_momentum = 0
        if t > 0:
            prev_si = data[t-1, 0]
            si_momentum = (short_interest - prev_si) / max(abs(prev_si), 1e-8)
            # Add exponential weighting if we have more history
            if t > 1:
                prev_prev_si = data[t-2, 0]
                si_momentum_prev = (prev_si - prev_prev_si) / max(abs(prev_prev_si), 1e-8)
                # Weighted average (0.7 current, 0.3 previous)
                si_momentum = 0.7 * si_momentum + 0.3 * si_momentum_prev
        eng.append(si_momentum)
        
        # 3. Normalized price volatility (improved with Parkinson's volatility estimator)
        # This uses high-low range which is more efficient than close-to-close
        parkinson_vol = 0
        if len(high_prices) > 1 and len(low_prices) > 1:
            # Parkinson's formula uses log of high/low ratio
            ln_hl_ratio = np.log(high_prices / np.maximum(low_prices, 1e-8))
            parkinson_vol = np.sqrt(np.sum(ln_hl_ratio**2) / (4 * np.log(2) * len(high_prices)))
            # Normalize by average price
            avg_price = np.mean(close_prices)
            parkinson_vol = parkinson_vol / max(abs(avg_price), 1e-8)
        eng.append(parkinson_vol)
        
        # 4. Price momentum with adaptive lookback
        # Adapts the lookback period based on available data
        price_momentum = 0
        if len(close_prices) > 1:
            # Use the maximum available lookback up to 10 days
            lookback = min(10, len(close_prices) - 1)
            price_momentum = (close_prices[-1] - close_prices[-lookback-1]) / max(abs(close_prices[-lookback-1]), 1e-8)
        eng.append(price_momentum)
        
        # 5. Volume-weighted price momentum
        # Weights price changes by their volume significance
        vol_weighted_momentum = 0
        if len(close_prices) > 1:
            # Create daily returns
            daily_returns = np.diff(close_prices) / np.maximum(close_prices[:-1], 1e-8)
            # Use volume data if available (otherwise equal weights)
            weights = np.ones(len(daily_returns))
            vol_weighted_momentum = np.sum(daily_returns * weights) / max(np.sum(weights), 1e-8)
        eng.append(vol_weighted_momentum)
        
        # 6. RSI with adaptive lookback (momentum oscillator)
        # More robust calculation with variable lookback
        rsi = 50  # Default neutral value
        if len(close_prices) > 2:
            # Determine lookback based on available data
            lookback = min(14, len(close_prices) - 1)
            delta = np.diff(close_prices[-lookback-1:])
            gain = np.where(delta > 0, delta, 0)
            loss = np.where(delta < 0, -delta, 0)
            avg_gain = np.mean(gain) if len(gain) > 0 else 0
            avg_loss = np.mean(loss) if len(loss) > 0 else 0
            
            if avg_loss > 1e-8:
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
            elif avg_gain > 0:
                rsi = 100
            # Normalize to [-1, 1] range for better model compatibility
            rsi = (rsi / 50) - 1
        eng.append(rsi)
        
        # 7. Short interest to price ratio
        # Relates short interest directly to price level
        si_price_ratio = 0
        if len(close_prices) > 0:
            avg_price = np.mean(close_prices)
            si_price_ratio = short_interest / max(abs(avg_price), 1e-8)
        eng.append(si_price_ratio)
        
        # 8. Gap volatility (overnight price jumps)
        # Improved by focusing on significant gaps only
        gap_volatility = 0
        if len(close_prices) > 1 and len(open_prices) > 1:
            gaps = []
            for i in range(1, min(len(close_prices), len(open_prices))):
                gap = (open_prices[i] - close_prices[i-1]) / max(abs(close_prices[i-1]), 1e-8)
                gaps.append(gap)
            if len(gaps) > 0:
                # Focus on significant gaps (>0.5%)
                sig_gaps = [g for g in gaps if abs(g) > 0.005]
                if len(sig_gaps) > 0:
                    gap_volatility = np.std(sig_gaps)
                else:
                    gap_volatility = np.std(gaps)
        eng.append(gap_volatility)
        
        # 9. Price trend strength (ADX-inspired)
        # Measures the strength of a trend regardless of direction
        trend_strength = 0
        if len(close_prices) > 2:
            # Calculate directional movement
            up_moves = []
            down_moves = []
            for i in range(1, len(close_prices)):
                up_move = high_prices[i] - high_prices[i-1]
                down_move = low_prices[i-1] - low_prices[i]
                
                if up_move > down_move and up_move > 0:
                    up_moves.append(up_move)
                else:
                    up_moves.append(0)
                    
                if down_move > up_move and down_move > 0:
                    down_moves.append(down_move)
                else:
                    down_moves.append(0)
            
            # Calculate trend strength (simplified ADX)
            if len(up_moves) > 0 and len(down_moves) > 0:
                avg_up = np.mean(up_moves)
                avg_down = np.mean(down_moves)
                avg_price_range = np.mean(high_prices - low_prices)
                
                # Normalize by price range
                if avg_price_range > 1e-8:
                    trend_strength = (avg_up + avg_down) / avg_price_range
        eng.append(trend_strength)
        
        # 10. Short interest acceleration
        # Second derivative of short interest
        si_acceleration = 0
        if t > 1:
            current_si = data[t, 0]
            prev_si = data[t-1, 0]
            prev_prev_si = data[t-2, 0]
            
            current_momentum = (current_si - prev_si) / max(abs(prev_si), 1e-8)
            prev_momentum = (prev_si - prev_prev_si) / max(abs(prev_prev_si), 1e-8)
            
            si_acceleration = (current_momentum - prev_momentum) / max(abs(prev_momentum), 1e-8)
        eng.append(si_acceleration)
        
        # 11. Normalized trading range (high-low range relative to price)
        # Improved by using median instead of mean for better robustness
        norm_range = 0
        if len(high_prices) > 0 and len(low_prices) > 0:
            daily_ranges = high_prices - low_prices
            median_price = np.median(close_prices)
            norm_range = np.mean(daily_ranges) / max(abs(median_price), 1e-8)
        eng.append(norm_range)
        
        # 12. Volume trend relative to price trend
        # Captures divergence between volume and price
        vol_price_divergence = 0
        if t > 0 and len(close_prices) > 1:
            prev_vol = data[t-1, 1]
            vol_change = (avg_volume - prev_vol) / max(abs(prev_vol), 1e-8)
            
            price_change = (close_prices[-1] - close_prices[0]) / max(abs(close_prices[0]), 1e-8)
            
            # Positive when volume and price move in opposite directions
            if abs(price_change) > 1e-8:
                vol_price_divergence = vol_change / price_change
                # Cap extreme values
                vol_price_divergence = np.clip(vol_price_divergence, -5, 5)
        eng.append(vol_price_divergence)
        
        # 13. Short interest to volatility ratio with exponential weighting
        # Relates short interest to recent volatility with more weight on recent data
        si_vol_ratio = 0
        if len(close_prices) > 1:
            # Calculate exponentially weighted volatility
            weights = np.exp(np.linspace(-1, 0, len(close_prices)))
            weights = weights / np.sum(weights)
            
            # Weighted mean and variance
            w_mean = np.sum(weights * close_prices)
            w_var = np.sum(weights * ((close_prices - w_mean) ** 2))
            w_vol = np.sqrt(w_var)
            
            si_vol_ratio = short_interest / max(w_vol, 1e-8)
        eng.append(si_vol_ratio)
        
        # 14. Price reversal indicator
        # Identifies potential reversal points using price patterns
        reversal_indicator = 0
        if len(close_prices) > 3:
            # Look for pattern where 3 consecutive days move in one direction
            # followed by a move in the opposite direction
            last_3_changes = np.diff(close_prices[-4:])
            
            # Check if last 3 days were all positive or all negative
            all_positive = np.all(last_3_changes[:-1] > 0)
            all_negative = np.all(last_3_changes[:-1] < 0)
            
            # Check if the most recent day reversed
            last_reversed = (all_positive and last_3_changes[-1] < 0) or (all_negative and last_3_changes[-1] > 0)
            
            if last_reversed:
                # Strength of reversal (normalized)
                reversal_indicator = abs(last_3_changes[-1]) / max(abs(np.mean(last_3_changes[:-1])), 1e-8)
                # Cap extreme values
                reversal_indicator = min(reversal_indicator, 3.0)
        eng.append(reversal_indicator)
        
        # 15. Intraday volatility ratio
        # Compares intraday volatility to close-to-close volatility
        intraday_ratio = 0
        if len(close_prices) > 1:
            # Intraday ranges
            intraday_ranges = high_prices - low_prices
            # Close-to-close changes
            close_changes = np.abs(np.diff(close_prices))
            
            avg_intraday = np.mean(intraday_ranges[1:])  # Skip first day to align with close_changes
            avg_close_change = np.mean(close_changes)
            
            if avg_close_change > 1e-8:
                intraday_ratio = avg_intraday / avg_close_change
                # Cap extreme values
                intraday_ratio = min(intraday_ratio, 5.0)
        eng.append(intraday_ratio)
        
        # 16. Short interest to price momentum ratio
        # Relates short interest to recent price momentum
        si_momentum_ratio = 0
        if len(close_prices) > 5:
            # Calculate 5-day momentum
            momentum_5d = (close_prices[-1] - close_prices[-6]) / max(abs(close_prices[-6]), 1e-8)
            
            # Relate short interest to momentum
            if abs(momentum_5d) > 1e-8:
                si_momentum_ratio = short_interest / max(abs(momentum_5d), 1e-8)
                # Cap extreme values
                si_momentum_ratio = np.clip(si_momentum_ratio, -100, 100)
        eng.append(si_momentum_ratio)
        
        # Ensure we don't exceed MAX_NEW
        eng = eng[:MAX_NEW]
        
        # Combine raw and engineered features
        row = np.array(raw_keep + eng, dtype=np.float32)
        
        # Pad or truncate to ensure consistent size
        if row.size < MAX_TOTAL:
            row = np.pad(row, (0, MAX_TOTAL - row.size), 'constant')
        elif row.size > MAX_TOTAL:
            row = row[:MAX_TOTAL]
            
        features_list.append(row)
    
    # Stack all rows into a 2D array
    features_array = np.stack(features_list, axis=0)
    
    # Handle NaN and infinite values
    features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
    
    return features_array
============================================================
