============================================================
ITERATIVE AGENT-BASED FEATURE SELECTION SUMMARY
============================================================
Stock: KIRK
Date: 2025-09-26 02:05:41
Total Iterations: 5

PERFORMANCE TREND:
----------------------------------------
Iteration 0: Baseline - MAPE: 7.27% (Baseline)
Iteration 1: Iteration 1 - MAPE: 13.20% (-5.93%)
Iteration 2: Iteration 2 - MAPE: 12.04% (-4.78%)
Iteration 3: Iteration 3 - MAPE: 14.03% (-6.76%)
Iteration 4: Iteration 4 - MAPE: 11.83% (-4.56%)
Iteration 5: Iteration 5 - MAPE: 16.07% (-8.80%)

Best Model: Baseline - MAPE: 7.27%

============================================================
FEATURE ENGINEERING CODES
============================================================

ITERATION 1:
Performance: MAPE = 13.20%
Improvement: -5.93%
Features: 23
----------------------------------------
def construct_features(data):
    """
    Constructs features for short interest prediction based on financial time series data.
    
    Args:
        data: numpy array of shape (lookback_window, 62) containing:
            - Feature_0: Short interest
            - Feature_1: Average daily volume
            - Features_2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize feature array
    features_list = []
    
    # Process each timestamp independently
    for t in range(lookback_window):
        timestamp_features = []
        
        # Extract key components from data
        short_interest = data[t, 0]  # Feature_0 (highest importance)
        avg_volume = data[t, 1]      # Feature_1
        
        # Extract OHLC data (reshape to 15 days x 4 OHLC values)
        ohlc_data = data[t, 2:62].reshape(15, 4)
        
        # 1. Keep original high importance features
        # Feature_0 (short interest) - highest importance
        timestamp_features.append(short_interest)
        
        # 2. Feature_56 (second highest importance) - likely a specific OHLC value
        timestamp_features.append(data[t, 56])
        
        # 3. Feature_21 and Feature_35 (high importance)
        timestamp_features.append(data[t, 21])
        timestamp_features.append(data[t, 35])
        
        # 4. Volume-based features (normalized)
        timestamp_features.append(avg_volume)
        if short_interest > 0:
            timestamp_features.append(avg_volume / short_interest)  # Volume to short interest ratio
        else:
            timestamp_features.append(0)
        
        # 5. Price-based features
        close_prices = ohlc_data[:, 3]  # Close prices
        
        # 5.1 Recent price momentum (1-day, 3-day, 5-day, 10-day)
        if len(close_prices) > 1:
            timestamp_features.append((close_prices[-1] / close_prices[-2] - 1) if close_prices[-2] != 0 else 0)  # 1-day return
        else:
            timestamp_features.append(0)
            
        if len(close_prices) > 3:
            timestamp_features.append((close_prices[-1] / close_prices[-4] - 1) if close_prices[-4] != 0 else 0)  # 3-day return
        else:
            timestamp_features.append(0)
            
        if len(close_prices) > 5:
            timestamp_features.append((close_prices[-1] / close_prices[-6] - 1) if close_prices[-6] != 0 else 0)  # 5-day return
        else:
            timestamp_features.append(0)
            
        if len(close_prices) > 10:
            timestamp_features.append((close_prices[-1] / close_prices[-11] - 1) if close_prices[-11] != 0 else 0)  # 10-day return
        else:
            timestamp_features.append(0)
        
        # 5.2 Volatility measures
        if len(close_prices) > 5:
            # 5-day volatility (standard deviation of returns)
            returns = np.diff(close_prices[-6:]) / close_prices[-6:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            timestamp_features.append(np.std(returns))
        else:
            timestamp_features.append(0)
        
        # 5.3 Price ranges and gaps
        high_prices = ohlc_data[:, 1]  # High prices
        low_prices = ohlc_data[:, 2]   # Low prices
        
        # Average daily range (High-Low) / Low - indicator of volatility
        avg_range = np.mean((high_prices - low_prices) / low_prices) if np.any(low_prices != 0) else 0
        timestamp_features.append(avg_range)
        
        # 6. Technical indicators
        # 6.1 RSI-like feature (simplified)
        if len(close_prices) > 14:
            diff = np.diff(close_prices[-15:])
            gains = np.sum(np.clip(diff, 0, None))
            losses = np.sum(np.abs(np.clip(diff, None, 0)))
            if losses > 0:
                rs = gains / losses
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100
            timestamp_features.append(rsi)
        else:
            timestamp_features.append(50)  # Default RSI
        
        # 6.2 Moving averages and crossovers
        if len(close_prices) >= 5:
            ma5 = np.mean(close_prices[-5:])
            timestamp_features.append(ma5)
            # Relative position to MA
            if close_prices[-1] > 0:
                timestamp_features.append(close_prices[-1] / ma5 - 1)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.append(np.mean(close_prices))
            timestamp_features.append(0)
            
        if len(close_prices) >= 10:
            ma10 = np.mean(close_prices[-10:])
            timestamp_features.append(ma10)
            # MA crossover indicator
            if ma5 > 0:
                timestamp_features.append(ma5 / ma10 - 1)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.append(np.mean(close_prices))
            timestamp_features.append(0)
        
        # 7. Interaction terms between high-importance features
        # Interaction between short interest and volume
        timestamp_features.append(short_interest * avg_volume)
        
        # Interaction between short interest and recent price movement
        if len(close_prices) > 1:
            recent_return = (close_prices[-1] / close_prices[-2] - 1) if close_prices[-2] != 0 else 0
            timestamp_features.append(short_interest * recent_return)
        else:
            timestamp_features.append(0)
        
        # 8. Non-linear transformations of important features
        # Log transformation of short interest (if positive)
        if short_interest > 0:
            timestamp_features.append(np.log(short_interest))
        else:
            timestamp_features.append(0)
        
        # Square root transformation of volume
        if avg_volume > 0:
            timestamp_features.append(np.sqrt(avg_volume))
        else:
            timestamp_features.append(0)
        
        # 9. Temporal features - changes in key metrics
        if t > 0:
            prev_short_interest = data[t-1, 0]
            si_change = (short_interest / prev_short_interest - 1) if prev_short_interest > 0 else 0
            timestamp_features.append(si_change)
            
            prev_volume = data[t-1, 1]
            vol_change = (avg_volume / prev_volume - 1) if prev_volume > 0 else 0
            timestamp_features.append(vol_change)
        else:
            timestamp_features.append(0)  # No previous data
            timestamp_features.append(0)
        
        features_list.append(timestamp_features)
    
    # Convert to numpy array
    features_array = np.array(features_list)
    
    # Final cleanup - handle any remaining NaN or inf values
    features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
    
    return features_array
============================================================

ITERATION 2:
Performance: MAPE = 12.04%
Improvement: -4.78%
Features: 45
----------------------------------------
def construct_features(data):
    """
    Constructs features for short interest prediction based on financial time series data.
    
    Args:
        data: numpy array of shape (lookback_window, 62) containing:
            - Feature_0: Short interest
            - Feature_1: Average daily volume
            - Features_2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Ensure data is 2D with correct dimensions
    if len(data.shape) != 2 or data.shape[1] != 62:
        # Handle incorrect input shape by returning empty array
        return np.array([])
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize feature array
    features_list = []
    
    # Process each timestamp independently
    for t in range(lookback_window):
        timestamp_features = []
        
        # Extract key components from data
        short_interest = data[t, 0]  # Feature_0 (highest importance in baseline)
        avg_volume = data[t, 1]      # Feature_1
        
        # Extract OHLC data (reshape to 15 days x 4 OHLC values)
        ohlc_data = data[t, 2:62].reshape(15, 4)
        open_prices = ohlc_data[:, 0]
        high_prices = ohlc_data[:, 1]
        low_prices = ohlc_data[:, 2]
        close_prices = ohlc_data[:, 3]
        
        # 1. Keep original high importance features from baseline model
        # Feature_0 (short interest) - highest importance
        timestamp_features.append(short_interest)
        
        # Feature_56 (second highest importance)
        timestamp_features.append(data[t, 56])
        
        # Feature_21 (third highest importance)
        timestamp_features.append(data[t, 21])
        
        # Feature_35 (fourth highest importance)
        timestamp_features.append(data[t, 35])
        
        # Feature_60 (fifth highest importance)
        timestamp_features.append(data[t, 60])
        
        # 2. Volume-based features
        # Raw volume
        timestamp_features.append(avg_volume)
        
        # Volume to short interest ratio (if short interest > 0)
        si_vol_ratio = avg_volume / short_interest if short_interest > 0 else 0
        timestamp_features.append(si_vol_ratio)
        
        # Volume trend (rate of change)
        vol_trend = np.zeros(3)
        for i in range(1, min(4, t + 1)):
            if t >= i and data[t-i, 1] > 0:
                vol_trend[i-1] = avg_volume / data[t-i, 1] - 1
        timestamp_features.extend(vol_trend)
        
        # 3. Short interest trend features
        si_trend = np.zeros(3)
        for i in range(1, min(4, t + 1)):
            if t >= i and data[t-i, 0] > 0:
                si_trend[i-1] = short_interest / data[t-i, 0] - 1
        timestamp_features.extend(si_trend)
        
        # 4. Price-based features
        # 4.1 Recent price momentum (1-day, 3-day, 7-day, 14-day)
        price_momentum = np.zeros(4)
        for i, days in enumerate([1, 3, 7, 14]):
            if len(close_prices) > days:
                price_momentum[i] = (close_prices[-1] / close_prices[-(days+1)] - 1) if close_prices[-(days+1)] != 0 else 0
        timestamp_features.extend(price_momentum)
        
        # 4.2 Volatility measures
        # Short-term volatility (5-day)
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            timestamp_features.append(np.std(returns))
        else:
            timestamp_features.append(0)
        
        # Medium-term volatility (10-day)
        if len(close_prices) >= 10:
            returns = np.diff(close_prices[-10:]) / close_prices[-10:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            timestamp_features.append(np.std(returns))
        else:
            timestamp_features.append(0)
        
        # 4.3 Price ranges and gaps
        # Average true range (ATR) - simplified version
        atr = 0
        if len(close_prices) > 1:
            ranges = []
            for i in range(1, min(15, len(close_prices))):
                tr1 = high_prices[-i] - low_prices[-i]
                tr2 = abs(high_prices[-i] - close_prices[-(i+1)]) if i < len(close_prices) else 0
                tr3 = abs(low_prices[-i] - close_prices[-(i+1)]) if i < len(close_prices) else 0
                ranges.append(max(tr1, tr2, tr3))
            atr = np.mean(ranges) if ranges else 0
        timestamp_features.append(atr)
        
        # 5. Technical indicators
        # 5.1 RSI (14-day)
        rsi = 50  # Default value
        if len(close_prices) > 14:
            diff = np.diff(close_prices[-15:])
            gains = np.sum(np.clip(diff, 0, None))
            losses = np.sum(np.abs(np.clip(diff, None, 0)))
            if losses > 0:
                rs = gains / losses
                rsi = 100 - (100 / (1 + rs))
            elif gains > 0:
                rsi = 100
        timestamp_features.append(rsi)
        
        # 5.2 Moving averages and crossovers
        ma5 = np.mean(close_prices[-5:]) if len(close_prices) >= 5 else np.mean(close_prices)
        ma10 = np.mean(close_prices[-10:]) if len(close_prices) >= 10 else np.mean(close_prices)
        ma20 = np.mean(close_prices[-15:]) if len(close_prices) >= 15 else np.mean(close_prices)
        
        # Price relative to moving averages
        if close_prices[-1] > 0:
            timestamp_features.append(close_prices[-1] / ma5 - 1)
            timestamp_features.append(close_prices[-1] / ma10 - 1)
            timestamp_features.append(close_prices[-1] / ma20 - 1)
        else:
            timestamp_features.extend([0, 0, 0])
        
        # Moving average crossovers
        timestamp_features.append(ma5 / ma10 - 1 if ma10 > 0 else 0)
        timestamp_features.append(ma5 / ma20 - 1 if ma20 > 0 else 0)
        timestamp_features.append(ma10 / ma20 - 1 if ma20 > 0 else 0)
        
        # 5.3 MACD-like indicator
        ema12 = np.mean(close_prices[-12:]) if len(close_prices) >= 12 else np.mean(close_prices)
        ema26 = np.mean(close_prices[-15:]) if len(close_prices) >= 15 else np.mean(close_prices)
        macd = ema12 - ema26
        timestamp_features.append(macd)
        
        # 5.4 Bollinger Bands
        if len(close_prices) >= 10:
            middle_band = ma10
            std_dev = np.std(close_prices[-10:])
            upper_band = middle_band + (2 * std_dev)
            lower_band = middle_band - (2 * std_dev)
            
            # Position within Bollinger Bands
            if upper_band - lower_band > 0:
                bb_position = (close_prices[-1] - lower_band) / (upper_band - lower_band)
                timestamp_features.append(bb_position)
            else:
                timestamp_features.append(0.5)  # Default middle position
            
            # Bollinger Band width
            bb_width = (upper_band - lower_band) / middle_band if middle_band > 0 else 0
            timestamp_features.append(bb_width)
        else:
            timestamp_features.extend([0.5, 0])  # Default values
        
        # 6. Interaction terms between high-importance features
        # Interaction between short interest and volume
        timestamp_features.append(short_interest * avg_volume)
        
        # Interaction between short interest and price momentum
        if len(close_prices) > 1:
            recent_return = (close_prices[-1] / close_prices[-2] - 1) if close_prices[-2] != 0 else 0
            timestamp_features.append(short_interest * recent_return)
        else:
            timestamp_features.append(0)
        
        # Interaction between short interest and volatility
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            vol = np.std(returns)
            timestamp_features.append(short_interest * vol)
        else:
            timestamp_features.append(0)
        
        # 7. Non-linear transformations of important features
        # Log transformation of short interest (if positive)
        if short_interest > 0:
            timestamp_features.append(np.log(short_interest))
        else:
            timestamp_features.append(0)
        
        # Square root transformation of volume
        if avg_volume > 0:
            timestamp_features.append(np.sqrt(avg_volume))
        else:
            timestamp_features.append(0)
        
        # 8. Temporal features - changes in key metrics
        if t > 0:
            prev_short_interest = data[t-1, 0]
            si_change = (short_interest / prev_short_interest - 1) if prev_short_interest > 0 else 0
            timestamp_features.append(si_change)
            
            prev_volume = data[t-1, 1]
            vol_change = (avg_volume / prev_volume - 1) if prev_volume > 0 else 0
            timestamp_features.append(vol_change)
        else:
            timestamp_features.extend([0, 0])
        
        # 9. Specific feature combinations based on importance analysis
        # Since Feature_0, Feature_56, Feature_21, Feature_35, Feature_60 were most important
        # Create polynomial combinations of these features
        timestamp_features.append(data[t, 0] * data[t, 56])  # Feature_0 * Feature_56
        timestamp_features.append(data[t, 0] * data[t, 21])  # Feature_0 * Feature_21
        timestamp_features.append(data[t, 56] * data[t, 21]) # Feature_56 * Feature_21
        timestamp_features.append(data[t, 35] * data[t, 60]) # Feature_35 * Feature_60
        
        # 10. Ratio features
        timestamp_features.append(data[t, 0] / data[t, 56] if data[t, 56] != 0 else 0)
        timestamp_features.append(data[t, 0] / data[t, 21] if data[t, 21] != 0 else 0)
        
        # 11. Candle pattern features
        # Doji-like pattern
        if len(close_prices) > 0 and len(open_prices) > 0:
            body_size = abs(close_prices[-1] - open_prices[-1])
            total_range = high_prices[-1] - low_prices[-1] if high_prices[-1] > low_prices[-1] else 0.001
            doji_ratio = body_size / total_range if total_range > 0 else 0
            timestamp_features.append(doji_ratio)
        else:
            timestamp_features.append(0)
        
        # Hammer/Inverted Hammer pattern
        if len(close_prices) > 0 and len(open_prices) > 0:
            body_size = abs(close_prices[-1] - open_prices[-1])
            upper_shadow = high_prices[-1] - max(close_prices[-1], open_prices[-1])
            lower_shadow = min(close_prices[-1], open_prices[-1]) - low_prices[-1]
            hammer_ratio = max(upper_shadow, lower_shadow) / body_size if body_size > 0 else 0
            timestamp_features.append(hammer_ratio)
        else:
            timestamp_features.append(0)
        
        features_list.append(timestamp_features)
    
    try:
        # Convert to numpy array
        features_array = np.array(features_list, dtype=np.float64)
        
        # Final cleanup - handle any remaining NaN or inf values
        features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
        
        return features_array
    except:
        # Fallback in case of any conversion errors
        # Return a simple array with just the most important original features
        safe_features = []
        for t in range(lookback_window):
            safe_features.append([
                data[t, 0],  # Feature_0
                data[t, 56], # Feature_56
                data[t, 21], # Feature_21
                data[t, 35], # Feature_35
                data[t, 60]  # Feature_60
            ])
        return np.array(safe_features, dtype=np.float64)
============================================================

ITERATION 3:
Performance: MAPE = 14.03%
Improvement: -6.76%
Features: 57
----------------------------------------
def construct_features(data):
    """
    Constructs features for short interest prediction based on financial time series data.
    
    Args:
        data: numpy array of shape (lookback_window, 62) containing:
            - Feature_0: Short interest
            - Feature_1: Average daily volume
            - Features_2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Ensure data is 2D with correct dimensions
    if len(data.shape) != 2 or data.shape[1] != 62:
        # Handle incorrect input shape by returning empty array
        return np.array([])
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize feature array
    features_list = []
    
    # Process each timestamp independently
    for t in range(lookback_window):
        timestamp_features = []
        
        # Extract key components from data
        short_interest = data[t, 0]  # Feature_0 (highest importance in baseline)
        avg_volume = data[t, 1]      # Feature_1
        
        # Extract OHLC data (reshape to 15 days x 4 OHLC values)
        ohlc_data = data[t, 2:62].reshape(15, 4)
        open_prices = ohlc_data[:, 0]
        high_prices = ohlc_data[:, 1]
        low_prices = ohlc_data[:, 2]
        close_prices = ohlc_data[:, 3]
        
        # 1. Keep original high importance features from baseline model
        # Analysis: The baseline model performed best, so we should prioritize these features
        # Feature_0 (short interest) - highest importance
        timestamp_features.append(short_interest)
        
        # Feature_56 (second highest importance) - corresponds to a specific OHLC value
        timestamp_features.append(data[t, 56])
        
        # Feature_21 (third highest importance) - corresponds to a specific OHLC value
        timestamp_features.append(data[t, 21])
        
        # Feature_35 (fourth highest importance) - corresponds to a specific OHLC value
        timestamp_features.append(data[t, 35])
        
        # Feature_60 (fifth highest importance) - corresponds to a specific OHLC value
        timestamp_features.append(data[t, 60])
        
        # 2. Simple transformations of the most important features
        # Analysis: Simple transformations may capture non-linear relationships
        # Log transformation of short interest (if positive)
        if short_interest > 0:
            timestamp_features.append(np.log(short_interest))
        else:
            timestamp_features.append(0)
            
        # Square root transformation of short interest
        if short_interest > 0:
            timestamp_features.append(np.sqrt(short_interest))
        else:
            timestamp_features.append(0)
            
        # Squared transformation of short interest
        timestamp_features.append(short_interest ** 2)
        
        # 3. Volume-based features
        # Raw volume
        timestamp_features.append(avg_volume)
        
        # Volume to short interest ratio (if short interest > 0)
        si_vol_ratio = avg_volume / short_interest if short_interest > 0 else 0
        timestamp_features.append(si_vol_ratio)
        
        # Log of volume (if positive)
        if avg_volume > 0:
            timestamp_features.append(np.log(avg_volume))
        else:
            timestamp_features.append(0)
            
        # Square root of volume
        if avg_volume > 0:
            timestamp_features.append(np.sqrt(avg_volume))
        else:
            timestamp_features.append(0)
        
        # 4. Short interest trend features (more focused)
        # Analysis: Temporal patterns in short interest are likely important
        si_trend = np.zeros(3)
        for i in range(1, min(4, t + 1)):
            if t >= i and data[t-i, 0] > 0:
                si_trend[i-1] = short_interest / data[t-i, 0] - 1
        timestamp_features.extend(si_trend)
        
        # 5. Price-based features (simplified from previous iteration)
        # Analysis: Focus on the most relevant price indicators
        
        # 5.1 Recent price momentum (1-day, 3-day, 7-day, 14-day)
        # Analysis: Price momentum at different timeframes can indicate sentiment
        price_momentum = np.zeros(4)
        for i, days in enumerate([1, 3, 7, 14]):
            if len(close_prices) > days:
                price_momentum[i] = (close_prices[-1] / close_prices[-(days+1)] - 1) if close_prices[-(days+1)] != 0 else 0
        timestamp_features.extend(price_momentum)
        
        # 5.2 Volatility measures
        # Analysis: Volatility often correlates with short interest changes
        # Short-term volatility (5-day)
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            timestamp_features.append(np.std(returns))
        else:
            timestamp_features.append(0)
        
        # Medium-term volatility (10-day)
        if len(close_prices) >= 10:
            returns = np.diff(close_prices[-10:]) / close_prices[-10:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            timestamp_features.append(np.std(returns))
        else:
            timestamp_features.append(0)
        
        # 6. Technical indicators (simplified and focused)
        # Analysis: Focus on the most predictive technical indicators
        
        # 6.1 Moving averages and price relative to MAs
        # Analysis: Price relative to moving averages can indicate trend strength
        ma5 = np.mean(close_prices[-5:]) if len(close_prices) >= 5 else np.mean(close_prices)
        ma10 = np.mean(close_prices[-10:]) if len(close_prices) >= 10 else np.mean(close_prices)
        ma15 = np.mean(close_prices[-15:]) if len(close_prices) >= 15 else np.mean(close_prices)
        
        # Price relative to moving averages
        if close_prices[-1] > 0:
            timestamp_features.append(close_prices[-1] / ma5 - 1)
            timestamp_features.append(close_prices[-1] / ma10 - 1)
            timestamp_features.append(close_prices[-1] / ma15 - 1)
        else:
            timestamp_features.extend([0, 0, 0])
        
        # 7. Interaction terms between high-importance features
        # Analysis: Feature interactions may capture complex relationships
        
        # Interaction between short interest and important features
        timestamp_features.append(short_interest * data[t, 56])  # SI * Feature_56
        timestamp_features.append(short_interest * data[t, 21])  # SI * Feature_21
        timestamp_features.append(short_interest * data[t, 35])  # SI * Feature_35
        timestamp_features.append(short_interest * data[t, 60])  # SI * Feature_60
        
        # Interaction between other important features
        timestamp_features.append(data[t, 56] * data[t, 21])  # Feature_56 * Feature_21
        timestamp_features.append(data[t, 35] * data[t, 60])  # Feature_35 * Feature_60
        
        # 8. Ratio features between important features
        # Analysis: Ratios can capture relative changes
        timestamp_features.append(data[t, 56] / data[t, 21] if data[t, 21] != 0 else 0)
        timestamp_features.append(data[t, 35] / data[t, 60] if data[t, 60] != 0 else 0)
        
        # 9. Short interest to price ratios
        # Analysis: Relationship between short interest and price levels
        if close_prices[-1] > 0:
            timestamp_features.append(short_interest / close_prices[-1])
        else:
            timestamp_features.append(0)
            
        # 10. Volume to price ratios
        # Analysis: Volume relative to price can indicate market interest
        if close_prices[-1] > 0:
            timestamp_features.append(avg_volume / close_prices[-1])
        else:
            timestamp_features.append(0)
        
        # 11. Price pattern features
        # Analysis: Price patterns may indicate future short interest changes
        
        # Price range relative to average
        if len(close_prices) >= 5:
            price_range = (high_prices[-1] - low_prices[-1]) / close_prices[-1] if close_prices[-1] > 0 else 0
            avg_range = np.mean([(high_prices[i] - low_prices[i]) / close_prices[i] if close_prices[i] > 0 else 0 
                                for i in range(-5, 0)])
            if avg_range > 0:
                timestamp_features.append(price_range / avg_range)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.append(0)
        
        # 12. Temporal features - changes in key metrics
        # Analysis: Rate of change in metrics can be predictive
        if t > 0:
            # Short interest change
            prev_short_interest = data[t-1, 0]
            si_change = (short_interest / prev_short_interest - 1) if prev_short_interest > 0 else 0
            timestamp_features.append(si_change)
            
            # Volume change
            prev_volume = data[t-1, 1]
            vol_change = (avg_volume / prev_volume - 1) if prev_volume > 0 else 0
            timestamp_features.append(vol_change)
            
            # Important feature changes
            timestamp_features.append((data[t, 56] / data[t-1, 56] - 1) if data[t-1, 56] != 0 else 0)
            timestamp_features.append((data[t, 21] / data[t-1, 21] - 1) if data[t-1, 21] != 0 else 0)
            timestamp_features.append((data[t, 35] / data[t-1, 35] - 1) if data[t-1, 35] != 0 else 0)
            timestamp_features.append((data[t, 60] / data[t-1, 60] - 1) if data[t-1, 60] != 0 else 0)
        else:
            timestamp_features.extend([0, 0, 0, 0, 0, 0])
        
        # 13. Exponential transformations of important features
        # Analysis: Exponential transformations can capture different relationships
        timestamp_features.append(np.exp(short_interest / 1000) if short_interest > 0 else 1)  # Scaled to avoid overflow
        timestamp_features.append(np.exp(data[t, 56] / 1000) if data[t, 56] > 0 else 1)
        
        # 14. Polynomial combinations of top features
        # Analysis: Polynomial features can capture non-linear relationships
        timestamp_features.append(short_interest ** 2 * data[t, 56])
        timestamp_features.append(short_interest * data[t, 56] ** 2)
        
        # 15. Moving average crossovers
        # Analysis: MA crossovers are important technical signals
        timestamp_features.append(ma5 / ma10 - 1 if ma10 > 0 else 0)
        timestamp_features.append(ma5 / ma15 - 1 if ma15 > 0 else 0)
        timestamp_features.append(ma10 / ma15 - 1 if ma15 > 0 else 0)
        
        # 16. Bollinger Bands
        # Analysis: Bollinger Bands can indicate volatility and potential reversals
        if len(close_prices) >= 10:
            middle_band = ma10
            std_dev = np.std(close_prices[-10:])
            upper_band = middle_band + (2 * std_dev)
            lower_band = middle_band - (2 * std_dev)
            
            # Position within Bollinger Bands
            if upper_band - lower_band > 0:
                bb_position = (close_prices[-1] - lower_band) / (upper_band - lower_band)
                timestamp_features.append(bb_position)
            else:
                timestamp_features.append(0.5)
            
            # Bollinger Band width
            bb_width = (upper_band - lower_band) / middle_band if middle_band > 0 else 0
            timestamp_features.append(bb_width)
        else:
            timestamp_features.extend([0.5, 0])
        
        # 17. Interaction between short interest and price volatility
        # Analysis: Short interest often correlates with volatility
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            vol = np.std(returns)
            timestamp_features.append(short_interest * vol)
        else:
            timestamp_features.append(0)
        
        # 18. Normalized features
        # Analysis: Normalization can help with scale issues
        # Normalize short interest by its recent max
        if t > 0:
            max_si = max([data[max(0, t-5):t+1, 0].max(), 0.001])
            timestamp_features.append(short_interest / max_si)
        else:
            timestamp_features.append(1.0)
        
        # 19. Directional features
        # Analysis: Direction of change can be predictive
        if t > 0:
            # Short interest direction
            si_direction = 1 if short_interest > data[t-1, 0] else (-1 if short_interest < data[t-1, 0] else 0)
            timestamp_features.append(si_direction)
            
            # Volume direction
            vol_direction = 1 if avg_volume > data[t-1, 1] else (-1 if avg_volume < data[t-1, 1] else 0)
            timestamp_features.append(vol_direction)
            
            # Price direction
            if len(close_prices) > 1:
                price_direction = 1 if close_prices[-1] > close_prices[-2] else (-1 if close_prices[-1] < close_prices[-2] else 0)
                timestamp_features.append(price_direction)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.extend([0, 0, 0])
        
        # 20. Acceleration features
        # Analysis: Acceleration (change in rate of change) can indicate momentum shifts
        if t > 1:
            # Short interest acceleration
            si_change_t = (data[t, 0] / data[t-1, 0] - 1) if data[t-1, 0] > 0 else 0
            si_change_t_1 = (data[t-1, 0] / data[t-2, 0] - 1) if data[t-2, 0] > 0 else 0
            si_accel = si_change_t - si_change_t_1
            timestamp_features.append(si_accel)
            
            # Volume acceleration
            vol_change_t = (data[t, 1] / data[t-1, 1] - 1) if data[t-1, 1] > 0 else 0
            vol_change_t_1 = (data[t-1, 1] / data[t-2, 1] - 1) if data[t-2, 1] > 0 else 0
            vol_accel = vol_change_t - vol_change_t_1
            timestamp_features.append(vol_accel)
        else:
            timestamp_features.extend([0, 0])
        
        features_list.append(timestamp_features)
    
    try:
        # Convert to numpy array
        features_array = np.array(features_list, dtype=np.float64)
        
        # Final cleanup - handle any remaining NaN or inf values
        features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
        
        return features_array
    except:
        # Fallback in case of any conversion errors
        # Return a simple array with just the most important original features
        safe_features = []
        for t in range(lookback_window):
            safe_features.append([
                data[t, 0],   # Feature_0
                data[t, 56],  # Feature_56
                data[t, 21],  # Feature_21
                data[t, 35],  # Feature_35
                data[t, 60]   # Feature_60
            ])
        return np.array(safe_features, dtype=np.float64)
============================================================

ITERATION 4:
Performance: MAPE = 11.83%
Improvement: -4.56%
Features: 62
----------------------------------------
def construct_features(data):
    """
    Constructs features for short interest prediction based on financial time series data.
    
    Args:
        data: numpy array of shape (lookback_window, 62) containing:
            - Feature_0: Short interest
            - Feature_1: Average daily volume
            - Features_2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Ensure data is 2D with correct dimensions
    if len(data.shape) != 2 or data.shape[1] != 62:
        # Handle incorrect input shape by returning empty array
        return np.array([])
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize feature array
    features_list = []
    
    # Process each timestamp independently
    for t in range(lookback_window):
        timestamp_features = []
        
        # Extract key components from data
        short_interest = data[t, 0]  # Feature_0 (highest importance in baseline)
        avg_volume = data[t, 1]      # Feature_1
        
        # Extract OHLC data (reshape to 15 days x 4 OHLC values)
        ohlc_data = data[t, 2:62].reshape(15, 4)
        open_prices = ohlc_data[:, 0]
        high_prices = ohlc_data[:, 1]
        low_prices = ohlc_data[:, 2]
        close_prices = ohlc_data[:, 3]
        
        # 1. BASELINE IMPORTANT FEATURES
        # Analysis: The baseline model had the best performance (7.27% MAPE), so we prioritize its top features
        # Feature_0 (short interest) - highest importance
        timestamp_features.append(short_interest)
        
        # Feature_56 (second highest importance) - corresponds to a specific OHLC value
        # This is day 14, index 0 (Open price of the most recent day)
        timestamp_features.append(data[t, 56])
        
        # Feature_21 (third highest importance) - corresponds to a specific OHLC value
        # This is day 5, index 1 (High price from 10 days ago)
        timestamp_features.append(data[t, 21])
        
        # Feature_35 (fourth highest importance) - corresponds to a specific OHLC value
        # This is day 8, index 3 (Close price from 7 days ago)
        timestamp_features.append(data[t, 35])
        
        # Feature_60 (fifth highest importance) - corresponds to a specific OHLC value
        # This is day 15, index 0 (Open price of the most recent day)
        timestamp_features.append(data[t, 60])
        
        # 2. SHORT INTEREST FEATURES
        # Raw short interest (already added above)
        
        # Short interest change rate (if previous data available)
        if t > 0 and data[t-1, 0] > 0:
            si_change = short_interest / data[t-1, 0] - 1
        else:
            si_change = 0
        timestamp_features.append(si_change)
        
        # Short interest acceleration (change in change rate)
        if t > 1 and data[t-2, 0] > 0 and data[t-1, 0] > 0:
            prev_si_change = data[t-1, 0] / data[t-2, 0] - 1
            si_accel = si_change - prev_si_change
        else:
            si_accel = 0
        timestamp_features.append(si_accel)
        
        # 3. VOLUME FEATURES
        # Raw volume
        timestamp_features.append(avg_volume)
        
        # Volume to short interest ratio (if short interest > 0)
        si_vol_ratio = avg_volume / short_interest if short_interest > 0 else 0
        timestamp_features.append(si_vol_ratio)
        
        # Volume change rate
        if t > 0 and data[t-1, 1] > 0:
            vol_change = avg_volume / data[t-1, 1] - 1
        else:
            vol_change = 0
        timestamp_features.append(vol_change)
        
        # 4. PRICE FEATURES
        # Most recent prices
        if len(close_prices) > 0:
            timestamp_features.append(close_prices[-1])  # Most recent close
        else:
            timestamp_features.append(0)
            
        # Price momentum at different timeframes
        for days in [1, 3, 7, 14]:
            if len(close_prices) > days:
                momentum = close_prices[-1] / close_prices[-(days+1)] - 1 if close_prices[-(days+1)] != 0 else 0
                timestamp_features.append(momentum)
            else:
                timestamp_features.append(0)
        
        # 5. VOLATILITY FEATURES
        # Short-term volatility (5-day)
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            timestamp_features.append(np.std(returns))
        else:
            timestamp_features.append(0)
        
        # Medium-term volatility (10-day)
        if len(close_prices) >= 10:
            returns = np.diff(close_prices[-10:]) / close_prices[-10:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            timestamp_features.append(np.std(returns))
        else:
            timestamp_features.append(0)
            
        # High-Low range volatility
        if len(high_prices) >= 5 and len(low_prices) >= 5:
            hl_ranges = (high_prices[-5:] - low_prices[-5:]) / low_prices[-5:]
            hl_ranges = np.nan_to_num(hl_ranges, nan=0.0)
            timestamp_features.append(np.mean(hl_ranges))
            timestamp_features.append(np.std(hl_ranges))
        else:
            timestamp_features.extend([0, 0])
        
        # 6. MOVING AVERAGES
        # Calculate moving averages
        ma5 = np.mean(close_prices[-5:]) if len(close_prices) >= 5 else np.mean(close_prices) if len(close_prices) > 0 else 0
        ma10 = np.mean(close_prices[-10:]) if len(close_prices) >= 10 else np.mean(close_prices) if len(close_prices) > 0 else 0
        ma15 = np.mean(close_prices[-15:]) if len(close_prices) >= 15 else np.mean(close_prices) if len(close_prices) > 0 else 0
        
        # Price relative to moving averages
        if len(close_prices) > 0 and close_prices[-1] > 0:
            timestamp_features.append(close_prices[-1] / ma5 - 1 if ma5 > 0 else 0)
            timestamp_features.append(close_prices[-1] / ma10 - 1 if ma10 > 0 else 0)
            timestamp_features.append(close_prices[-1] / ma15 - 1 if ma15 > 0 else 0)
        else:
            timestamp_features.extend([0, 0, 0])
        
        # Moving average crossovers
        timestamp_features.append(ma5 / ma10 - 1 if ma10 > 0 else 0)
        timestamp_features.append(ma5 / ma15 - 1 if ma15 > 0 else 0)
        timestamp_features.append(ma10 / ma15 - 1 if ma15 > 0 else 0)
        
        # 7. TECHNICAL INDICATORS
        # RSI (Relative Strength Index) - 14-day
        if len(close_prices) >= 15:
            diff = np.diff(close_prices[-15:])
            gains = np.sum(np.clip(diff, 0, None))
            losses = np.sum(np.abs(np.clip(diff, None, 0)))
            
            if losses > 0:
                rs = gains / losses
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100 if gains > 0 else 50
                
            timestamp_features.append(rsi)
            # RSI normalized to [-1, 1] range
            timestamp_features.append((rsi - 50) / 50)
        else:
            timestamp_features.extend([50, 0])
        
        # Bollinger Bands
        if len(close_prices) >= 10:
            middle_band = ma10
            std_dev = np.std(close_prices[-10:])
            upper_band = middle_band + (2 * std_dev)
            lower_band = middle_band - (2 * std_dev)
            
            # Position within Bollinger Bands
            if upper_band - lower_band > 0 and len(close_prices) > 0:
                bb_position = (close_prices[-1] - lower_band) / (upper_band - lower_band)
                timestamp_features.append(bb_position)
            else:
                timestamp_features.append(0.5)
            
            # Bollinger Band width
            bb_width = (upper_band - lower_band) / middle_band if middle_band > 0 else 0
            timestamp_features.append(bb_width)
        else:
            timestamp_features.extend([0.5, 0])
        
        # 8. INTERACTION TERMS
        # Interaction between short interest and important features
        timestamp_features.append(short_interest * data[t, 56])  # SI * Feature_56
        timestamp_features.append(short_interest * data[t, 21])  # SI * Feature_21
        timestamp_features.append(short_interest * data[t, 35])  # SI * Feature_35
        timestamp_features.append(short_interest * data[t, 60])  # SI * Feature_60
        
        # Interaction between short interest and volume
        timestamp_features.append(short_interest * avg_volume)
        
        # Interaction between short interest and volatility
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            vol = np.std(returns)
            timestamp_features.append(short_interest * vol)
        else:
            timestamp_features.append(0)
        
        # 9. RATIO FEATURES
        # Short interest to price ratio
        if len(close_prices) > 0 and close_prices[-1] > 0:
            timestamp_features.append(short_interest / close_prices[-1])
        else:
            timestamp_features.append(0)
        
        # Volume to price ratio
        if len(close_prices) > 0 and close_prices[-1] > 0:
            timestamp_features.append(avg_volume / close_prices[-1])
        else:
            timestamp_features.append(0)
        
        # 10. TREND FEATURES
        # Price trend strength
        if len(close_prices) >= 10:
            # Linear regression slope of prices
            x = np.arange(10)
            y = close_prices[-10:]
            mean_x = np.mean(x)
            mean_y = np.mean(y)
            
            # Calculate slope using covariance / variance
            numerator = np.sum((x - mean_x) * (y - mean_y))
            denominator = np.sum((x - mean_x) ** 2)
            
            slope = numerator / denominator if denominator != 0 else 0
            # Normalize slope by average price
            norm_slope = slope / mean_y if mean_y != 0 else 0
            timestamp_features.append(norm_slope)
        else:
            timestamp_features.append(0)
        
        # 11. SPECIFIC OHLC PATTERNS
        # Gap up/down
        if len(open_prices) >= 2 and len(close_prices) >= 2:
            gap = (open_prices[-1] - close_prices[-2]) / close_prices[-2] if close_prices[-2] > 0 else 0
            timestamp_features.append(gap)
        else:
            timestamp_features.append(0)
        
        # Doji pattern (open ≈ close)
        if len(open_prices) > 0 and len(close_prices) > 0 and open_prices[-1] > 0:
            doji = abs(open_prices[-1] - close_prices[-1]) / open_prices[-1]
            timestamp_features.append(1 - doji)  # Higher value means closer to doji
        else:
            timestamp_features.append(0)
        
        # 12. VOLUME PATTERNS
        # Volume trend
        if len(close_prices) >= 5:
            # Extract volumes for the last 5 days
            recent_volumes = np.array([avg_volume])
            if t > 0:
                for i in range(1, min(5, t + 1)):
                    recent_volumes = np.append(recent_volumes, data[t-i, 1])
            
            # Volume trend (simple linear regression slope)
            if len(recent_volumes) > 1:
                x = np.arange(len(recent_volumes))
                mean_x = np.mean(x)
                mean_vol = np.mean(recent_volumes)
                
                numerator = np.sum((x - mean_x) * (recent_volumes - mean_vol))
                denominator = np.sum((x - mean_x) ** 2)
                
                vol_slope = numerator / denominator if denominator != 0 else 0
                # Normalize by average volume
                norm_vol_slope = vol_slope / mean_vol if mean_vol != 0 else 0
                timestamp_features.append(norm_vol_slope)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.append(0)
        
        # 13. NORMALIZED FEATURES
        # Normalize short interest by its recent max
        if t > 0:
            max_si = max([data[max(0, t-5):t+1, 0].max(), 0.001])
            timestamp_features.append(short_interest / max_si)
        else:
            timestamp_features.append(1.0)
        
        # Normalize volume by its recent max
        if t > 0:
            max_vol = max([data[max(0, t-5):t+1, 1].max(), 0.001])
            timestamp_features.append(avg_volume / max_vol)
        else:
            timestamp_features.append(1.0)
        
        # 14. DIRECTIONAL FEATURES
        # Short interest direction
        if t > 0:
            si_direction = 1 if short_interest > data[t-1, 0] else (-1 if short_interest < data[t-1, 0] else 0)
            timestamp_features.append(si_direction)
        else:
            timestamp_features.append(0)
        
        # Volume direction
        if t > 0:
            vol_direction = 1 if avg_volume > data[t-1, 1] else (-1 if avg_volume < data[t-1, 1] else 0)
            timestamp_features.append(vol_direction)
        else:
            timestamp_features.append(0)
        
        # Price direction
        if len(close_prices) > 1:
            price_direction = 1 if close_prices[-1] > close_prices[-2] else (-1 if close_prices[-1] < close_prices[-2] else 0)
            timestamp_features.append(price_direction)
        else:
            timestamp_features.append(0)
        
        # 15. SPECIFIC OHLC VALUES
        # We include specific OHLC values that were important in the baseline model
        # Most recent day's OHLC
        if len(ohlc_data) > 0:
            timestamp_features.extend(ohlc_data[-1])  # Last day's OHLC
        else:
            timestamp_features.extend([0, 0, 0, 0])
        
        # Day 5's High (Feature_21 was important)
        if len(ohlc_data) >= 5:
            timestamp_features.append(ohlc_data[4, 1])  # Day 5's High
        else:
            timestamp_features.append(0)
        
        # Day 8's Close (Feature_35 was important)
        if len(ohlc_data) >= 8:
            timestamp_features.append(ohlc_data[7, 3])  # Day 8's Close
        else:
            timestamp_features.append(0)
        
        # 16. STATISTICAL FEATURES
        # Z-score of short interest relative to recent history
        if t >= 3:
            recent_si = data[max(0, t-5):t, 0]
            si_mean = np.mean(recent_si)
            si_std = np.std(recent_si)
            si_zscore = (short_interest - si_mean) / si_std if si_std > 0 else 0
            timestamp_features.append(si_zscore)
        else:
            timestamp_features.append(0)
        
        # Z-score of volume relative to recent history
        if t >= 3:
            recent_vol = data[max(0, t-5):t, 1]
            vol_mean = np.mean(recent_vol)
            vol_std = np.std(recent_vol)
            vol_zscore = (avg_volume - vol_mean) / vol_std if vol_std > 0 else 0
            timestamp_features.append(vol_zscore)
        else:
            timestamp_features.append(0)
        
        # 17. MOMENTUM OSCILLATORS
        # Stochastic Oscillator
        if len(high_prices) >= 14 and len(low_prices) >= 14 and len(close_prices) >= 1:
            highest_high = np.max(high_prices[-14:])
            lowest_low = np.min(low_prices[-14:])
            
            if highest_high - lowest_low > 0:
                k_percent = 100 * (close_prices[-1] - lowest_low) / (highest_high - lowest_low)
            else:
                k_percent = 50
                
            timestamp_features.append(k_percent / 100)  # Normalized to [0,1]
        else:
            timestamp_features.append(0.5)
        
        # 18. ADVANCED INTERACTION TERMS
        # Interaction between short interest change and price momentum
        if t > 0 and data[t-1, 0] > 0 and len(close_prices) > 5:
            si_change = short_interest / data[t-1, 0] - 1
            price_momentum = close_prices[-1] / close_prices[-5] - 1 if close_prices[-5] > 0 else 0
            timestamp_features.append(si_change * price_momentum)
        else:
            timestamp_features.append(0)
        
        # Interaction between volume change and price momentum
        if t > 0 and data[t-1, 1] > 0 and len(close_prices) > 5:
            vol_change = avg_volume / data[t-1, 1] - 1
            price_momentum = close_prices[-1] / close_prices[-5] - 1 if close_prices[-5] > 0 else 0
            timestamp_features.append(vol_change * price_momentum)
        else:
            timestamp_features.append(0)
        
        # 19. TEMPORAL FEATURES
        # Days since significant short interest change
        if t > 0:
            days_since_change = 0
            threshold = 0.05  # 5% change
            
            for i in range(1, min(lookback_window, t + 1)):
                if t-i >= 0 and data[t-i, 0] > 0:
                    change = abs(data[t-i+1, 0] / data[t-i, 0] - 1)
                    if change > threshold:
                        days_since_change = i
                        break
            
            timestamp_features.append(days_since_change / lookback_window)  # Normalized
        else:
            timestamp_features.append(0)
        
        # 20. POLYNOMIAL FEATURES OF TOP IMPORTANCE
        # Square of short interest (Feature_0)
        timestamp_features.append(short_interest ** 2)
        
        # Square of Feature_56
        timestamp_features.append(data[t, 56] ** 2)
        
        # Square root of short interest
        timestamp_features.append(np.sqrt(abs(short_interest)))
        
        # Log of short interest (if positive)
        if short_interest > 0:
            timestamp_features.append(np.log(short_interest))
        else:
            timestamp_features.append(0)
        
        features_list.append(timestamp_features)
    
    try:
        # Convert to numpy array
        features_array = np.array(features_list, dtype=np.float64)
        
        # Final cleanup - handle any remaining NaN or inf values
        features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
        
        return features_array
    except:
        # Fallback in case of any conversion errors
        # Return a simple array with just the most important original features
        safe_features = []
        for t in range(lookback_window):
            safe_features.append([
                data[t, 0],   # Feature_0
                data[t, 56],  # Feature_56
                data[t, 21],  # Feature_21
                data[t, 35],  # Feature_35
                data[t, 60]   # Feature_60
            ])
        return np.array(safe_features, dtype=np.float64)
============================================================

ITERATION 5:
Performance: MAPE = 16.07%
Improvement: -8.80%
Features: 60
----------------------------------------
def construct_features(data):
    """
    Constructs features for short interest prediction based on financial time series data.
    
    Args:
        data: numpy array of shape (lookback_window, 62) containing:
            - Feature_0: Short interest
            - Feature_1: Average daily volume
            - Features_2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Ensure data is 2D with correct dimensions
    if len(data.shape) != 2 or data.shape[1] != 62:
        # Handle incorrect input shape by returning empty array
        return np.array([])
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize feature array
    features_list = []
    
    # Process each timestamp independently
    for t in range(lookback_window):
        timestamp_features = []
        
        # Extract key components from data
        short_interest = data[t, 0]  # Feature_0 (highest importance in baseline)
        avg_volume = data[t, 1]      # Feature_1
        
        # Extract OHLC data (reshape to 15 days x 4 OHLC values)
        ohlc_data = data[t, 2:62].reshape(15, 4)
        open_prices = ohlc_data[:, 0]
        high_prices = ohlc_data[:, 1]
        low_prices = ohlc_data[:, 2]
        close_prices = ohlc_data[:, 3]
        
        # =====================================================================
        # 1. BASELINE IMPORTANT FEATURES - KEEP THESE AS THEY WERE IN THE BEST MODEL
        # =====================================================================
        # Analysis: The baseline model had the best performance (7.27% MAPE), so we prioritize its top features
        # Feature_0 (short interest) - highest importance
        timestamp_features.append(short_interest)
        
        # Feature_56 (second highest importance) - corresponds to a specific OHLC value
        # This is day 14, index 0 (Open price of the most recent day)
        timestamp_features.append(data[t, 56])
        
        # Feature_21 (third highest importance) - corresponds to a specific OHLC value
        # This is day 5, index 1 (High price from 10 days ago)
        timestamp_features.append(data[t, 21])
        
        # Feature_35 (fourth highest importance) - corresponds to a specific OHLC value
        # This is day 8, index 3 (Close price from 7 days ago)
        timestamp_features.append(data[t, 35])
        
        # Feature_60 (fifth highest importance) - corresponds to a specific OHLC value
        # This is day 15, index 0 (Open price of the most recent day)
        timestamp_features.append(data[t, 60])
        
        # =====================================================================
        # 2. ENHANCED SHORT INTEREST FEATURES
        # =====================================================================
        # Short interest change rate (if previous data available)
        if t > 0 and data[t-1, 0] > 0:
            si_change = short_interest / data[t-1, 0] - 1
        else:
            si_change = 0
        timestamp_features.append(si_change)
        
        # Short interest acceleration (change in change rate)
        if t > 1 and data[t-2, 0] > 0 and data[t-1, 0] > 0:
            prev_si_change = data[t-1, 0] / data[t-2, 0] - 1
            si_accel = si_change - prev_si_change
        else:
            si_accel = 0
        timestamp_features.append(si_accel)
        
        # Short interest moving average (3-period)
        si_history = [short_interest]
        for i in range(1, min(3, t + 1)):
            si_history.append(data[t-i, 0])
        si_ma3 = np.mean(si_history)
        timestamp_features.append(si_ma3)
        
        # Short interest relative to its moving average
        si_rel_ma = short_interest / si_ma3 - 1 if si_ma3 > 0 else 0
        timestamp_features.append(si_rel_ma)
        
        # =====================================================================
        # 3. VOLUME FEATURES - REFINED FROM PREVIOUS ITERATIONS
        # =====================================================================
        # Raw volume
        timestamp_features.append(avg_volume)
        
        # Volume to short interest ratio (if short interest > 0)
        si_vol_ratio = avg_volume / short_interest if short_interest > 0 else 0
        timestamp_features.append(si_vol_ratio)
        
        # Volume change rate
        if t > 0 and data[t-1, 1] > 0:
            vol_change = avg_volume / data[t-1, 1] - 1
        else:
            vol_change = 0
        timestamp_features.append(vol_change)
        
        # Volume moving average (3-period)
        vol_history = [avg_volume]
        for i in range(1, min(3, t + 1)):
            vol_history.append(data[t-i, 1])
        vol_ma3 = np.mean(vol_history)
        timestamp_features.append(vol_ma3)
        
        # Volume relative to its moving average
        vol_rel_ma = avg_volume / vol_ma3 - 1 if vol_ma3 > 0 else 0
        timestamp_features.append(vol_rel_ma)
        
        # =====================================================================
        # 4. PRICE FEATURES - FOCUSED ON MOST RECENT AND IMPORTANT TIMEFRAMES
        # =====================================================================
        # Most recent prices
        if len(close_prices) > 0:
            timestamp_features.append(close_prices[-1])  # Most recent close
        else:
            timestamp_features.append(0)
            
        # Price momentum at different timeframes (focusing on shorter timeframes)
        for days in [1, 3, 5]:
            if len(close_prices) > days:
                momentum = close_prices[-1] / close_prices[-(days+1)] - 1 if close_prices[-(days+1)] != 0 else 0
                timestamp_features.append(momentum)
            else:
                timestamp_features.append(0)
        
        # =====================================================================
        # 5. VOLATILITY FEATURES - REFINED TO CAPTURE DIFFERENT ASPECTS
        # =====================================================================
        # Short-term volatility (5-day)
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            st_vol = np.std(returns)
            timestamp_features.append(st_vol)
        else:
            timestamp_features.append(0)
        
        # High-Low range volatility (5-day)
        if len(high_prices) >= 5 and len(low_prices) >= 5:
            hl_ranges = (high_prices[-5:] - low_prices[-5:]) / low_prices[-5:]
            hl_ranges = np.nan_to_num(hl_ranges, nan=0.0)
            hl_vol = np.mean(hl_ranges)
            timestamp_features.append(hl_vol)
        else:
            timestamp_features.append(0)
        
        # Volatility trend (change in volatility)
        if t > 0 and len(close_prices) >= 5:
            prev_returns = []
            if t > 0 and len(data[t-1, 2:62].reshape(15, 4)[:, 3]) >= 5:
                prev_close = data[t-1, 2:62].reshape(15, 4)[:, 3]
                prev_returns = np.diff(prev_close[-5:]) / prev_close[-5:-1]
                prev_returns = np.nan_to_num(prev_returns, nan=0.0)
            
            if len(prev_returns) > 0:
                prev_vol = np.std(prev_returns)
                vol_change = st_vol / prev_vol - 1 if prev_vol > 0 else 0
                timestamp_features.append(vol_change)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 6. MOVING AVERAGES - FOCUSED ON SHORTER TIMEFRAMES
        # =====================================================================
        # Calculate moving averages
        ma5 = np.mean(close_prices[-5:]) if len(close_prices) >= 5 else np.mean(close_prices) if len(close_prices) > 0 else 0
        ma10 = np.mean(close_prices[-10:]) if len(close_prices) >= 10 else np.mean(close_prices) if len(close_prices) > 0 else 0
        
        # Price relative to moving averages
        if len(close_prices) > 0 and close_prices[-1] > 0:
            timestamp_features.append(close_prices[-1] / ma5 - 1 if ma5 > 0 else 0)
            timestamp_features.append(close_prices[-1] / ma10 - 1 if ma10 > 0 else 0)
        else:
            timestamp_features.extend([0, 0])
        
        # Moving average crossover
        timestamp_features.append(ma5 / ma10 - 1 if ma10 > 0 else 0)
        
        # =====================================================================
        # 7. TECHNICAL INDICATORS - SIMPLIFIED AND FOCUSED
        # =====================================================================
        # RSI (Relative Strength Index) - 14-day
        if len(close_prices) >= 14:
            diff = np.diff(close_prices[-14:])
            gains = np.sum(np.clip(diff, 0, None))
            losses = np.sum(np.abs(np.clip(diff, None, 0)))
            
            if losses > 0:
                rs = gains / losses
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100 if gains > 0 else 50
                
            # RSI normalized to [-1, 1] range
            timestamp_features.append((rsi - 50) / 50)
        else:
            timestamp_features.append(0)
        
        # Bollinger Bands - Position within bands
        if len(close_prices) >= 10:
            middle_band = ma10
            std_dev = np.std(close_prices[-10:])
            upper_band = middle_band + (2 * std_dev)
            lower_band = middle_band - (2 * std_dev)
            
            # Position within Bollinger Bands
            if upper_band - lower_band > 0 and len(close_prices) > 0:
                bb_position = (close_prices[-1] - lower_band) / (upper_band - lower_band)
                timestamp_features.append(bb_position)
            else:
                timestamp_features.append(0.5)
        else:
            timestamp_features.append(0.5)
        
        # =====================================================================
        # 8. INTERACTION TERMS - FOCUSED ON BASELINE IMPORTANT FEATURES
        # =====================================================================
        # Interaction between short interest and important features from baseline
        timestamp_features.append(short_interest * data[t, 56])  # SI * Feature_56
        timestamp_features.append(short_interest * data[t, 21])  # SI * Feature_21
        timestamp_features.append(short_interest * data[t, 35])  # SI * Feature_35
        
        # Interaction between short interest and volume
        timestamp_features.append(short_interest * avg_volume)
        
        # Interaction between short interest change and volume change
        timestamp_features.append(si_change * vol_change)
        
        # =====================================================================
        # 9. RATIO FEATURES - SIMPLIFIED FROM PREVIOUS ITERATIONS
        # =====================================================================
        # Short interest to price ratio
        if len(close_prices) > 0 and close_prices[-1] > 0:
            timestamp_features.append(short_interest / close_prices[-1])
        else:
            timestamp_features.append(0)
        
        # Volume to price ratio
        if len(close_prices) > 0 and close_prices[-1] > 0:
            timestamp_features.append(avg_volume / close_prices[-1])
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 10. TREND FEATURES - FOCUSED ON SHORTER TIMEFRAMES
        # =====================================================================
        # Price trend strength (5-day)
        if len(close_prices) >= 5:
            # Linear regression slope of prices
            x = np.arange(5)
            y = close_prices[-5:]
            mean_x = np.mean(x)
            mean_y = np.mean(y)
            
            # Calculate slope using covariance / variance
            numerator = np.sum((x - mean_x) * (y - mean_y))
            denominator = np.sum((x - mean_x) ** 2)
            
            slope = numerator / denominator if denominator != 0 else 0
            # Normalize slope by average price
            norm_slope = slope / mean_y if mean_y != 0 else 0
            timestamp_features.append(norm_slope)
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 11. SPECIFIC OHLC PATTERNS - FOCUSED ON RECENT DAYS
        # =====================================================================
        # Gap up/down
        if len(open_prices) >= 2 and len(close_prices) >= 2:
            gap = (open_prices[-1] - close_prices[-2]) / close_prices[-2] if close_prices[-2] > 0 else 0
            timestamp_features.append(gap)
        else:
            timestamp_features.append(0)
        
        # Doji pattern (open ≈ close)
        if len(open_prices) > 0 and len(close_prices) > 0 and open_prices[-1] > 0:
            doji = abs(open_prices[-1] - close_prices[-1]) / open_prices[-1]
            timestamp_features.append(1 - doji)  # Higher value means closer to doji
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 12. NORMALIZED FEATURES - FOCUSED ON SHORT INTEREST
        # =====================================================================
        # Normalize short interest by its recent max
        if t > 0:
            max_si = max([data[max(0, t-5):t+1, 0].max(), 0.001])
            timestamp_features.append(short_interest / max_si)
        else:
            timestamp_features.append(1.0)
        
        # Z-score of short interest relative to recent history
        if t >= 3:
            recent_si = data[max(0, t-5):t, 0]
            si_mean = np.mean(recent_si)
            si_std = np.std(recent_si)
            si_zscore = (short_interest - si_mean) / si_std if si_std > 0 else 0
            timestamp_features.append(si_zscore)
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 13. DIRECTIONAL FEATURES - SIMPLIFIED
        # =====================================================================
        # Short interest direction
        if t > 0:
            si_direction = 1 if short_interest > data[t-1, 0] else (-1 if short_interest < data[t-1, 0] else 0)
            timestamp_features.append(si_direction)
        else:
            timestamp_features.append(0)
        
        # Price direction
        if len(close_prices) > 1:
            price_direction = 1 if close_prices[-1] > close_prices[-2] else (-1 if close_prices[-1] < close_prices[-2] else 0)
            timestamp_features.append(price_direction)
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 14. SPECIFIC OHLC VALUES FROM BASELINE IMPORTANT FEATURES
        # =====================================================================
        # Most recent day's OHLC
        if len(ohlc_data) > 0:
            timestamp_features.extend(ohlc_data[-1])  # Last day's OHLC
        else:
            timestamp_features.extend([0, 0, 0, 0])
        
        # Day 5's High (Feature_21 was important)
        if len(ohlc_data) >= 5:
            timestamp_features.append(ohlc_data[4, 1])  # Day 5's High
        else:
            timestamp_features.append(0)
        
        # Day 8's Close (Feature_35 was important)
        if len(ohlc_data) >= 8:
            timestamp_features.append(ohlc_data[7, 3])  # Day 8's Close
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 15. POLYNOMIAL FEATURES OF TOP IMPORTANCE - FOCUSED ON BASELINE
        # =====================================================================
        # Square of short interest (Feature_0)
        timestamp_features.append(short_interest ** 2)
        
        # Square of Feature_56
        timestamp_features.append(data[t, 56] ** 2)
        
        # Square root of short interest
        timestamp_features.append(np.sqrt(abs(short_interest)))
        
        # Log of short interest (if positive)
        if short_interest > 0:
            timestamp_features.append(np.log(short_interest))
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 16. MOMENTUM OSCILLATORS - SIMPLIFIED
        # =====================================================================
        # Stochastic Oscillator
        if len(high_prices) >= 14 and len(low_prices) >= 14 and len(close_prices) >= 1:
            highest_high = np.max(high_prices[-14:])
            lowest_low = np.min(low_prices[-14:])
            
            if highest_high - lowest_low > 0:
                k_percent = 100 * (close_prices[-1] - lowest_low) / (highest_high - lowest_low)
            else:
                k_percent = 50
                
            timestamp_features.append(k_percent / 100)  # Normalized to [0,1]
        else:
            timestamp_features.append(0.5)
        
        # =====================================================================
        # 17. NEW: ADVANCED SHORT INTEREST FEATURES
        # =====================================================================
        # Short interest rate of change over multiple periods
        si_roc = []
        for period in [1, 2, 3]:
            if t >= period and data[t-period, 0] > 0:
                roc = (short_interest / data[t-period, 0]) - 1
                si_roc.append(roc)
            else:
                si_roc.append(0)
        timestamp_features.extend(si_roc)
        
        # Short interest momentum (acceleration of change)
        if len(si_roc) >= 2:
            si_momentum = si_roc[0] - si_roc[1]
            timestamp_features.append(si_momentum)
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 18. NEW: PRICE-VOLUME RELATIONSHIPS
        # =====================================================================
        # Price-volume correlation (5-day)
        if len(close_prices) >= 5 and t >= 4:
            price_changes = []
            volume_changes = []
            
            for i in range(min(5, t + 1)):
                if i < len(close_prices) - 1:
                    price_change = close_prices[-i-1] / close_prices[-i-2] - 1 if close_prices[-i-2] > 0 else 0
                    price_changes.append(price_change)
                
                if t-i > 0 and data[t-i-1, 1] > 0:
                    vol_change = data[t-i, 1] / data[t-i-1, 1] - 1
                    volume_changes.append(vol_change)
            
            if len(price_changes) >= 3 and len(volume_changes) >= 3:
                # Calculate correlation
                price_mean = np.mean(price_changes)
                vol_mean = np.mean(volume_changes)
                
                numerator = np.sum((price_changes - price_mean) * (volume_changes - vol_mean))
                denominator = np.sqrt(np.sum((price_changes - price_mean) ** 2) * np.sum((volume_changes - vol_mean) ** 2))
                
                correlation = numerator / denominator if denominator != 0 else 0
                timestamp_features.append(correlation)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 19. NEW: ENHANCED VOLATILITY MEASURES
        # =====================================================================
        # Average True Range (ATR) - 5-day
        if len(high_prices) >= 5 and len(low_prices) >= 5 and len(close_prices) >= 5:
            tr_values = []
            
            # First TR value
            tr_values.append(high_prices[-5] - low_prices[-5])
            
            # Remaining TR values
            for i in range(4, 0, -1):
                if i < len(high_prices) and i < len(low_prices) and i+1 < len(close_prices):
                    hl = high_prices[-i] - low_prices[-i]
                    hpc = abs(high_prices[-i] - close_prices[-(i+1)])
                    lpc = abs(low_prices[-i] - close_prices[-(i+1)])
                    tr = max(hl, hpc, lpc)
                    tr_values.append(tr)
            
            # Calculate ATR
            atr = np.mean(tr_values)
            
            # Normalize by close price
            if len(close_prices) > 0 and close_prices[-1] > 0:
                norm_atr = atr / close_prices[-1]
                timestamp_features.append(norm_atr)
            else:
                timestamp_features.append(0)
        else:
            timestamp_features.append(0)
        
        # =====================================================================
        # 20. NEW: ENHANCED INTERACTION TERMS WITH BASELINE FEATURES
        # =====================================================================
        # Interaction between short interest and volatility
        if len(close_prices) >= 5:
            returns = np.diff(close_prices[-5:]) / close_prices[-5:-1]
            returns = np.nan_to_num(returns, nan=0.0)
            vol = np.std(returns)
            timestamp_features.append(short_interest * vol)
        else:
            timestamp_features.append(0)
        
        # Interaction between Feature_56 and Feature_21 (top baseline features)
        timestamp_features.append(data[t, 56] * data[t, 21])
        
        # Interaction between short interest and RSI
        if len(close_prices) >= 14:
            diff = np.diff(close_prices[-14:])
            gains = np.sum(np.clip(diff, 0, None))
            losses = np.sum(np.abs(np.clip(diff, None, 0)))
            
            if losses > 0:
                rs = gains / losses
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100 if gains > 0 else 50
            
            timestamp_features.append(short_interest * (rsi / 100))
        else:
            timestamp_features.append(0)
        
        features_list.append(timestamp_features)
    
    try:
        # Convert to numpy array
        features_array = np.array(features_list, dtype=np.float64)
        
        # Final cleanup - handle any remaining NaN or inf values
        features_array = np.nan_to_num(features_array, nan=0.0, posinf=0.0, neginf=0.0)
        
        return features_array
    except:
        # Fallback in case of any conversion errors
        # Return a simple array with just the most important original features
        safe_features = []
        for t in range(lookback_window):
            safe_features.append([
                data[t, 0],   # Feature_0
                data[t, 56],  # Feature_56
                data[t, 21],  # Feature_21
                data[t, 35],  # Feature_35
                data[t, 60]   # Feature_60
            ])
        return np.array(safe_features, dtype=np.float64)
============================================================

