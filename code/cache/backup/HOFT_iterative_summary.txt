============================================================
ITERATIVE AGENT-BASED FEATURE SELECTION SUMMARY
============================================================
Stock: HOFT
Date: 2025-09-26 01:40:41
Total Iterations: 5

PERFORMANCE TREND:
----------------------------------------
Iteration 0: Baseline - MAPE: 14.92% (Baseline)
Iteration 1: Iteration 1 - MAPE: 30.86% (-15.94%)
Iteration 2: Iteration 2 - MAPE: nan% (+nan%)
Iteration 3: Iteration 3 - MAPE: 36.42% (-21.50%)
Iteration 4: Iteration 4 - MAPE: 20.12% (-5.20%)
Iteration 5: Iteration 5 - MAPE: 24.95% (-10.02%)

Best Model: Baseline - MAPE: 14.92%

============================================================
FEATURE ENGINEERING CODES
============================================================

ITERATION 1:
Performance: MAPE = 30.86%
Improvement: -15.94%
Features: 21
----------------------------------------
def construct_features(data):
    """
    Constructs engineered features for short interest prediction.
    
    Args:
        data: numpy array of shape (lookback_window, 62)
            - Feature 0: Short interest
            - Feature 1: Average daily volume
            - Features 2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data)
    
    # Initialize features array
    # We'll create a comprehensive set of features based on importance analysis
    constructed_features = []
    
    for t in range(lookback_window):
        time_features = []
        
        # Feature 0 (Short Interest) - highest importance (0.0051)
        short_interest = data[t, 0]
        time_features.append(short_interest)
        
        # Feature 1 (Average Daily Volume) - second highest importance (0.0027)
        avg_volume = data[t, 1]
        time_features.append(avg_volume)
        
        # Extract OHLC data for easier manipulation
        # Each day has 4 values (OHLC), so we have 15 days of data
        ohlc_data = data[t, 2:62].reshape(15, 4)
        
        # Extract specific components
        opens = ohlc_data[:, 0]
        highs = ohlc_data[:, 1]
        lows = ohlc_data[:, 2]
        closes = ohlc_data[:, 3]
        
        # Feature 29 was important (0.0012) - this corresponds to a specific OHLC value
        # Let's include it directly
        time_features.append(data[t, 29])
        
        # Feature 61 was important (0.0010) - this is the last OHLC value
        time_features.append(data[t, 61])
        
        # Feature 4 was important (0.0009)
        time_features.append(data[t, 4])
        
        # Price momentum features (short-term and medium-term)
        # 1-day returns
        daily_returns = np.diff(closes) / closes[:-1]
        time_features.append(np.mean(daily_returns))  # Average daily return
        time_features.append(np.sum(daily_returns > 0) / len(daily_returns))  # Percentage of positive returns
        
        # 3-day momentum
        if len(closes) >= 3:
            momentum_3d = (closes[-1] - closes[-3]) / closes[-3]
            time_features.append(momentum_3d)
        else:
            time_features.append(0)
            
        # 5-day momentum
        if len(closes) >= 5:
            momentum_5d = (closes[-1] - closes[-5]) / closes[-5]
            time_features.append(momentum_5d)
        else:
            time_features.append(0)
            
        # 10-day momentum
        if len(closes) >= 10:
            momentum_10d = (closes[-1] - closes[-10]) / closes[-10]
            time_features.append(momentum_10d)
        else:
            time_features.append(0)
        
        # Volatility features
        # Daily price range relative to close
        daily_ranges = (highs - lows) / closes
        time_features.append(np.mean(daily_ranges))  # Average daily range
        time_features.append(np.std(daily_ranges))   # Volatility of daily ranges
        
        # Standard deviation of returns (volatility)
        time_features.append(np.std(daily_returns))
        
        # Volume-price relationship features
        # Short interest to volume ratio (key relationship for short squeeze potential)
        time_features.append(short_interest / (avg_volume + 1e-8))  # Avoid division by zero
        
        # Rate of change in short interest (if we have previous data)
        if t > 0 and data[t-1, 0] != 0:
            si_change = (short_interest - data[t-1, 0]) / data[t-1, 0]
            time_features.append(si_change)
        else:
            time_features.append(0)
        
        # Technical indicators
        # Simple Moving Averages
        sma_5 = np.mean(closes[-5:]) if len(closes) >= 5 else np.mean(closes)
        sma_10 = np.mean(closes[-10:]) if len(closes) >= 10 else np.mean(closes)
        
        # SMA crossover signal
        time_features.append(sma_5 / (sma_10 + 1e-8) - 1)
        
        # RSI-like feature (simplified)
        if len(daily_returns) > 0:
            gains = daily_returns.copy()
            losses = daily_returns.copy()
            gains[gains < 0] = 0
            losses[losses > 0] = 0
            losses = np.abs(losses)
            
            avg_gain = np.mean(gains) if len(gains) > 0 else 0
            avg_loss = np.mean(losses) if len(losses) > 0 else 0
            
            if avg_loss != 0:
                rs = avg_gain / (avg_loss + 1e-8)
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100 if avg_gain > 0 else 50
                
            time_features.append(rsi)
        else:
            time_features.append(50)  # Neutral RSI
        
        # Price gap features
        if len(opens) > 1 and len(closes) > 1:
            overnight_gaps = opens[1:] - closes[:-1]
            normalized_gaps = overnight_gaps / closes[:-1]
            time_features.append(np.mean(normalized_gaps))
            time_features.append(np.sum(normalized_gaps > 0.01) / len(normalized_gaps))  # Significant positive gaps
            time_features.append(np.sum(normalized_gaps < -0.01) / len(normalized_gaps))  # Significant negative gaps
        else:
            time_features.extend([0, 0, 0])
        
        # Combine short interest with price action
        # Short interest relative to price change
        if len(daily_returns) > 0:
            time_features.append(short_interest * np.mean(daily_returns))
        else:
            time_features.append(0)
        
        # Avoid features identified as least important (Feature_40, Feature_10, Feature_3)
        # Instead, focus on derived features that capture financial relationships
        
        constructed_features.append(time_features)
    
    return np.array(constructed_features)
============================================================

ITERATION 2:
Performance: MAPE = nan%
Improvement: +nan%
Features: 26
----------------------------------------
def construct_features(data):
    """
    Constructs engineered features for short interest prediction.
    
    Args:
        data: numpy array of shape (lookback_window, 62)
            - Feature 0: Short interest
            - Feature 1: Average daily volume
            - Features 2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Validate input shape
    if len(data.shape) != 2 or data.shape[1] != 62:
        raise ValueError(f"Expected input shape (lookback_window, 62), got {data.shape}")
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize features array
    constructed_features = []
    
    for t in range(lookback_window):
        time_features = []
        
        # IMPORTANT: The baseline model performed better than the previous iteration
        # This suggests we should focus more on the original features that showed high importance
        # and be more selective with derived features
        
        # ---- ORIGINAL HIGH-IMPORTANCE FEATURES ----
        
        # Feature 0 (Short Interest) - highest importance (0.0051)
        short_interest = data[t, 0]
        time_features.append(short_interest)
        
        # Feature 1 (Average Daily Volume) - second highest importance (0.0027)
        avg_volume = data[t, 1]
        time_features.append(avg_volume)
        
        # Feature 29 was important (0.0012)
        time_features.append(data[t, 29])
        
        # Feature 61 was important (0.0010)
        time_features.append(data[t, 61])
        
        # Feature 4 was important (0.0009)
        time_features.append(data[t, 4])
        
        # Extract OHLC data for easier manipulation
        # Each day has 4 values (OHLC), so we have 15 days of data
        ohlc_data = data[t, 2:62].reshape(15, 4)
        
        # Extract specific components
        opens = ohlc_data[:, 0]
        highs = ohlc_data[:, 1]
        lows = ohlc_data[:, 2]
        closes = ohlc_data[:, 3]
        
        # ---- CORE SHORT INTEREST RELATIONSHIPS ----
        
        # Days to cover (key short squeeze indicator)
        days_to_cover = short_interest / (avg_volume + 1e-8)
        time_features.append(days_to_cover)
        
        # Short interest as percentage of average volume
        si_volume_ratio = short_interest * 100 / (avg_volume + 1e-8)
        time_features.append(si_volume_ratio)
        
        # Short interest momentum (if we have previous data)
        if t > 0 and data[t-1, 0] > 0:
            si_change = (short_interest - data[t-1, 0]) / data[t-1, 0]
            time_features.append(si_change)
        else:
            time_features.append(0)
        
        # ---- PRICE ACTION FEATURES ----
        
        # Calculate returns carefully to avoid division by zero
        daily_returns = np.zeros(len(closes)-1)
        for i in range(len(closes)-1):
            if closes[i] != 0:
                daily_returns[i] = (closes[i+1] - closes[i]) / closes[i]
        
        # Last day return (most recent price action)
        if len(daily_returns) > 0:
            time_features.append(daily_returns[-1])
        else:
            time_features.append(0)
        
        # Recent price trend (last 3 days)
        if len(closes) >= 3 and closes[-3] != 0:
            recent_trend = (closes[-1] - closes[-3]) / closes[-3]
            time_features.append(recent_trend)
        else:
            time_features.append(0)
        
        # ---- VOLATILITY FEATURES ----
        
        # Recent volatility (standard deviation of last 5 days' returns)
        if len(daily_returns) >= 5:
            recent_volatility = np.std(daily_returns[-5:])
            time_features.append(recent_volatility)
        else:
            time_features.append(np.std(daily_returns) if len(daily_returns) > 0 else 0)
        
        # Average true range (ATR) - simplified version
        tr_values = []
        for i in range(1, len(ohlc_data)):
            high = highs[i]
            low = lows[i]
            prev_close = closes[i-1]
            tr = max(high - low, abs(high - prev_close), abs(low - prev_close))
            if closes[i] != 0:  # Normalize by close price
                tr_values.append(tr / closes[i])
            else:
                tr_values.append(0)
        
        time_features.append(np.mean(tr_values) if tr_values else 0)
        
        # ---- VOLUME-PRICE RELATIONSHIP ----
        
        # Volume trend
        if t > 0 and data[t-1, 1] > 0:
            volume_change = (avg_volume - data[t-1, 1]) / data[t-1, 1]
            time_features.append(volume_change)
        else:
            time_features.append(0)
        
        # Volume-price correlation
        if len(daily_returns) > 5:
            # Calculate daily volume changes
            daily_volumes = np.ones(len(daily_returns))  # Placeholder as we don't have daily volume
            # Use correlation between price changes and volume
            try:
                vol_price_corr = np.corrcoef(daily_returns, daily_volumes)[0, 1]
                time_features.append(vol_price_corr)
            except:
                time_features.append(0)
        else:
            time_features.append(0)
        
        # ---- TECHNICAL INDICATORS ----
        
        # Moving averages
        ma5 = np.mean(closes[-5:]) if len(closes) >= 5 else np.mean(closes)
        ma10 = np.mean(closes[-10:]) if len(closes) >= 10 else np.mean(closes)
        ma15 = np.mean(closes) if closes.size > 0 else 0
        
        # Price relative to moving averages
        if closes.size > 0 and closes[-1] != 0:
            price_to_ma5 = closes[-1] / ma5 if ma5 != 0 else 1
            price_to_ma10 = closes[-1] / ma10 if ma10 != 0 else 1
            price_to_ma15 = closes[-1] / ma15 if ma15 != 0 else 1
            
            time_features.append(price_to_ma5 - 1)  # Percent above/below MA5
            time_features.append(price_to_ma10 - 1)  # Percent above/below MA10
            time_features.append(price_to_ma15 - 1)  # Percent above/below MA15
        else:
            time_features.extend([0, 0, 0])
        
        # RSI (14-period)
        if len(daily_returns) >= 14:
            gains = np.maximum(daily_returns, 0)
            losses = np.abs(np.minimum(daily_returns, 0))
            
            avg_gain = np.mean(gains[-14:])
            avg_loss = np.mean(losses[-14:])
            
            if avg_loss > 0:
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100 if avg_gain > 0 else 50
            
            time_features.append(rsi / 100)  # Normalize to 0-1 range
        else:
            time_features.append(0.5)  # Neutral RSI
        
        # ---- COMBINED FEATURES ----
        
        # Short interest relative to volatility
        if len(daily_returns) > 0:
            volatility = np.std(daily_returns)
            si_vol_ratio = short_interest * volatility
            time_features.append(si_vol_ratio)
        else:
            time_features.append(0)
        
        # Short interest change relative to price change
        if t > 0 and data[t-1, 0] > 0 and len(daily_returns) > 0:
            si_change = (short_interest - data[t-1, 0]) / data[t-1, 0]
            price_change = daily_returns[-1] if len(daily_returns) > 0 else 0
            si_price_change_ratio = si_change * price_change
            time_features.append(si_price_change_ratio)
        else:
            time_features.append(0)
        
        # ---- FEATURE TRANSFORMATIONS ----
        
        # Log transform of short interest (to handle skewness)
        time_features.append(np.log1p(short_interest))
        
        # Log transform of volume
        time_features.append(np.log1p(avg_volume))
        
        # Square root transform of days to cover
        time_features.append(np.sqrt(days_to_cover))
        
        # ---- INTERACTION TERMS ----
        
        # Short interest × Recent volatility
        recent_vol = np.std(daily_returns[-5:]) if len(daily_returns) >= 5 else (np.std(daily_returns) if len(daily_returns) > 0 else 0)
        time_features.append(short_interest * recent_vol)
        
        # Short interest × Volume
        time_features.append(short_interest * avg_volume)
        
        # Short interest × Price trend
        recent_trend = (closes[-1] - closes[-3]) / closes[-3] if len(closes) >= 3 and closes[-3] != 0 else 0
        time_features.append(short_interest * recent_trend)
        
        constructed_features.append(time_features)
    
    # Convert to numpy array and ensure we have a 2D array
    result = np.array(constructed_features)
    
    # Final validation of output shape
    if len(result.shape) != 2:
        raise ValueError(f"Expected output shape (lookback_window, features), got {result.shape}")
    
    return result
============================================================

ITERATION 3:
Performance: MAPE = 36.42%
Improvement: -21.50%
Features: 26
----------------------------------------
def construct_features(data):
    """
    Constructs engineered features for short interest prediction.
    
    Args:
        data: numpy array of shape (lookback_window, 62)
            - Feature 0: Short interest
            - Feature 1: Average daily volume
            - Features 2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Validate input shape
    if len(data.shape) != 2 or data.shape[1] != 62:
        raise ValueError(f"Expected input shape (lookback_window, 62), got {data.shape}")
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize features array
    constructed_features = []
    
    for t in range(lookback_window):
        time_features = []
        
        # ---- ORIGINAL HIGH-IMPORTANCE FEATURES ----
        # The baseline model (MAPE 14.92%) outperformed both iterations, suggesting we should
        # focus primarily on the original high-importance features and be very selective with
        # derived features to avoid overfitting
        
        # Feature 0 (Short Interest) - highest importance (0.0051)
        short_interest = data[t, 0]
        time_features.append(short_interest)  # Keep original short interest
        
        # Feature 1 (Average Daily Volume) - second highest importance (0.0027)
        avg_volume = data[t, 1]
        time_features.append(avg_volume)  # Keep original volume
        
        # Feature 29 was important (0.0012) - corresponds to a specific OHLC value
        time_features.append(data[t, 29])
        
        # Feature 61 was important (0.0010) - corresponds to a specific OHLC value
        time_features.append(data[t, 61])
        
        # Feature 4 was important (0.0009) - corresponds to a specific OHLC value
        time_features.append(data[t, 4])
        
        # Extract OHLC data for easier manipulation
        # Each day has 4 values (OHLC), so we have 15 days of data
        ohlc_data = data[t, 2:62].reshape(15, 4)
        
        # Extract specific components
        opens = ohlc_data[:, 0]
        highs = ohlc_data[:, 1]
        lows = ohlc_data[:, 2]
        closes = ohlc_data[:, 3]
        
        # ---- CORE SHORT INTEREST METRICS ----
        
        # Days to cover - key short squeeze indicator (simplified)
        # This is a standard financial metric for short interest analysis
        days_to_cover = short_interest / (avg_volume + 1e-8)
        time_features.append(days_to_cover)
        
        # Short interest as percentage of average volume
        si_volume_ratio = short_interest / (avg_volume + 1e-8)
        time_features.append(si_volume_ratio)
        
        # ---- SHORT INTEREST MOMENTUM ----
        
        # Short interest change (if we have previous data)
        # Momentum is often a strong predictor in financial time series
        if t > 0:
            prev_si = data[t-1, 0]
            if prev_si > 0:
                si_change = (short_interest - prev_si) / prev_si
            else:
                si_change = 0 if short_interest == 0 else 1
            time_features.append(si_change)
            
            # Short interest acceleration (rate of change of the change)
            if t > 1:
                prev_prev_si = data[t-2, 0]
                if prev_prev_si > 0:
                    prev_si_change = (prev_si - prev_prev_si) / prev_prev_si
                    si_acceleration = si_change - prev_si_change
                    time_features.append(si_acceleration)
                else:
                    time_features.append(0)
            else:
                time_features.append(0)
        else:
            time_features.extend([0, 0])  # Padding for consistency
        
        # ---- PRICE ACTION FEATURES ----
        
        # Calculate returns carefully to avoid division by zero
        daily_returns = np.zeros(len(closes)-1)
        for i in range(len(closes)-1):
            if closes[i] > 0:
                daily_returns[i] = (closes[i+1] - closes[i]) / closes[i]
        
        # Most recent return (last day)
        if len(daily_returns) > 0:
            time_features.append(daily_returns[-1])
        else:
            time_features.append(0)
        
        # ---- VOLATILITY FEATURES ----
        
        # Recent volatility (standard deviation of returns)
        # Using different lookback periods to capture different time horizons
        if len(daily_returns) > 0:
            volatility = np.std(daily_returns)
            time_features.append(volatility)
            
            # Short-term volatility (last 5 days if available)
            if len(daily_returns) >= 5:
                short_term_vol = np.std(daily_returns[-5:])
                time_features.append(short_term_vol)
            else:
                time_features.append(volatility)  # Use overall volatility if not enough data
        else:
            time_features.extend([0, 0])  # Padding for consistency
        
        # ---- PRICE LEVELS AND TRENDS ----
        
        # Current price relative to recent highs/lows
        if len(closes) > 0 and closes[-1] > 0:
            recent_high = np.max(highs[-5:]) if len(highs) >= 5 else np.max(highs)
            recent_low = np.min(lows[-5:]) if len(lows) >= 5 else np.min(lows)
            
            # Price position within recent range (0 = at low, 1 = at high)
            if recent_high > recent_low:
                price_position = (closes[-1] - recent_low) / (recent_high - recent_low)
                time_features.append(price_position)
            else:
                time_features.append(0.5)  # Middle if no range
        else:
            time_features.append(0.5)  # Default to middle
        
        # ---- MOVING AVERAGES ----
        
        # Simple moving averages
        ma5 = np.mean(closes[-5:]) if len(closes) >= 5 else np.mean(closes) if len(closes) > 0 else 0
        ma10 = np.mean(closes[-10:]) if len(closes) >= 10 else np.mean(closes) if len(closes) > 0 else 0
        
        # Price relative to moving averages
        if len(closes) > 0 and closes[-1] > 0:
            if ma5 > 0:
                price_to_ma5 = closes[-1] / ma5 - 1  # Percent above/below MA5
                time_features.append(price_to_ma5)
            else:
                time_features.append(0)
                
            if ma10 > 0:
                price_to_ma10 = closes[-1] / ma10 - 1  # Percent above/below MA10
                time_features.append(price_to_ma10)
            else:
                time_features.append(0)
        else:
            time_features.extend([0, 0])
        
        # ---- VOLUME ANALYSIS ----
        
        # Volume trend
        if t > 0:
            prev_volume = data[t-1, 1]
            if prev_volume > 0:
                volume_change = (avg_volume - prev_volume) / prev_volume
                time_features.append(volume_change)
            else:
                time_features.append(0)
        else:
            time_features.append(0)
        
        # ---- KEY FINANCIAL RATIOS ----
        
        # Short interest to float ratio (approximation)
        # We don't have float data, but we can use volume as a proxy
        si_to_volume_ratio = short_interest / (avg_volume * 20 + 1e-8)  # 20 trading days ~ 1 month
        time_features.append(si_to_volume_ratio)
        
        # ---- INTERACTION TERMS ----
        
        # Short interest × Volatility interaction
        # Higher short interest combined with higher volatility may indicate potential for short squeezes
        si_vol_interaction = short_interest * volatility if len(daily_returns) > 0 else 0
        time_features.append(si_vol_interaction)
        
        # Short interest × Recent return interaction
        # Captures relationship between short interest and recent price movements
        recent_return = daily_returns[-1] if len(daily_returns) > 0 else 0
        si_return_interaction = short_interest * recent_return
        time_features.append(si_return_interaction)
        
        # ---- TRANSFORMATIONS ----
        
        # Log transform of short interest (to handle skewness)
        # Log transformation can help normalize heavily skewed distributions
        log_si = np.log1p(short_interest)  # log(1+x) to handle zeros
        time_features.append(log_si)
        
        # Log transform of volume
        log_volume = np.log1p(avg_volume)
        time_features.append(log_volume)
        
        # ---- TECHNICAL INDICATORS ----
        
        # RSI (Relative Strength Index) - simplified
        if len(daily_returns) >= 14:
            gains = np.maximum(daily_returns, 0)
            losses = np.abs(np.minimum(daily_returns, 0))
            
            avg_gain = np.mean(gains[-14:])
            avg_loss = np.mean(losses[-14:])
            
            if avg_loss > 0:
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100 if avg_gain > 0 else 50
            
            time_features.append(rsi / 100)  # Normalize to 0-1 range
        else:
            time_features.append(0.5)  # Neutral RSI
        
        # ---- TEMPORAL FEATURES ----
        
        # Lookback window position (normalized time indicator)
        # This helps the model understand the temporal position within the sequence
        time_position = t / (lookback_window - 1) if lookback_window > 1 else 0.5
        time_features.append(time_position)
        
        # ---- ADDITIONAL IMPORTANT ORIGINAL FEATURES ----
        
        # Include a few more of the original features that might be important
        # Based on the importance analysis, we're selecting a few more original features
        # that might contain valuable information
        time_features.append(data[t, 2])  # First OHLC value
        time_features.append(data[t, 17])  # Mid-range OHLC value
        time_features.append(data[t, 45])  # Later OHLC value
        
        constructed_features.append(time_features)
    
    # Convert to numpy array
    result = np.array(constructed_features)
    
    # Final validation of output shape
    if len(result.shape) != 2:
        raise ValueError(f"Expected output shape (lookback_window, features), got {result.shape}")
    
    return result
============================================================

ITERATION 4:
Performance: MAPE = 20.12%
Improvement: -5.20%
Features: 23
----------------------------------------
def construct_features(data):
    """
    Constructs engineered features for short interest prediction.
    
    Args:
        data: numpy array of shape (lookback_window, 62)
            - Feature 0: Short interest
            - Feature 1: Average daily volume
            - Features 2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Validate input shape
    if len(data.shape) != 2 or data.shape[1] != 62:
        raise ValueError(f"Expected input shape (lookback_window, 62), got {data.shape}")
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize features array
    constructed_features = []
    
    for t in range(lookback_window):
        time_features = []
        
        # ---- ORIGINAL HIGH-IMPORTANCE FEATURES ----
        # Analysis of performance history shows the baseline model (MAPE 14.92%) 
        # outperformed all iterations. This suggests we should focus on the original
        # high-importance features and be very selective with derived features.
        
        # Feature 0 (Short Interest) - highest importance (0.0051)
        short_interest = data[t, 0]
        time_features.append(short_interest)  # Keep original short interest
        
        # Feature 1 (Average Daily Volume) - second highest importance (0.0027)
        avg_volume = data[t, 1]
        time_features.append(avg_volume)  # Keep original volume
        
        # Feature 29 was important (0.0012) - corresponds to a specific OHLC value
        time_features.append(data[t, 29])
        
        # Feature 61 was important (0.0010) - corresponds to a specific OHLC value
        time_features.append(data[t, 61])
        
        # Feature 4 was important (0.0009) - corresponds to a specific OHLC value
        time_features.append(data[t, 4])
        
        # Extract OHLC data for easier manipulation
        # Each day has 4 values (OHLC), so we have 15 days of data
        ohlc_data = data[t, 2:62].reshape(15, 4)
        
        # Extract specific components
        opens = ohlc_data[:, 0]
        highs = ohlc_data[:, 1]
        lows = ohlc_data[:, 2]
        closes = ohlc_data[:, 3]
        
        # ---- MINIMAL FEATURE ENGINEERING ----
        # Previous iterations added too many derived features, which likely led to overfitting.
        # We'll be much more selective here, focusing only on the most financially relevant
        # metrics with minimal transformations.
        
        # Days to cover - key short squeeze indicator
        # This is a standard financial metric for short interest analysis
        days_to_cover = short_interest / (avg_volume + 1e-8)
        time_features.append(days_to_cover)
        
        # Short interest change (if we have previous data)
        # Only include if we have previous data
        if t > 0:
            prev_si = data[t-1, 0]
            if prev_si > 0:
                si_change = (short_interest - prev_si) / prev_si
            else:
                si_change = 0 if short_interest == 0 else 1
            time_features.append(si_change)
        else:
            time_features.append(0)  # Padding for consistency
        
        # Recent price trend (using last 5 days of closes)
        # Simple moving average of recent closes
        recent_closes = closes[-5:] if len(closes) >= 5 else closes
        if len(recent_closes) > 0:
            recent_price_trend = np.mean(recent_closes) / (recent_closes[0] + 1e-8) - 1
            time_features.append(recent_price_trend)
        else:
            time_features.append(0)
            
        # Recent volatility (using last 5 days of OHLC)
        # Volatility is often correlated with short interest changes
        if len(recent_closes) > 1:
            daily_ranges = (highs[-5:] - lows[-5:]) / (opens[-5:] + 1e-8)
            avg_range = np.mean(daily_ranges)
            time_features.append(avg_range)
        else:
            time_features.append(0)
            
        # Volume trend (rate of change)
        # Only include if we have previous data
        if t > 0:
            prev_volume = data[t-1, 1]
            if prev_volume > 0:
                volume_change = (avg_volume - prev_volume) / prev_volume
                time_features.append(volume_change)
            else:
                time_features.append(0)
        else:
            time_features.append(0)
            
        # ---- INCLUDE MORE ORIGINAL FEATURES ----
        # Since the baseline model performed best, we'll include more of the original
        # features that might contain valuable information
        
        # Add a few more original OHLC values that might be important
        # These correspond to different days in the 15-day window
        important_indices = [2, 8, 17, 23, 35, 41, 47, 53]
        for idx in important_indices:
            if idx < data.shape[1]:
                time_features.append(data[t, idx])
        
        # ---- SIMPLE TRANSFORMATIONS OF KEY FEATURES ----
        # Simple transformations can help capture non-linear relationships
        
        # Log transform of short interest (to handle skewness)
        log_si = np.log1p(short_interest)  # log(1+x) to handle zeros
        time_features.append(log_si)
        
        # Square root transform of volume (less aggressive than log)
        sqrt_volume = np.sqrt(avg_volume)
        time_features.append(sqrt_volume)
        
        # Short interest to volume ratio (key financial metric)
        si_to_volume = short_interest / (avg_volume + 1e-8)
        time_features.append(si_to_volume)
        
        # ---- MINIMAL TECHNICAL INDICATORS ----
        # Only include the most relevant technical indicators
        
        # Price momentum (rate of change over last few days)
        if len(closes) > 5:
            momentum = closes[-1] / (closes[-6] + 1e-8) - 1
            time_features.append(momentum)
        else:
            time_features.append(0)
        
        # ---- INTERACTION TERMS ----
        # Only include the most financially meaningful interaction
        
        # Short interest × Volatility interaction
        # Higher short interest combined with higher volatility may indicate potential for short squeezes
        if len(recent_closes) > 1:
            si_vol_interaction = short_interest * avg_range / 100  # Scale down to avoid large values
            time_features.append(si_vol_interaction)
        else:
            time_features.append(0)
            
        constructed_features.append(time_features)
    
    # Convert to numpy array
    result = np.array(constructed_features)
    
    # Final validation of output shape
    if len(result.shape) != 2:
        raise ValueError(f"Expected output shape (lookback_window, features), got {result.shape}")
    
    return result
============================================================

ITERATION 5:
Performance: MAPE = 24.95%
Improvement: -10.02%
Features: 38
----------------------------------------
def construct_features(data):
    """
    Constructs engineered features for short interest prediction.
    
    Args:
        data: numpy array of shape (lookback_window, 62)
            - Feature 0: Short interest
            - Feature 1: Average daily volume
            - Features 2-61: OHLC prices for past 15 days (4 × 15 = 60 dimensions)
    
    Returns:
        numpy array of shape (lookback_window, constructed_features)
    """
    # Validate input shape
    if len(data.shape) != 2 or data.shape[1] != 62:
        raise ValueError(f"Expected input shape (lookback_window, 62), got {data.shape}")
    
    lookback_window = data.shape[0]
    
    # Handle NaN values
    data = np.nan_to_num(data, nan=0.0)
    
    # Initialize features array
    constructed_features = []
    
    # ANALYSIS OF PREVIOUS ITERATIONS:
    # - Baseline model (MAPE 14.92%) outperformed all iterations
    # - Feature_0 (Short Interest) was consistently important across iterations
    # - Feature_1 (Volume) was important in the best model
    # - Too many derived features likely led to overfitting
    # - Need to focus on original high-importance features with minimal transformations
    
    for t in range(lookback_window):
        time_features = []
        
        # ---- ORIGINAL HIGH-IMPORTANCE FEATURES ----
        # Keep all original features that showed high importance in the best model
        
        # Feature 0 (Short Interest) - consistently highest importance
        short_interest = data[t, 0]
        time_features.append(short_interest)
        
        # Feature 1 (Average Daily Volume) - second highest importance
        avg_volume = data[t, 1]
        time_features.append(avg_volume)
        
        # Extract OHLC data for easier manipulation
        # Each day has 4 values (OHLC), so we have 15 days of data
        ohlc_data = data[t, 2:62].reshape(15, 4)
        
        # Extract specific components
        opens = ohlc_data[:, 0]
        highs = ohlc_data[:, 1]
        lows = ohlc_data[:, 2]
        closes = ohlc_data[:, 3]
        
        # ---- KEEP ORIGINAL HIGH-IMPORTANCE FEATURES ----
        # Feature 29 was important (0.0012) in the best model
        time_features.append(data[t, 29])
        
        # Feature 61 was important (0.0010) in the best model
        time_features.append(data[t, 61])
        
        # Feature 4 was important (0.0009) in the best model
        time_features.append(data[t, 4])
        
        # ---- MINIMAL FEATURE ENGINEERING ----
        # Since the baseline model performed best, we'll be extremely selective
        # with derived features, focusing only on the most financially relevant metrics
        
        # Days to cover - key short squeeze indicator
        days_to_cover = short_interest / (avg_volume + 1e-8)
        time_features.append(days_to_cover)
        
        # Short interest to price ratio (for each of the last 3 days)
        # This captures the relationship between short interest and recent prices
        for i in range(1, 4):
            if i < len(closes):
                si_price_ratio = short_interest / (closes[-i] + 1e-8)
                time_features.append(si_price_ratio)
            else:
                time_features.append(0)
        
        # Short interest change (if we have previous data)
        if t > 0:
            prev_si = data[t-1, 0]
            si_change = (short_interest - prev_si) / (prev_si + 1e-8)
            time_features.append(si_change)
        else:
            time_features.append(0)
        
        # Volume change (if we have previous data)
        if t > 0:
            prev_volume = data[t-1, 1]
            volume_change = (avg_volume - prev_volume) / (prev_volume + 1e-8)
            time_features.append(volume_change)
        else:
            time_features.append(0)
        
        # ---- PRICE PATTERNS ----
        # Recent price trends (last 5 days)
        if len(closes) >= 5:
            price_trend = closes[-1] / (closes[-5] + 1e-8) - 1
            time_features.append(price_trend)
        else:
            time_features.append(0)
        
        # Recent volatility (using last 5 days)
        if len(closes) >= 5:
            recent_highs = highs[-5:]
            recent_lows = lows[-5:]
            avg_range = np.mean((recent_highs - recent_lows) / (recent_lows + 1e-8))
            time_features.append(avg_range)
        else:
            time_features.append(0)
        
        # ---- INCLUDE MORE ORIGINAL FEATURES ----
        # Add more original features that might contain valuable information
        # These indices were chosen based on their potential importance in the OHLC data
        # and to provide a good coverage of the 15-day window
        important_indices = [2, 5, 8, 11, 14, 17, 20, 23, 26, 32, 35, 38, 41, 44, 47, 50, 53, 56, 59]
        for idx in important_indices:
            if idx < data.shape[1]:
                time_features.append(data[t, idx])
        
        # ---- SIMPLE TRANSFORMATIONS OF KEY FEATURES ----
        # Simple transformations can help capture non-linear relationships
        
        # Log transform of short interest (to handle skewness)
        log_si = np.log1p(short_interest)
        time_features.append(log_si)
        
        # Log transform of volume
        log_volume = np.log1p(avg_volume)
        time_features.append(log_volume)
        
        # ---- TECHNICAL INDICATORS ----
        # Only include the most relevant technical indicators
        
        # Moving Average Convergence Divergence (MACD) - simplified version
        if len(closes) >= 12:
            ema_12 = np.mean(closes[-12:])
            ema_26 = np.mean(closes[-min(26, len(closes)):])
            macd = ema_12 - ema_26
            time_features.append(macd)
        else:
            time_features.append(0)
        
        # Relative Strength Index (RSI) - simplified version
        if len(closes) >= 14:
            diff = np.diff(closes[-15:])
            gains = np.sum(np.maximum(diff, 0))
            losses = np.sum(np.abs(np.minimum(diff, 0)))
            if losses > 0:
                rs = gains / losses
                rsi = 100 - (100 / (1 + rs))
            else:
                rsi = 100
            time_features.append(rsi / 100)  # Normalize to [0,1]
        else:
            time_features.append(0.5)  # Neutral RSI
        
        # ---- INTERACTION TERMS ----
        # Only include the most financially meaningful interactions
        
        # Short interest × Volume interaction
        si_vol = short_interest * avg_volume / 1e6  # Scale down
        time_features.append(si_vol)
        
        # Short interest × Price volatility interaction
        if len(closes) >= 5:
            si_vol_interaction = short_interest * avg_range / 100  # Scale down
            time_features.append(si_vol_interaction)
        else:
            time_features.append(0)
        
        constructed_features.append(time_features)
    
    # Convert to numpy array
    result = np.array(constructed_features)
    
    # Final validation of output shape
    if len(result.shape) != 2:
        raise ValueError(f"Expected output shape (lookback_window, features), got {result.shape}")
    
    return result
============================================================

